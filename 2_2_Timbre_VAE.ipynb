{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2.2 Timbre VAE",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PratikStar/google-colab/blob/main/2_2_Timbre_VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHIAgyMQE-60"
      },
      "source": [
        "### Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSpskSmkGT4C",
        "outputId": "4da2543f-ce77-47d3-9f2b-b3435534ae03"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',  force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdlnHSb1FDsJ"
      },
      "source": [
        "### Install tensorflow v2.4.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vr15BDmekCAy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95e7609f-328f-4530-c4ee-8365da1be88d"
      },
      "source": [
        "!pip uninstall --yes tensorflow\n",
        "!pip install tensorflow==2.4.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.6.0\n",
            "Uninstalling tensorflow-2.6.0:\n",
            "  Successfully uninstalled tensorflow-2.6.0\n",
            "Collecting tensorflow==2.4.0\n",
            "  Downloading tensorflow-2.4.0-cp37-cp37m-manylinux2010_x86_64.whl (394.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 394.7 MB 15 kB/s \n",
            "\u001b[?25hCollecting h5py~=2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 74.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.12)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (0.12.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.19.5)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (2.6.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (3.17.3)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.12.1)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (3.7.4.3)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.6.3)\n",
            "Collecting tensorflow-estimator<2.5.0,>=2.4.0rc0\n",
            "  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 67.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.1.2)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.15.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (3.3.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (0.37.0)\n",
            "Collecting gast==0.3.3\n",
            "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
            "Collecting grpcio~=1.32.0\n",
            "  Downloading grpcio-1.32.0-cp37-cp37m-manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 24.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.1.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (0.2.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (3.3.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (2.23.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (1.35.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (1.0.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.0) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.0) (4.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.0) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.0) (3.5.0)\n",
            "Installing collected packages: grpcio, tensorflow-estimator, h5py, gast, tensorflow\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.40.0\n",
            "    Uninstalling grpcio-1.40.0:\n",
            "      Successfully uninstalled grpcio-1.40.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.6.0\n",
            "    Uninstalling tensorflow-estimator-2.6.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.6.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "Successfully installed gast-0.3.3 grpcio-1.32.0 h5py-2.10.0 tensorflow-2.4.0 tensorflow-estimator-2.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTlUZZpvz9Xt"
      },
      "source": [
        "## Autoencoder Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlxNWPvvVn1L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd8adbd7-5038-485a-923f-79370ba461ea"
      },
      "source": [
        "\"#@title\"\n",
        "import os\n",
        "import pickle\n",
        "import csv\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization, \\\n",
        "    Flatten, Dense, Reshape, Conv2DTranspose, Activation, Lambda, concatenate\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "print(tf.__version__)\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "\n",
        "class VAE:\n",
        "    \"\"\"\n",
        "    VAE represents a Deep Convolutional variational autoencoder architecture\n",
        "    with mirrored encoder and decoder components.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 timbre_input_shape,\n",
        "                 music_input_shape,\n",
        "                 conv_filters,\n",
        "                 conv_kernels,\n",
        "                 conv_strides,\n",
        "                 music_latent_space_dim,\n",
        "                 timbre_latent_space_dim):\n",
        "        self.timbre_input_shape = timbre_input_shape\n",
        "        self.music_input_shape = music_input_shape\n",
        "\n",
        "        self.conv_filters = conv_filters\n",
        "        self.conv_kernels = conv_kernels \n",
        "        self.conv_strides = conv_strides \n",
        "        self.music_latent_space_dim = music_latent_space_dim \n",
        "        self.timbre_latent_space_dim = timbre_latent_space_dim \n",
        "        self.reconstruction_loss_weight = 1000000\n",
        "\n",
        "        self.encoder = None\n",
        "        self.decoder = None\n",
        "        self.model = None\n",
        "\n",
        "        self._num_conv_layers = len(conv_filters)\n",
        "        self._shape_before_bottleneck = None\n",
        "        self._model_input = None\n",
        "\n",
        "        self._build()\n",
        "\n",
        "    def summary(self):\n",
        "        self.encoder.summary()\n",
        "        self.decoder.summary()\n",
        "        self.model.summary()\n",
        "\n",
        "    def compile(self, learning_rate=0.0001):\n",
        "        optimizer = Adam(learning_rate=learning_rate)\n",
        "        self.model.compile(optimizer=optimizer,\n",
        "                           loss=self._calculate_combined_loss,\n",
        "                           metrics=[self._calculate_reconstruction_loss,\n",
        "                                    self._calculate_kl_loss])\n",
        "\n",
        "    def train(self, generator, dataset_length, batch_size, num_epochs, callbacks):\n",
        "        if dataset_length % batch_size != 0:\n",
        "            raise Exception(\"dataset_length % batch_size = \" + str(dataset_length % batch_size) + \" != 0. Exiting!!\")\n",
        "        return self.model.fit(x=generator,\n",
        "                       steps_per_epoch= dataset_length/batch_size,\n",
        "                       epochs=num_epochs,\n",
        "                       callbacks=callbacks\n",
        "              )\n",
        "\n",
        "    def save(self, save_folder=\".\"):\n",
        "        self._create_folder_if_it_doesnt_exist(save_folder)\n",
        "        self.save_parameters(save_folder)\n",
        "        self._save_weights(save_folder)\n",
        "\n",
        "    def reconstruct(self, images):\n",
        "        latent_representations = self.encoder.predict(images)\n",
        "        reconstructed_images = self.decoder.predict(latent_representations)\n",
        "        return reconstructed_images, latent_representations\n",
        "\n",
        "    def save_parameters(self, save_folder):\n",
        "        self._create_folder_if_it_doesnt_exist(save_folder)\n",
        "        parameters = [\n",
        "            self.timbre_input_shape,\n",
        "            self.music_input_shape,\n",
        "            self.conv_filters,\n",
        "            self.conv_kernels,\n",
        "            self.conv_strides,\n",
        "            self.music_latent_space_dim,\n",
        "            self.timbre_latent_space_dim\n",
        "        ]\n",
        "        save_path = os.path.join(save_folder, \"parameters.pkl\")\n",
        "        with open(save_path, \"wb\") as f:\n",
        "            print(parameters)\n",
        "            pickle.dump(parameters, f)\n",
        "\n",
        "    def _save_weights(self, save_folder):\n",
        "        save_path = os.path.join(save_folder, \"weights.h5\")\n",
        "        self.model.save_weights(save_path)\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, save_folder=\".\", weights_file_name=\"weights.h5\"):\n",
        "        parameters_path = os.path.join(save_folder, \"parameters.pkl\")\n",
        "        weights_path = os.path.join(save_folder, weights_file_name)\n",
        "        if not os.path.exists(parameters_path) or not os.path.exists(weights_path):\n",
        "            return None\n",
        "        with open(parameters_path, \"rb\") as f:\n",
        "            parameters = pickle.load(f)\n",
        "        autoencoder = VAE(*parameters)\n",
        "        autoencoder.load_weights(weights_path)\n",
        "        return autoencoder\n",
        "\n",
        "    def load_weights(self, weights_path):\n",
        "        self.model.load_weights(weights_path)\n",
        "\n",
        "    def _calculate_combined_loss(self, y_target, y_predicted):\n",
        "        reconstruction_loss = self._calculate_reconstruction_loss(y_target, y_predicted)\n",
        "        kl_loss = self._calculate_kl_loss(y_target, y_predicted)\n",
        "        combined_loss = self.reconstruction_loss_weight * reconstruction_loss\\\n",
        "                                                         + kl_loss\n",
        "        return combined_loss\n",
        "\n",
        "    def _calculate_reconstruction_loss(self, y_target, y_predicted):\n",
        "        error = y_target - y_predicted\n",
        "        reconstruction_loss = K.mean(K.square(error), axis=[1, 2, 3])\n",
        "        return reconstruction_loss\n",
        "\n",
        "    def _calculate_kl_loss(self, y_target, y_predicted):\n",
        "        kl_loss = -0.5 * K.sum(1 + self.log_variance - K.square(self.mu) -\n",
        "                               K.exp(self.log_variance), axis=1)\n",
        "        return kl_loss\n",
        "\n",
        "    def _create_folder_if_it_doesnt_exist(self, folder):\n",
        "        if not os.path.exists(folder):\n",
        "            os.makedirs(folder)\n",
        "\n",
        "    def _build(self):\n",
        "        self._build_encoder()\n",
        "        self._build_decoder()\n",
        "        self._build_autoencoder()\n",
        "\n",
        "    def _build_autoencoder(self):\n",
        "        model_input = self._model_input\n",
        "        model_output = self.decoder(self.encoder(model_input))\n",
        "        self.model = Model(model_input, model_output, name=\"autoencoder\")\n",
        "\n",
        "    def _build_decoder(self):\n",
        "        decoder_input = self._add_decoder_input()\n",
        "        dense_layer = self._add_dense_layer(decoder_input)\n",
        "        reshape_layer = self._add_reshape_layer(dense_layer)\n",
        "        conv_transpose_layers = self._add_conv_transpose_layers(reshape_layer)\n",
        "        decoder_output = self._add_decoder_output(conv_transpose_layers)\n",
        "        self.decoder = Model(decoder_input, decoder_output, name=\"decoder\")\n",
        "\n",
        "    def _add_decoder_input(self):\n",
        "        return Input(shape=self.music_latent_space_dim + self.timbre_latent_space_dim, name=\"decoder_input\")\n",
        "\n",
        "    def _add_dense_layer(self, decoder_input):\n",
        "        num_neurons = np.prod(self._shape_before_bottleneck) # [1, 2, 4] -> 8\n",
        "        dense_layer = Dense(num_neurons, name=\"decoder_dense\")(decoder_input)\n",
        "        return dense_layer\n",
        "\n",
        "    def _add_reshape_layer(self, dense_layer):\n",
        "        return Reshape(self._shape_before_bottleneck)(dense_layer)\n",
        "\n",
        "    def _add_conv_transpose_layers(self, x):\n",
        "        \"\"\"Add conv transpose blocks.\"\"\"\n",
        "        # loop through all the conv layers in reverse order and stop at the\n",
        "        # first layer\n",
        "        for layer_index in reversed(range(1, self._num_conv_layers)):\n",
        "            x = self._add_conv_transpose_layer(layer_index, x)\n",
        "        return x\n",
        "\n",
        "    def _add_conv_transpose_layer(self, layer_index, x):\n",
        "        layer_num = self._num_conv_layers - layer_index\n",
        "        conv_transpose_layer = Conv2DTranspose(\n",
        "            filters=self.conv_filters[layer_index],\n",
        "            kernel_size=self.conv_kernels[layer_index],\n",
        "            strides=self.conv_strides[layer_index],\n",
        "            padding=\"same\",\n",
        "            name=f\"decoder_conv_transpose_layer_{layer_num}\"\n",
        "        )\n",
        "        x = conv_transpose_layer(x)\n",
        "        x = ReLU(name=f\"decoder_relu_{layer_num}\")(x)\n",
        "        x = BatchNormalization(name=f\"decoder_bn_{layer_num}\")(x)\n",
        "        return x\n",
        "\n",
        "    def _add_decoder_output(self, x):\n",
        "        conv_transpose_layer = Conv2DTranspose(\n",
        "            filters=1,\n",
        "            kernel_size=self.conv_kernels[0],\n",
        "            strides=self.conv_strides[0],\n",
        "            padding=\"same\",\n",
        "            name=f\"decoder_conv_transpose_layer_{self._num_conv_layers}\"\n",
        "        )\n",
        "        x = conv_transpose_layer(x)\n",
        "        output_layer = Activation(\"sigmoid\", name=\"sigmoid_layer\")(x)\n",
        "        return output_layer\n",
        "\n",
        "    def _build_encoder(self):\n",
        "        timbre_input = self._add_timbre_input()\n",
        "        music_input = self._add_music_input()\n",
        "\n",
        "        conv_layers = self._add_conv_layers(timbre_input)\n",
        "        # Join here\n",
        "        timbre_bottleneck = self._add_bottleneck(conv_layers)\n",
        "        bottleneck = concatenate([timbre_bottleneck, music_input])\n",
        "        self._model_input = [timbre_input, music_input]\n",
        "        self.encoder = Model(inputs=self._model_input, outputs=bottleneck, name=\"encoder\")\n",
        "\n",
        "    def _add_timbre_input(self):\n",
        "        return Input(shape=self.timbre_input_shape, name=\"timbre_input\")\n",
        "\n",
        "    def _add_music_input(self):\n",
        "        return Input(shape=self.music_input_shape, name=\"music_input\")\n",
        "\n",
        "    def _add_conv_layers(self, encoder_input):\n",
        "        \"\"\"Create all convolutional blocks in encoder.\"\"\"\n",
        "        x = encoder_input\n",
        "        for layer_index in range(self._num_conv_layers):\n",
        "            x = self._add_conv_layer(layer_index, x)\n",
        "        return x\n",
        "\n",
        "    def _add_conv_layer(self, layer_index, x):\n",
        "        \"\"\"Add a convolutional block to a graph of layers, consisting of\n",
        "        conv 2d + ReLU + batch normalization.\n",
        "        \"\"\"\n",
        "        layer_number = layer_index + 1\n",
        "        conv_layer = Conv2D(\n",
        "            filters=self.conv_filters[layer_index],\n",
        "            kernel_size=self.conv_kernels[layer_index],\n",
        "            strides=self.conv_strides[layer_index],\n",
        "            padding=\"same\",\n",
        "            name=f\"encoder_conv_layer_{layer_number}\"\n",
        "        )\n",
        "        x = conv_layer(x)\n",
        "        x = ReLU(name=f\"encoder_relu_{layer_number}\")(x)\n",
        "        x = BatchNormalization(name=f\"encoder_bn_{layer_number}\")(x)\n",
        "        return x\n",
        "\n",
        "    def _add_bottleneck(self, x):\n",
        "        \"\"\"Flatten data and add bottleneck with Guassian sampling (Dense\n",
        "        layer).\n",
        "        \"\"\"\n",
        "        self._shape_before_bottleneck = K.int_shape(x)[1:]\n",
        "        x = Flatten()(x)\n",
        "        self.mu = Dense(self.timbre_latent_space_dim, name=\"mu\")(x)\n",
        "        self.log_variance = Dense(self.timbre_latent_space_dim,\n",
        "                                  name=\"log_variance\")(x)\n",
        "\n",
        "        def sample_point_from_normal_distribution(args):\n",
        "            mu, log_variance = args\n",
        "            epsilon = K.random_normal(shape=K.shape(self.mu), mean=0.,\n",
        "                                      stddev=1.)\n",
        "            sampled_point = mu + K.exp(log_variance / 2) * epsilon\n",
        "            return sampled_point\n",
        "\n",
        "        x = Lambda(sample_point_from_normal_distribution,\n",
        "                   name=\"encoder_output\")([self.mu, self.log_variance])\n",
        "        return x\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwpH8-kffCJP"
      },
      "source": [
        "## Data Generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqXQrrOGfbi_"
      },
      "source": [
        "### Data generator code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xqdOkoUfFyu"
      },
      "source": [
        "import re\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Number of Reamped Clips (ampids): 80\n",
        "# Number of (Sub)clips each Reamped Clip(clipids): 12\n",
        "# Number of windows each Clip(windowid): different for clip:\n",
        "#     1: 13\n",
        "#     2: 12\n",
        "#     3: 13\n",
        "#     4: 11\n",
        "#     5: 11\n",
        "#     6: 14\n",
        "#     7: 11\n",
        "#     8: 14\n",
        "#     9: 11\n",
        "#     10: 08\n",
        "#     11: 09\n",
        "#     12: 15\n",
        "\n",
        "# Null Spectrograms/Windows. To be disregarded while training\n",
        "# 01-12\n",
        "# 04-10\n",
        "# 06-00\n",
        "# 07-10\n",
        "# 08-13\n",
        "# 11-08\n",
        "# 12-14\n",
        "\n",
        "def get_valid_files(spectrograms_path, ampids, clipids):\n",
        "\n",
        "    # Error checking\n",
        "    # ampid check: 1-80\n",
        "    invalidampids = [i for i in ampids if i>80 or i<1]\n",
        "    if len(invalidampids) > 0:\n",
        "        raise Exception(\"Invalid ampids: \" + str(invalidampids))\n",
        "    # clipid check: 1-12\n",
        "    invalidclipids = [i for i in clipids if i>12 or i<1]\n",
        "    if len(invalidclipids) > 0:\n",
        "        raise Exception(\"Invalid clipids: \" + str(invalidclipids))\n",
        "\n",
        "    clips_to_remove = [\"01-12\", \"04-10\", \"06-00\", \"07-10\", \"08-13\", \"11-08\", \"12-14\"]\n",
        "    # Actual DS creation\n",
        "    for root, _, filenames in os.walk(spectrograms_path):\n",
        "\n",
        "        ds = []\n",
        "        for filename in filenames:\n",
        "            fn_split = filename.split(\" \")[0].split(\"-\")\n",
        "\n",
        "            ampid = int(fn_split[0])\n",
        "            clipid = int(fn_split[1])\n",
        "            windowid = int(fn_split[2])\n",
        "\n",
        "            regex = \"^(?!00000.*$).*\"\n",
        "            if re.match(regex, filename) and (ampid in ampids and clipid in clipids) and (\"%02d\" % clipid + \"-\" + \"%02d\" % windowid) not in clips_to_remove:\n",
        "                ds.append(filename)\n",
        "    return sorted(ds)\n",
        "\n",
        "def get_music_embeddings_dict(model_path, embeddings_file, filenames_file):\n",
        "    filenames = []\n",
        "    with open(os.path.join(model_path, filenames_file), 'r') as f:\n",
        "        r = csv.reader(f, delimiter='\\t')\n",
        "        for row in r:\n",
        "            filenames.append(row[0])\n",
        "    vec = []\n",
        "    with open(os.path.join(model_path, embeddings_file), 'r') as f:\n",
        "        r = csv.reader(f, delimiter='\\t')\n",
        "        for row in r:\n",
        "            float_row = [float(i) for i in row]\n",
        "            vec.append(float_row)\n",
        "\n",
        "    d_name_vec = {}\n",
        "    for i in range(0, len(filenames)):\n",
        "        d_name_vec[filenames[i]] = vec[i]\n",
        "\n",
        "    return d_name_vec\n",
        "\n",
        "def music_ds_generator(d_name_vec, spectrograms_path, filenames, batchsize, return_filenames=False):\n",
        "        i = 0\n",
        "        dslen = len(filenames)\n",
        "        while True:\n",
        "            x, mvecs, xfiles = [], [], []\n",
        "\n",
        "            st = i\n",
        "            end = (i + batchsize) % dslen\n",
        "            i = (end ) % dslen\n",
        "            \n",
        "            if end < st:\n",
        "                xfiles = filenames[st:dslen]\n",
        "                xfiles.extend(filenames[0:end])\n",
        "            else:\n",
        "                xfiles = filenames[st: end]\n",
        "        \n",
        "            for filename in xfiles:\n",
        "                filepath = os.path.join(spectrograms_path, filename)\n",
        "                \n",
        "                spectrogram = np.load(filepath)\n",
        "                mvec = d_name_vec[filename]\n",
        "                \n",
        "                x.append(spectrogram[..., np.newaxis])\n",
        "                mvecs.append(mvec)\n",
        "            if return_filenames:\n",
        "                yield (((np.array(x), np.array(mvecs)), np.array(x)), xfiles)\n",
        "            else:\n",
        "                yield ((np.array(x), np.array(mvecs)), np.array(x))\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xjx81E8fY6i"
      },
      "source": [
        "### Driver for data generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKfOa7B4fYUt",
        "outputId": "33fac03d-7bd0-4c49-af58-65f80a11ea4d"
      },
      "source": [
        "SPECTROGRAMS_PATH = \"/content/drive/MyDrive/Music/VAE/ICASSP/spectrogram\"\n",
        "TIMBREAE_SAVE_PATH = \"/content/drive/MyDrive/Music/VAE/ICASSP/timbre-encoder/\"\n",
        "MUSICAE_SAVE_PATH = \"/content/drive/MyDrive/Music/VAE/ICASSP/music-encoder/\"\n",
        "\n",
        "TIMBREAE_MODEL_PATH = os.path.join(TIMBREAE_SAVE_PATH, \"model\")\n",
        "MUSICAE_MODEL_PATH = os.path.join(MUSICAE_SAVE_PATH, \"model\")\n",
        "\n",
        "EMBEDDINGS_FILE = \"embeddings-2021-10-04-06-08-29.tsv\"\n",
        "FILENAMES_FILE = \"embedding-filenames-2021-10-04-06-08-29.tsv\"\n",
        "\n",
        "AMP_IDS = [i for i in range(1, 81)] # 1-80\n",
        "CLIP_IDS = [i for i in range(1, 13)] # 1-12\n",
        "BATCH_SIZE = 27\n",
        "\n",
        "dsfilenames = get_valid_files(SPECTROGRAMS_PATH, AMP_IDS, CLIP_IDS)\n",
        "dslen = len(dsfilenames)\n",
        "print(\"Total dataset size: \" + str(dslen))\n",
        "\n",
        "d_name_vec = get_music_embeddings_dict(MUSICAE_MODEL_PATH, EMBEDDINGS_FILE, FILENAMES_FILE)\n",
        "\n",
        "musicds_gen = music_ds_generator(d_name_vec, SPECTROGRAMS_PATH, dsfilenames, BATCH_SIZE, False)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total dataset size: 10800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmj4WCwVsZit"
      },
      "source": [
        "i =0\n",
        "for m in musicds_gen:\n",
        "    print(np.shape(m[0][0]))    \n",
        "    print(np.shape(m[0][1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoxtrbGxba-l"
      },
      "source": [
        "## Timbre AutoEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEqY1PrYmAQT"
      },
      "source": [
        "### Instantiate Or Load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrEmr1d2mC7g",
        "outputId": "b1973c79-27ba-4275-cead-4d12ded6ac0f"
      },
      "source": [
        "TIMBREAE_SAVE_PATH = \"/content/drive/MyDrive/Music/VAE/ICASSP/timbre-encoder/\"\n",
        "TIMBREAE_MODEL_PATH = os.path.join(TIMBREAE_SAVE_PATH, \"model\")\n",
        "LEARNING_RATE = 0.0001\n",
        "\n",
        "timbreae = VAE.load(TIMBREAE_MODEL_PATH, 'weights.h5')\n",
        "\n",
        "if timbreae == None:\n",
        "    print(\"Instantiating the model\")\n",
        "    MUSIC_LATENT_SPACE_DIM= 16\n",
        "    TIMBRE_LATENT_SPACE_DIM= 4\n",
        "    CONV_FILTERS = (128, 64, 32, 32)\n",
        "    CONV_KERNELS = (3, 3, 3, 3)\n",
        "    CONV_STRIDES = (1, 2, 2, 1)\n",
        "\n",
        "    timbreae = VAE(\n",
        "        timbre_input_shape= (256, 64, 1),\n",
        "        music_input_shape= (16, ),\n",
        "        conv_filters= CONV_FILTERS, \n",
        "        conv_kernels= CONV_KERNELS,\n",
        "        conv_strides= CONV_STRIDES,\n",
        "        music_latent_space_dim=MUSIC_LATENT_SPACE_DIM,\n",
        "        timbre_latent_space_dim=TIMBRE_LATENT_SPACE_DIM\n",
        "    )\n",
        "    timbreae.save_parameters(TIMBREAE_MODEL_PATH)\n",
        "\n",
        "timbreae.compile(LEARNING_RATE)\n",
        "timbreae.summary()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instantiating the model\n",
            "[(256, 64, 1), (16,), (128, 64, 32, 32), (3, 3, 3, 3), (1, 2, 2, 1), 16, 4]\n",
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "timbre_input (InputLayer)       [(None, 256, 64, 1)] 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "encoder_conv_layer_1 (Conv2D)   (None, 256, 64, 128) 1280        timbre_input[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "encoder_relu_1 (ReLU)           (None, 256, 64, 128) 0           encoder_conv_layer_1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "encoder_bn_1 (BatchNormalizatio (None, 256, 64, 128) 512         encoder_relu_1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "encoder_conv_layer_2 (Conv2D)   (None, 128, 32, 64)  73792       encoder_bn_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "encoder_relu_2 (ReLU)           (None, 128, 32, 64)  0           encoder_conv_layer_2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "encoder_bn_2 (BatchNormalizatio (None, 128, 32, 64)  256         encoder_relu_2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "encoder_conv_layer_3 (Conv2D)   (None, 64, 16, 32)   18464       encoder_bn_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "encoder_relu_3 (ReLU)           (None, 64, 16, 32)   0           encoder_conv_layer_3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "encoder_bn_3 (BatchNormalizatio (None, 64, 16, 32)   128         encoder_relu_3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "encoder_conv_layer_4 (Conv2D)   (None, 64, 16, 32)   9248        encoder_bn_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "encoder_relu_4 (ReLU)           (None, 64, 16, 32)   0           encoder_conv_layer_4[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "encoder_bn_4 (BatchNormalizatio (None, 64, 16, 32)   128         encoder_relu_4[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_11 (Flatten)            (None, 32768)        0           encoder_bn_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "mu (Dense)                      (None, 4)            131076      flatten_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "log_variance (Dense)            (None, 4)            131076      flatten_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "encoder_output (Lambda)         (None, 4)            0           mu[0][0]                         \n",
            "                                                                 log_variance[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "music_input (InputLayer)        [(None, 16)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 20)           0           encoder_output[0][0]             \n",
            "                                                                 music_input[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 365,960\n",
            "Trainable params: 365,448\n",
            "Non-trainable params: 512\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "decoder_input (InputLayer)   [(None, 20)]              0         \n",
            "_________________________________________________________________\n",
            "decoder_dense (Dense)        (None, 32768)             688128    \n",
            "_________________________________________________________________\n",
            "reshape_7 (Reshape)          (None, 64, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "decoder_conv_transpose_layer (None, 64, 16, 32)        9248      \n",
            "_________________________________________________________________\n",
            "decoder_relu_1 (ReLU)        (None, 64, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "decoder_bn_1 (BatchNormaliza (None, 64, 16, 32)        128       \n",
            "_________________________________________________________________\n",
            "decoder_conv_transpose_layer (None, 128, 32, 32)       9248      \n",
            "_________________________________________________________________\n",
            "decoder_relu_2 (ReLU)        (None, 128, 32, 32)       0         \n",
            "_________________________________________________________________\n",
            "decoder_bn_2 (BatchNormaliza (None, 128, 32, 32)       128       \n",
            "_________________________________________________________________\n",
            "decoder_conv_transpose_layer (None, 256, 64, 64)       18496     \n",
            "_________________________________________________________________\n",
            "decoder_relu_3 (ReLU)        (None, 256, 64, 64)       0         \n",
            "_________________________________________________________________\n",
            "decoder_bn_3 (BatchNormaliza (None, 256, 64, 64)       256       \n",
            "_________________________________________________________________\n",
            "decoder_conv_transpose_layer (None, 256, 64, 1)        577       \n",
            "_________________________________________________________________\n",
            "sigmoid_layer (Activation)   (None, 256, 64, 1)        0         \n",
            "=================================================================\n",
            "Total params: 726,209\n",
            "Trainable params: 725,953\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n",
            "Model: \"autoencoder\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "timbre_input (InputLayer)       [(None, 256, 64, 1)] 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "music_input (InputLayer)        [(None, 16)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "encoder (Functional)            (None, 20)           365960      timbre_input[0][0]               \n",
            "                                                                 music_input[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "decoder (Functional)            (None, 256, 64, 1)   726209      encoder[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 1,092,169\n",
            "Trainable params: 1,091,401\n",
            "Non-trainable params: 768\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IezgTIyXpXOz"
      },
      "source": [
        "### Train Model (Iterative)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2cOkawppZ95",
        "outputId": "589feec5-6dd4-4bdd-b139-befe9102f451"
      },
      "source": [
        "import pytz\n",
        "from datetime import datetime\n",
        "\n",
        "EPOCHS = 500\n",
        "TIMBREAE_SAVE_PATH = \"/content/drive/MyDrive/Music/VAE/ICASSP/timbre-encoder/\"\n",
        "TIMBREAE_MODEL_PATH = os.path.join(TIMBREAE_SAVE_PATH, \"model\")\n",
        "\n",
        "ts = pytz.timezone('Asia/Tokyo').localize(datetime.now())\n",
        "tsf = ts.strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
        "CHECKPOINT_PATH = os.path.join(TIMBREAE_MODEL_PATH, \"checkpoints-\" + tsf)\n",
        "\n",
        "if not os.path.exists(CHECKPOINT_PATH):\n",
        "    os.makedirs(CHECKPOINT_PATH)\n",
        "\n",
        "class CustomCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        save_checkpoint_path = os.path.join(CHECKPOINT_PATH, \"weights-{}.h5\".format(epoch))\n",
        "        save_path = os.path.join(TIMBREAE_MODEL_PATH, \"weights.h5\")\n",
        "        self.model.save_weights(save_checkpoint_path)\n",
        "        self.model.save_weights(save_path)\n",
        "\n",
        "history = timbreae.train(\n",
        "    generator=musicds_gen, \n",
        "    dataset_length=dslen,\n",
        "    batch_size=BATCH_SIZE, \n",
        "    num_epochs=EPOCHS,\n",
        "    callbacks=[CustomCallback()]\n",
        "    )\n",
        "losses = history.history['loss']\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 8706.8106 - _calculate_reconstruction_loss: 0.0084 - _calculate_kl_loss: 257.4191\n",
            "Epoch 2/500\n",
            "400/400 [==============================] - 41s 102ms/step - batch: 199.5000 - size: 27.0000 - loss: 8349.6759 - _calculate_reconstruction_loss: 0.0081 - _calculate_kl_loss: 243.3278\n",
            "Epoch 3/500\n",
            "400/400 [==============================] - 41s 102ms/step - batch: 199.5000 - size: 27.0000 - loss: 8531.2483 - _calculate_reconstruction_loss: 0.0083 - _calculate_kl_loss: 246.1919\n",
            "Epoch 4/500\n",
            "400/400 [==============================] - 41s 102ms/step - batch: 199.5000 - size: 27.0000 - loss: 9254.6054 - _calculate_reconstruction_loss: 0.0089 - _calculate_kl_loss: 321.4472\n",
            "Epoch 5/500\n",
            "400/400 [==============================] - 41s 102ms/step - batch: 199.5000 - size: 27.0000 - loss: 8571.4451 - _calculate_reconstruction_loss: 0.0083 - _calculate_kl_loss: 286.8864\n",
            "Epoch 6/500\n",
            "400/400 [==============================] - 41s 102ms/step - batch: 199.5000 - size: 27.0000 - loss: 8240.5675 - _calculate_reconstruction_loss: 0.0080 - _calculate_kl_loss: 272.7903\n",
            "Epoch 7/500\n",
            "400/400 [==============================] - 41s 102ms/step - batch: 199.5000 - size: 27.0000 - loss: 7919.3168 - _calculate_reconstruction_loss: 0.0077 - _calculate_kl_loss: 258.5442\n",
            "Epoch 8/500\n",
            "400/400 [==============================] - 41s 102ms/step - batch: 199.5000 - size: 27.0000 - loss: 7703.6613 - _calculate_reconstruction_loss: 0.0075 - _calculate_kl_loss: 236.4261\n",
            "Epoch 9/500\n",
            "400/400 [==============================] - 41s 102ms/step - batch: 199.5000 - size: 27.0000 - loss: 7556.1282 - _calculate_reconstruction_loss: 0.0073 - _calculate_kl_loss: 234.8286\n",
            "Epoch 10/500\n",
            "400/400 [==============================] - 41s 102ms/step - batch: 199.5000 - size: 27.0000 - loss: 7744.0202 - _calculate_reconstruction_loss: 0.0075 - _calculate_kl_loss: 254.7537\n",
            "Epoch 11/500\n",
            "400/400 [==============================] - 41s 102ms/step - batch: 199.5000 - size: 27.0000 - loss: 7859.3036 - _calculate_reconstruction_loss: 0.0076 - _calculate_kl_loss: 260.7249\n",
            "Epoch 12/500\n",
            "400/400 [==============================] - 41s 102ms/step - batch: 199.5000 - size: 27.0000 - loss: 7504.4196 - _calculate_reconstruction_loss: 0.0072 - _calculate_kl_loss: 259.9973\n",
            "Epoch 13/500\n",
            "400/400 [==============================] - 41s 102ms/step - batch: 199.5000 - size: 27.0000 - loss: 7225.8541 - _calculate_reconstruction_loss: 0.0070 - _calculate_kl_loss: 243.8803\n",
            "Epoch 14/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 7207.3852 - _calculate_reconstruction_loss: 0.0070 - _calculate_kl_loss: 230.9550\n",
            "Epoch 15/500\n",
            "400/400 [==============================] - 41s 102ms/step - batch: 199.5000 - size: 27.0000 - loss: 7383.4200 - _calculate_reconstruction_loss: 0.0071 - _calculate_kl_loss: 240.5891\n",
            "Epoch 16/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 7387.7010 - _calculate_reconstruction_loss: 0.0071 - _calculate_kl_loss: 242.2227\n",
            "Epoch 17/500\n",
            "400/400 [==============================] - 41s 102ms/step - batch: 199.5000 - size: 27.0000 - loss: 7041.8652 - _calculate_reconstruction_loss: 0.0068 - _calculate_kl_loss: 225.6593\n",
            "Epoch 18/500\n",
            "400/400 [==============================] - 41s 102ms/step - batch: 199.5000 - size: 27.0000 - loss: 7027.9296 - _calculate_reconstruction_loss: 0.0068 - _calculate_kl_loss: 228.3061\n",
            "Epoch 19/500\n",
            "400/400 [==============================] - 41s 102ms/step - batch: 199.5000 - size: 27.0000 - loss: 6933.1745 - _calculate_reconstruction_loss: 0.0067 - _calculate_kl_loss: 216.1609\n",
            "Epoch 20/500\n",
            "400/400 [==============================] - 41s 102ms/step - batch: 199.5000 - size: 27.0000 - loss: 7020.4228 - _calculate_reconstruction_loss: 0.0068 - _calculate_kl_loss: 224.8479\n",
            "Epoch 21/500\n",
            "400/400 [==============================] - 41s 102ms/step - batch: 199.5000 - size: 27.0000 - loss: 7091.0321 - _calculate_reconstruction_loss: 0.0069 - _calculate_kl_loss: 230.1237\n",
            "Epoch 22/500\n",
            "400/400 [==============================] - 41s 102ms/step - batch: 199.5000 - size: 27.0000 - loss: 7595.8683 - _calculate_reconstruction_loss: 0.0072 - _calculate_kl_loss: 362.9447\n",
            "Epoch 23/500\n",
            "400/400 [==============================] - 41s 102ms/step - batch: 199.5000 - size: 27.0000 - loss: 7496.8967 - _calculate_reconstruction_loss: 0.0072 - _calculate_kl_loss: 267.4820\n",
            "Epoch 24/500\n",
            "400/400 [==============================] - 41s 102ms/step - batch: 199.5000 - size: 27.0000 - loss: 7220.1075 - _calculate_reconstruction_loss: 0.0070 - _calculate_kl_loss: 268.6191\n",
            "Epoch 25/500\n",
            "400/400 [==============================] - 41s 102ms/step - batch: 199.5000 - size: 27.0000 - loss: 7038.2535 - _calculate_reconstruction_loss: 0.0068 - _calculate_kl_loss: 243.3739\n",
            "Epoch 26/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 7012.2657 - _calculate_reconstruction_loss: 0.0067 - _calculate_kl_loss: 269.4807\n",
            "Epoch 27/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 6812.5209 - _calculate_reconstruction_loss: 0.0066 - _calculate_kl_loss: 243.1844\n",
            "Epoch 28/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 6889.0318 - _calculate_reconstruction_loss: 0.0067 - _calculate_kl_loss: 234.8221\n",
            "Epoch 29/500\n",
            "400/400 [==============================] - 41s 102ms/step - batch: 199.5000 - size: 27.0000 - loss: 6798.8745 - _calculate_reconstruction_loss: 0.0066 - _calculate_kl_loss: 238.5867\n",
            "Epoch 30/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 6796.1998 - _calculate_reconstruction_loss: 0.0066 - _calculate_kl_loss: 231.2121\n",
            "Epoch 31/500\n",
            "400/400 [==============================] - 41s 102ms/step - batch: 199.5000 - size: 27.0000 - loss: 6860.5169 - _calculate_reconstruction_loss: 0.0066 - _calculate_kl_loss: 225.2014\n",
            "Epoch 32/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 6819.3047 - _calculate_reconstruction_loss: 0.0066 - _calculate_kl_loss: 235.4295\n",
            "Epoch 33/500\n",
            "400/400 [==============================] - 41s 102ms/step - batch: 199.5000 - size: 27.0000 - loss: 6697.9724 - _calculate_reconstruction_loss: 0.0065 - _calculate_kl_loss: 221.9813\n",
            "Epoch 34/500\n",
            "400/400 [==============================] - 41s 102ms/step - batch: 199.5000 - size: 27.0000 - loss: 6604.5287 - _calculate_reconstruction_loss: 0.0064 - _calculate_kl_loss: 203.7495\n",
            "Epoch 35/500\n",
            "400/400 [==============================] - 41s 102ms/step - batch: 199.5000 - size: 27.0000 - loss: 6585.1959 - _calculate_reconstruction_loss: 0.0064 - _calculate_kl_loss: 200.7745\n",
            "Epoch 36/500\n",
            "400/400 [==============================] - 41s 102ms/step - batch: 199.5000 - size: 27.0000 - loss: 6633.3852 - _calculate_reconstruction_loss: 0.0064 - _calculate_kl_loss: 201.0040\n",
            "Epoch 37/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 6620.2918 - _calculate_reconstruction_loss: 0.0064 - _calculate_kl_loss: 206.6872\n",
            "Epoch 38/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 6660.5676 - _calculate_reconstruction_loss: 0.0065 - _calculate_kl_loss: 209.4880\n",
            "Epoch 39/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 6501.2058 - _calculate_reconstruction_loss: 0.0063 - _calculate_kl_loss: 211.1940\n",
            "Epoch 40/500\n",
            "400/400 [==============================] - 41s 102ms/step - batch: 199.5000 - size: 27.0000 - loss: 6399.4219 - _calculate_reconstruction_loss: 0.0062 - _calculate_kl_loss: 196.8439\n",
            "Epoch 41/500\n",
            "400/400 [==============================] - 41s 102ms/step - batch: 199.5000 - size: 27.0000 - loss: 6550.5748 - _calculate_reconstruction_loss: 0.0064 - _calculate_kl_loss: 194.3236\n",
            "Epoch 42/500\n",
            "400/400 [==============================] - 41s 102ms/step - batch: 199.5000 - size: 27.0000 - loss: 6560.9371 - _calculate_reconstruction_loss: 0.0064 - _calculate_kl_loss: 192.8619\n",
            "Epoch 43/500\n",
            "400/400 [==============================] - 41s 102ms/step - batch: 199.5000 - size: 27.0000 - loss: 6591.2170 - _calculate_reconstruction_loss: 0.0064 - _calculate_kl_loss: 190.4798\n",
            "Epoch 44/500\n",
            "400/400 [==============================] - 41s 102ms/step - batch: 199.5000 - size: 27.0000 - loss: 6400.6876 - _calculate_reconstruction_loss: 0.0062 - _calculate_kl_loss: 194.3694\n",
            "Epoch 45/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 6442.8967 - _calculate_reconstruction_loss: 0.0063 - _calculate_kl_loss: 187.4743\n",
            "Epoch 46/500\n",
            "400/400 [==============================] - 41s 102ms/step - batch: 199.5000 - size: 27.0000 - loss: 6344.1545 - _calculate_reconstruction_loss: 0.0062 - _calculate_kl_loss: 182.2523\n",
            "Epoch 47/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 6324.8236 - _calculate_reconstruction_loss: 0.0061 - _calculate_kl_loss: 180.3683\n",
            "Epoch 48/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 6178.9507 - _calculate_reconstruction_loss: 0.0060 - _calculate_kl_loss: 166.9750\n",
            "Epoch 49/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 6114.8130 - _calculate_reconstruction_loss: 0.0060 - _calculate_kl_loss: 158.6374\n",
            "Epoch 50/500\n",
            "400/400 [==============================] - 41s 102ms/step - batch: 199.5000 - size: 27.0000 - loss: 6142.9550 - _calculate_reconstruction_loss: 0.0060 - _calculate_kl_loss: 158.6051\n",
            "Epoch 51/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 6300.1132 - _calculate_reconstruction_loss: 0.0061 - _calculate_kl_loss: 169.6951\n",
            "Epoch 52/500\n",
            "400/400 [==============================] - 41s 102ms/step - batch: 199.5000 - size: 27.0000 - loss: 6248.5812 - _calculate_reconstruction_loss: 0.0061 - _calculate_kl_loss: 163.1259\n",
            "Epoch 53/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 6483.2122 - _calculate_reconstruction_loss: 0.0063 - _calculate_kl_loss: 171.6911\n",
            "Epoch 54/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 6121.7022 - _calculate_reconstruction_loss: 0.0059 - _calculate_kl_loss: 173.4103\n",
            "Epoch 55/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 6070.8195 - _calculate_reconstruction_loss: 0.0059 - _calculate_kl_loss: 167.9917\n",
            "Epoch 56/500\n",
            "400/400 [==============================] - 41s 102ms/step - batch: 199.5000 - size: 27.0000 - loss: 8170.0880 - _calculate_reconstruction_loss: 0.0064 - _calculate_kl_loss: 1775.9822\n",
            "Epoch 57/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 7008.4236 - _calculate_reconstruction_loss: 0.0068 - _calculate_kl_loss: 222.2879\n",
            "Epoch 58/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 6680.6566 - _calculate_reconstruction_loss: 0.0065 - _calculate_kl_loss: 226.9881\n",
            "Epoch 59/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 6311.3368 - _calculate_reconstruction_loss: 0.0061 - _calculate_kl_loss: 203.7116\n",
            "Epoch 60/500\n",
            "400/400 [==============================] - 41s 102ms/step - batch: 199.5000 - size: 27.0000 - loss: 6109.0791 - _calculate_reconstruction_loss: 0.0059 - _calculate_kl_loss: 187.0162\n",
            "Epoch 61/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5992.4044 - _calculate_reconstruction_loss: 0.0058 - _calculate_kl_loss: 175.0437\n",
            "Epoch 62/500\n",
            "400/400 [==============================] - 41s 102ms/step - batch: 199.5000 - size: 27.0000 - loss: 5922.3334 - _calculate_reconstruction_loss: 0.0058 - _calculate_kl_loss: 172.0479\n",
            "Epoch 63/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 6083.5021 - _calculate_reconstruction_loss: 0.0059 - _calculate_kl_loss: 178.8431\n",
            "Epoch 64/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 6304.5507 - _calculate_reconstruction_loss: 0.0061 - _calculate_kl_loss: 187.1178\n",
            "Epoch 65/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 6267.7686 - _calculate_reconstruction_loss: 0.0061 - _calculate_kl_loss: 191.3646\n",
            "Epoch 66/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 6036.9615 - _calculate_reconstruction_loss: 0.0059 - _calculate_kl_loss: 184.5903\n",
            "Epoch 67/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5921.8787 - _calculate_reconstruction_loss: 0.0057 - _calculate_kl_loss: 173.3691\n",
            "Epoch 68/500\n",
            "400/400 [==============================] - 41s 102ms/step - batch: 199.5000 - size: 27.0000 - loss: 5859.2528 - _calculate_reconstruction_loss: 0.0057 - _calculate_kl_loss: 167.8208\n",
            "Epoch 69/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5744.7812 - _calculate_reconstruction_loss: 0.0056 - _calculate_kl_loss: 157.6099\n",
            "Epoch 70/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5841.0128 - _calculate_reconstruction_loss: 0.0057 - _calculate_kl_loss: 152.3503\n",
            "Epoch 71/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5955.1225 - _calculate_reconstruction_loss: 0.0058 - _calculate_kl_loss: 156.7241\n",
            "Epoch 72/500\n",
            "400/400 [==============================] - 41s 102ms/step - batch: 199.5000 - size: 27.0000 - loss: 6103.7320 - _calculate_reconstruction_loss: 0.0059 - _calculate_kl_loss: 169.9745\n",
            "Epoch 73/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5933.5882 - _calculate_reconstruction_loss: 0.0058 - _calculate_kl_loss: 165.1040\n",
            "Epoch 74/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5951.8644 - _calculate_reconstruction_loss: 0.0058 - _calculate_kl_loss: 163.6463\n",
            "Epoch 75/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5919.3632 - _calculate_reconstruction_loss: 0.0058 - _calculate_kl_loss: 162.4034\n",
            "Epoch 76/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5870.9659 - _calculate_reconstruction_loss: 0.0057 - _calculate_kl_loss: 158.7291\n",
            "Epoch 77/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5841.4662 - _calculate_reconstruction_loss: 0.0057 - _calculate_kl_loss: 152.7686\n",
            "Epoch 78/500\n",
            "400/400 [==============================] - 41s 102ms/step - batch: 199.5000 - size: 27.0000 - loss: 5734.5026 - _calculate_reconstruction_loss: 0.0056 - _calculate_kl_loss: 151.7112\n",
            "Epoch 79/500\n",
            "400/400 [==============================] - 41s 102ms/step - batch: 199.5000 - size: 27.0000 - loss: 5699.2263 - _calculate_reconstruction_loss: 0.0056 - _calculate_kl_loss: 146.5455\n",
            "Epoch 80/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5746.5725 - _calculate_reconstruction_loss: 0.0056 - _calculate_kl_loss: 140.7655\n",
            "Epoch 81/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 6025.9484 - _calculate_reconstruction_loss: 0.0058 - _calculate_kl_loss: 182.6898\n",
            "Epoch 82/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5862.8513 - _calculate_reconstruction_loss: 0.0057 - _calculate_kl_loss: 168.0263\n",
            "Epoch 83/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5744.7220 - _calculate_reconstruction_loss: 0.0056 - _calculate_kl_loss: 166.0495\n",
            "Epoch 84/500\n",
            "400/400 [==============================] - 41s 102ms/step - batch: 199.5000 - size: 27.0000 - loss: 5722.6243 - _calculate_reconstruction_loss: 0.0056 - _calculate_kl_loss: 157.5655\n",
            "Epoch 85/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5580.6917 - _calculate_reconstruction_loss: 0.0054 - _calculate_kl_loss: 153.7186\n",
            "Epoch 86/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5608.7311 - _calculate_reconstruction_loss: 0.0055 - _calculate_kl_loss: 149.2047\n",
            "Epoch 87/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5673.9108 - _calculate_reconstruction_loss: 0.0055 - _calculate_kl_loss: 153.7394\n",
            "Epoch 88/500\n",
            "400/400 [==============================] - 41s 102ms/step - batch: 199.5000 - size: 27.0000 - loss: 5591.5104 - _calculate_reconstruction_loss: 0.0054 - _calculate_kl_loss: 144.8768\n",
            "Epoch 89/500\n",
            "400/400 [==============================] - 41s 102ms/step - batch: 199.5000 - size: 27.0000 - loss: 5685.6280 - _calculate_reconstruction_loss: 0.0055 - _calculate_kl_loss: 141.6499\n",
            "Epoch 90/500\n",
            "400/400 [==============================] - 41s 102ms/step - batch: 199.5000 - size: 27.0000 - loss: 5796.8355 - _calculate_reconstruction_loss: 0.0057 - _calculate_kl_loss: 141.2135\n",
            "Epoch 91/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5786.2935 - _calculate_reconstruction_loss: 0.0056 - _calculate_kl_loss: 141.7307\n",
            "Epoch 92/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5648.8909 - _calculate_reconstruction_loss: 0.0055 - _calculate_kl_loss: 134.1525\n",
            "Epoch 93/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5702.4683 - _calculate_reconstruction_loss: 0.0056 - _calculate_kl_loss: 140.7913\n",
            "Epoch 94/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5580.8206 - _calculate_reconstruction_loss: 0.0054 - _calculate_kl_loss: 140.0502\n",
            "Epoch 95/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5636.0460 - _calculate_reconstruction_loss: 0.0055 - _calculate_kl_loss: 136.1080\n",
            "Epoch 96/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5674.6057 - _calculate_reconstruction_loss: 0.0055 - _calculate_kl_loss: 132.6038\n",
            "Epoch 97/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5573.7228 - _calculate_reconstruction_loss: 0.0054 - _calculate_kl_loss: 125.0030\n",
            "Epoch 98/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5614.3294 - _calculate_reconstruction_loss: 0.0055 - _calculate_kl_loss: 126.1741\n",
            "Epoch 99/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5651.0058 - _calculate_reconstruction_loss: 0.0055 - _calculate_kl_loss: 128.5673\n",
            "Epoch 100/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5597.7567 - _calculate_reconstruction_loss: 0.0055 - _calculate_kl_loss: 128.6376\n",
            "Epoch 101/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5607.9122 - _calculate_reconstruction_loss: 0.0055 - _calculate_kl_loss: 125.5696\n",
            "Epoch 102/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5619.2189 - _calculate_reconstruction_loss: 0.0055 - _calculate_kl_loss: 122.8215\n",
            "Epoch 103/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5631.4776 - _calculate_reconstruction_loss: 0.0055 - _calculate_kl_loss: 125.4745\n",
            "Epoch 104/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5565.9457 - _calculate_reconstruction_loss: 0.0054 - _calculate_kl_loss: 119.9569\n",
            "Epoch 105/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5486.1005 - _calculate_reconstruction_loss: 0.0054 - _calculate_kl_loss: 115.7977\n",
            "Epoch 106/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5495.0553 - _calculate_reconstruction_loss: 0.0054 - _calculate_kl_loss: 112.0461\n",
            "Epoch 107/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5432.3658 - _calculate_reconstruction_loss: 0.0053 - _calculate_kl_loss: 106.7092\n",
            "Epoch 108/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5390.7884 - _calculate_reconstruction_loss: 0.0053 - _calculate_kl_loss: 104.2542\n",
            "Epoch 109/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5341.9368 - _calculate_reconstruction_loss: 0.0052 - _calculate_kl_loss: 101.0650\n",
            "Epoch 110/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5368.5143 - _calculate_reconstruction_loss: 0.0053 - _calculate_kl_loss: 105.8005\n",
            "Epoch 111/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5458.5036 - _calculate_reconstruction_loss: 0.0054 - _calculate_kl_loss: 106.2933\n",
            "Epoch 112/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5386.6389 - _calculate_reconstruction_loss: 0.0053 - _calculate_kl_loss: 103.1834\n",
            "Epoch 113/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 32182897.8267 - _calculate_reconstruction_loss: 0.0068 - _calculate_kl_loss: 32176058.0000\n",
            "Epoch 114/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 39504.9400 - _calculate_reconstruction_loss: 0.0061 - _calculate_kl_loss: 33443.9609\n",
            "Epoch 115/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 16237.0962 - _calculate_reconstruction_loss: 0.0057 - _calculate_kl_loss: 10547.5967\n",
            "Epoch 116/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 12337.9672 - _calculate_reconstruction_loss: 0.0055 - _calculate_kl_loss: 6853.3135\n",
            "Epoch 117/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 10441.4522 - _calculate_reconstruction_loss: 0.0055 - _calculate_kl_loss: 4897.4229\n",
            "Epoch 118/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 9094.0152 - _calculate_reconstruction_loss: 0.0054 - _calculate_kl_loss: 3663.9907\n",
            "Epoch 119/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 8151.8965 - _calculate_reconstruction_loss: 0.0054 - _calculate_kl_loss: 2790.4897\n",
            "Epoch 120/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 7708.1600 - _calculate_reconstruction_loss: 0.0056 - _calculate_kl_loss: 2111.1663\n",
            "Epoch 121/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 7135.0191 - _calculate_reconstruction_loss: 0.0055 - _calculate_kl_loss: 1641.6555\n",
            "Epoch 122/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 6708.2703 - _calculate_reconstruction_loss: 0.0054 - _calculate_kl_loss: 1340.9843\n",
            "Epoch 123/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 6346.2942 - _calculate_reconstruction_loss: 0.0052 - _calculate_kl_loss: 1096.7954\n",
            "Epoch 124/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 6115.3645 - _calculate_reconstruction_loss: 0.0052 - _calculate_kl_loss: 906.0399\n",
            "Epoch 125/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 6029.7464 - _calculate_reconstruction_loss: 0.0053 - _calculate_kl_loss: 758.7603\n",
            "Epoch 126/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5910.2518 - _calculate_reconstruction_loss: 0.0053 - _calculate_kl_loss: 639.9355\n",
            "Epoch 127/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5967.5687 - _calculate_reconstruction_loss: 0.0054 - _calculate_kl_loss: 550.6934\n",
            "Epoch 128/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 6200.7037 - _calculate_reconstruction_loss: 0.0055 - _calculate_kl_loss: 750.6567\n",
            "Epoch 129/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5825.2149 - _calculate_reconstruction_loss: 0.0054 - _calculate_kl_loss: 383.3066\n",
            "Epoch 130/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5685.3432 - _calculate_reconstruction_loss: 0.0053 - _calculate_kl_loss: 345.0048\n",
            "Epoch 131/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5598.2984 - _calculate_reconstruction_loss: 0.0053 - _calculate_kl_loss: 306.3181\n",
            "Epoch 132/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5432.9862 - _calculate_reconstruction_loss: 0.0052 - _calculate_kl_loss: 268.9969\n",
            "Epoch 133/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5386.3320 - _calculate_reconstruction_loss: 0.0051 - _calculate_kl_loss: 240.9163\n",
            "Epoch 134/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5293.9068 - _calculate_reconstruction_loss: 0.0051 - _calculate_kl_loss: 216.1267\n",
            "Epoch 135/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5359.5724 - _calculate_reconstruction_loss: 0.0052 - _calculate_kl_loss: 201.6689\n",
            "Epoch 136/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5501.2988 - _calculate_reconstruction_loss: 0.0053 - _calculate_kl_loss: 190.7523\n",
            "Epoch 137/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5468.6376 - _calculate_reconstruction_loss: 0.0053 - _calculate_kl_loss: 179.9450\n",
            "Epoch 138/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5544.0393 - _calculate_reconstruction_loss: 0.0054 - _calculate_kl_loss: 178.3542\n",
            "Epoch 139/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5432.1038 - _calculate_reconstruction_loss: 0.0053 - _calculate_kl_loss: 171.4859\n",
            "Epoch 140/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5429.0815 - _calculate_reconstruction_loss: 0.0053 - _calculate_kl_loss: 165.4113\n",
            "Epoch 141/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5326.3271 - _calculate_reconstruction_loss: 0.0052 - _calculate_kl_loss: 157.5193\n",
            "Epoch 142/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5204.5071 - _calculate_reconstruction_loss: 0.0051 - _calculate_kl_loss: 145.7627\n",
            "Epoch 143/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5141.7754 - _calculate_reconstruction_loss: 0.0050 - _calculate_kl_loss: 135.9215\n",
            "Epoch 144/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5208.0450 - _calculate_reconstruction_loss: 0.0051 - _calculate_kl_loss: 131.0999\n",
            "Epoch 145/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5222.5959 - _calculate_reconstruction_loss: 0.0051 - _calculate_kl_loss: 130.1645\n",
            "Epoch 146/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5227.9764 - _calculate_reconstruction_loss: 0.0051 - _calculate_kl_loss: 131.7231\n",
            "Epoch 147/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5263.9388 - _calculate_reconstruction_loss: 0.0051 - _calculate_kl_loss: 143.8865\n",
            "Epoch 148/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5442.2085 - _calculate_reconstruction_loss: 0.0053 - _calculate_kl_loss: 142.4391\n",
            "Epoch 149/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5397.9805 - _calculate_reconstruction_loss: 0.0053 - _calculate_kl_loss: 141.7426\n",
            "Epoch 150/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5307.9464 - _calculate_reconstruction_loss: 0.0052 - _calculate_kl_loss: 143.8544\n",
            "Epoch 151/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5244.6352 - _calculate_reconstruction_loss: 0.0051 - _calculate_kl_loss: 138.7070\n",
            "Epoch 152/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5195.8146 - _calculate_reconstruction_loss: 0.0051 - _calculate_kl_loss: 132.5520\n",
            "Epoch 153/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5177.8278 - _calculate_reconstruction_loss: 0.0050 - _calculate_kl_loss: 130.9745\n",
            "Epoch 154/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5227.5669 - _calculate_reconstruction_loss: 0.0051 - _calculate_kl_loss: 129.7676\n",
            "Epoch 155/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5305.8109 - _calculate_reconstruction_loss: 0.0052 - _calculate_kl_loss: 130.5615\n",
            "Epoch 156/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5507.0397 - _calculate_reconstruction_loss: 0.0054 - _calculate_kl_loss: 141.9960\n",
            "Epoch 157/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5207.4863 - _calculate_reconstruction_loss: 0.0051 - _calculate_kl_loss: 129.2101\n",
            "Epoch 158/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5015.5776 - _calculate_reconstruction_loss: 0.0049 - _calculate_kl_loss: 120.1013\n",
            "Epoch 159/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4978.2271 - _calculate_reconstruction_loss: 0.0049 - _calculate_kl_loss: 114.2199\n",
            "Epoch 160/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4983.0544 - _calculate_reconstruction_loss: 0.0049 - _calculate_kl_loss: 109.9151\n",
            "Epoch 161/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5053.8148 - _calculate_reconstruction_loss: 0.0049 - _calculate_kl_loss: 108.9524\n",
            "Epoch 162/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5170.7948 - _calculate_reconstruction_loss: 0.0051 - _calculate_kl_loss: 113.8950\n",
            "Epoch 163/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 125288.3229 - _calculate_reconstruction_loss: 0.0070 - _calculate_kl_loss: 118285.0156\n",
            "Epoch 164/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5779.0432 - _calculate_reconstruction_loss: 0.0056 - _calculate_kl_loss: 194.7767\n",
            "Epoch 165/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5349.9669 - _calculate_reconstruction_loss: 0.0052 - _calculate_kl_loss: 171.4354\n",
            "Epoch 166/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5248.8297 - _calculate_reconstruction_loss: 0.0051 - _calculate_kl_loss: 160.4228\n",
            "Epoch 167/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5159.1186 - _calculate_reconstruction_loss: 0.0050 - _calculate_kl_loss: 152.1955\n",
            "Epoch 168/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5101.0172 - _calculate_reconstruction_loss: 0.0050 - _calculate_kl_loss: 144.9770\n",
            "Epoch 169/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5108.5586 - _calculate_reconstruction_loss: 0.0050 - _calculate_kl_loss: 146.5673\n",
            "Epoch 170/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5307.7351 - _calculate_reconstruction_loss: 0.0052 - _calculate_kl_loss: 153.2903\n",
            "Epoch 171/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5125.9274 - _calculate_reconstruction_loss: 0.0050 - _calculate_kl_loss: 142.7734\n",
            "Epoch 172/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5107.9707 - _calculate_reconstruction_loss: 0.0050 - _calculate_kl_loss: 140.5779\n",
            "Epoch 173/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5144.7926 - _calculate_reconstruction_loss: 0.0050 - _calculate_kl_loss: 137.4210\n",
            "Epoch 174/500\n",
            "400/400 [==============================] - 41s 102ms/step - batch: 199.5000 - size: 27.0000 - loss: 5097.5102 - _calculate_reconstruction_loss: 0.0050 - _calculate_kl_loss: 132.4273\n",
            "Epoch 175/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5053.6318 - _calculate_reconstruction_loss: 0.0049 - _calculate_kl_loss: 132.6284\n",
            "Epoch 176/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5117.7379 - _calculate_reconstruction_loss: 0.0050 - _calculate_kl_loss: 131.0542\n",
            "Epoch 177/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5095.8412 - _calculate_reconstruction_loss: 0.0050 - _calculate_kl_loss: 130.8735\n",
            "Epoch 178/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5180.9234 - _calculate_reconstruction_loss: 0.0050 - _calculate_kl_loss: 134.6126\n",
            "Epoch 179/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5285.6762 - _calculate_reconstruction_loss: 0.0051 - _calculate_kl_loss: 136.4229\n",
            "Epoch 180/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5346.6425 - _calculate_reconstruction_loss: 0.0052 - _calculate_kl_loss: 147.1864\n",
            "Epoch 181/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5323.6361 - _calculate_reconstruction_loss: 0.0052 - _calculate_kl_loss: 149.0288\n",
            "Epoch 182/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5072.8511 - _calculate_reconstruction_loss: 0.0049 - _calculate_kl_loss: 141.6177\n",
            "Epoch 183/500\n",
            "400/400 [==============================] - 41s 102ms/step - batch: 199.5000 - size: 27.0000 - loss: 4962.5751 - _calculate_reconstruction_loss: 0.0048 - _calculate_kl_loss: 128.9392\n",
            "Epoch 184/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4922.4318 - _calculate_reconstruction_loss: 0.0048 - _calculate_kl_loss: 119.8954\n",
            "Epoch 185/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4913.8667 - _calculate_reconstruction_loss: 0.0048 - _calculate_kl_loss: 116.5474\n",
            "Epoch 186/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 6397.5236 - _calculate_reconstruction_loss: 0.0062 - _calculate_kl_loss: 156.2599\n",
            "Epoch 187/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5401.5223 - _calculate_reconstruction_loss: 0.0053 - _calculate_kl_loss: 151.4639\n",
            "Epoch 188/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5057.9330 - _calculate_reconstruction_loss: 0.0049 - _calculate_kl_loss: 143.2419\n",
            "Epoch 189/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4951.7493 - _calculate_reconstruction_loss: 0.0048 - _calculate_kl_loss: 133.3873\n",
            "Epoch 190/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4889.0041 - _calculate_reconstruction_loss: 0.0048 - _calculate_kl_loss: 128.6901\n",
            "Epoch 191/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4855.9618 - _calculate_reconstruction_loss: 0.0047 - _calculate_kl_loss: 123.1905\n",
            "Epoch 192/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4823.4808 - _calculate_reconstruction_loss: 0.0047 - _calculate_kl_loss: 111.3014\n",
            "Epoch 193/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4832.4447 - _calculate_reconstruction_loss: 0.0047 - _calculate_kl_loss: 107.1142\n",
            "Epoch 194/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5036.5871 - _calculate_reconstruction_loss: 0.0049 - _calculate_kl_loss: 108.6583\n",
            "Epoch 195/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5380.4692 - _calculate_reconstruction_loss: 0.0053 - _calculate_kl_loss: 125.5440\n",
            "Epoch 196/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5206.0020 - _calculate_reconstruction_loss: 0.0051 - _calculate_kl_loss: 127.1869\n",
            "Epoch 197/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5064.5844 - _calculate_reconstruction_loss: 0.0049 - _calculate_kl_loss: 126.0717\n",
            "Epoch 198/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5084.1186 - _calculate_reconstruction_loss: 0.0050 - _calculate_kl_loss: 124.5419\n",
            "Epoch 199/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5012.0184 - _calculate_reconstruction_loss: 0.0049 - _calculate_kl_loss: 119.4005\n",
            "Epoch 200/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4945.9557 - _calculate_reconstruction_loss: 0.0048 - _calculate_kl_loss: 120.8016\n",
            "Epoch 201/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4926.0111 - _calculate_reconstruction_loss: 0.0048 - _calculate_kl_loss: 116.6335\n",
            "Epoch 202/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4945.6246 - _calculate_reconstruction_loss: 0.0048 - _calculate_kl_loss: 113.9411\n",
            "Epoch 203/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5139.7645 - _calculate_reconstruction_loss: 0.0050 - _calculate_kl_loss: 119.6166\n",
            "Epoch 204/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5118.9098 - _calculate_reconstruction_loss: 0.0050 - _calculate_kl_loss: 118.3036\n",
            "Epoch 205/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5091.3664 - _calculate_reconstruction_loss: 0.0050 - _calculate_kl_loss: 120.5620\n",
            "Epoch 206/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5105.8221 - _calculate_reconstruction_loss: 0.0050 - _calculate_kl_loss: 116.9189\n",
            "Epoch 207/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5092.9408 - _calculate_reconstruction_loss: 0.0050 - _calculate_kl_loss: 118.9951\n",
            "Epoch 208/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4971.3361 - _calculate_reconstruction_loss: 0.0049 - _calculate_kl_loss: 115.0007\n",
            "Epoch 209/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4913.7306 - _calculate_reconstruction_loss: 0.0048 - _calculate_kl_loss: 116.6093\n",
            "Epoch 210/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4926.7301 - _calculate_reconstruction_loss: 0.0048 - _calculate_kl_loss: 110.7641\n",
            "Epoch 211/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4958.9774 - _calculate_reconstruction_loss: 0.0049 - _calculate_kl_loss: 108.8362\n",
            "Epoch 212/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5015.1142 - _calculate_reconstruction_loss: 0.0049 - _calculate_kl_loss: 109.2655\n",
            "Epoch 213/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5174.4450 - _calculate_reconstruction_loss: 0.0051 - _calculate_kl_loss: 114.4844\n",
            "Epoch 214/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5067.3744 - _calculate_reconstruction_loss: 0.0050 - _calculate_kl_loss: 109.2222\n",
            "Epoch 215/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4998.0810 - _calculate_reconstruction_loss: 0.0049 - _calculate_kl_loss: 102.8359\n",
            "Epoch 216/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4915.4291 - _calculate_reconstruction_loss: 0.0048 - _calculate_kl_loss: 97.6927\n",
            "Epoch 217/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4952.2524 - _calculate_reconstruction_loss: 0.0049 - _calculate_kl_loss: 96.0931\n",
            "Epoch 218/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4892.5949 - _calculate_reconstruction_loss: 0.0048 - _calculate_kl_loss: 93.1123\n",
            "Epoch 219/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4984.0817 - _calculate_reconstruction_loss: 0.0049 - _calculate_kl_loss: 94.8682\n",
            "Epoch 220/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5008.2732 - _calculate_reconstruction_loss: 0.0049 - _calculate_kl_loss: 95.9238\n",
            "Epoch 221/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5090.3797 - _calculate_reconstruction_loss: 0.0050 - _calculate_kl_loss: 96.1488\n",
            "Epoch 222/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5089.4941 - _calculate_reconstruction_loss: 0.0050 - _calculate_kl_loss: 98.6525\n",
            "Epoch 223/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5036.1032 - _calculate_reconstruction_loss: 0.0049 - _calculate_kl_loss: 94.7710\n",
            "Epoch 224/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4945.5465 - _calculate_reconstruction_loss: 0.0049 - _calculate_kl_loss: 93.7253\n",
            "Epoch 225/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4951.1203 - _calculate_reconstruction_loss: 0.0049 - _calculate_kl_loss: 90.1691\n",
            "Epoch 226/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4910.8423 - _calculate_reconstruction_loss: 0.0048 - _calculate_kl_loss: 88.9667\n",
            "Epoch 227/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4867.2702 - _calculate_reconstruction_loss: 0.0048 - _calculate_kl_loss: 85.6477\n",
            "Epoch 228/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4840.8093 - _calculate_reconstruction_loss: 0.0048 - _calculate_kl_loss: 82.3935\n",
            "Epoch 229/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4830.9893 - _calculate_reconstruction_loss: 0.0048 - _calculate_kl_loss: 80.3515\n",
            "Epoch 230/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4860.9567 - _calculate_reconstruction_loss: 0.0048 - _calculate_kl_loss: 80.1496\n",
            "Epoch 231/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4888.8081 - _calculate_reconstruction_loss: 0.0048 - _calculate_kl_loss: 80.5588\n",
            "Epoch 232/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4878.9623 - _calculate_reconstruction_loss: 0.0048 - _calculate_kl_loss: 81.2487\n",
            "Epoch 233/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5287.3061 - _calculate_reconstruction_loss: 0.0051 - _calculate_kl_loss: 166.1284\n",
            "Epoch 234/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4868.0170 - _calculate_reconstruction_loss: 0.0048 - _calculate_kl_loss: 93.5097\n",
            "Epoch 235/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4927.8753 - _calculate_reconstruction_loss: 0.0048 - _calculate_kl_loss: 89.7066\n",
            "Epoch 236/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4789.1722 - _calculate_reconstruction_loss: 0.0047 - _calculate_kl_loss: 85.0492\n",
            "Epoch 237/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4764.5407 - _calculate_reconstruction_loss: 0.0047 - _calculate_kl_loss: 82.9930\n",
            "Epoch 238/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4810.5736 - _calculate_reconstruction_loss: 0.0047 - _calculate_kl_loss: 81.3742\n",
            "Epoch 239/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4828.9471 - _calculate_reconstruction_loss: 0.0047 - _calculate_kl_loss: 80.1643\n",
            "Epoch 240/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4870.7833 - _calculate_reconstruction_loss: 0.0048 - _calculate_kl_loss: 78.7634\n",
            "Epoch 241/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4834.7717 - _calculate_reconstruction_loss: 0.0048 - _calculate_kl_loss: 79.0806\n",
            "Epoch 242/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4779.9980 - _calculate_reconstruction_loss: 0.0047 - _calculate_kl_loss: 77.0468\n",
            "Epoch 243/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5170.8287 - _calculate_reconstruction_loss: 0.0051 - _calculate_kl_loss: 105.7019\n",
            "Epoch 244/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4919.0838 - _calculate_reconstruction_loss: 0.0048 - _calculate_kl_loss: 83.4204\n",
            "Epoch 245/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4892.1816 - _calculate_reconstruction_loss: 0.0048 - _calculate_kl_loss: 82.8310\n",
            "Epoch 246/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4706.5269 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 78.9652\n",
            "Epoch 247/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4694.9639 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 77.7735\n",
            "Epoch 248/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4690.1653 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 74.9162\n",
            "Epoch 249/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4710.9241 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 73.7674\n",
            "Epoch 250/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4784.8789 - _calculate_reconstruction_loss: 0.0047 - _calculate_kl_loss: 72.0747\n",
            "Epoch 251/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4809.5938 - _calculate_reconstruction_loss: 0.0047 - _calculate_kl_loss: 73.1564\n",
            "Epoch 252/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4861.7892 - _calculate_reconstruction_loss: 0.0048 - _calculate_kl_loss: 73.3139\n",
            "Epoch 253/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4832.8703 - _calculate_reconstruction_loss: 0.0048 - _calculate_kl_loss: 71.3365\n",
            "Epoch 254/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4900.4636 - _calculate_reconstruction_loss: 0.0048 - _calculate_kl_loss: 72.5504\n",
            "Epoch 255/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4779.0584 - _calculate_reconstruction_loss: 0.0047 - _calculate_kl_loss: 71.9663\n",
            "Epoch 256/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4794.0729 - _calculate_reconstruction_loss: 0.0047 - _calculate_kl_loss: 71.9950\n",
            "Epoch 257/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4779.7378 - _calculate_reconstruction_loss: 0.0047 - _calculate_kl_loss: 69.7372\n",
            "Epoch 258/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4726.3662 - _calculate_reconstruction_loss: 0.0047 - _calculate_kl_loss: 67.5880\n",
            "Epoch 259/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4724.7044 - _calculate_reconstruction_loss: 0.0047 - _calculate_kl_loss: 66.5067\n",
            "Epoch 260/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4910.1494 - _calculate_reconstruction_loss: 0.0048 - _calculate_kl_loss: 69.9322\n",
            "Epoch 261/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4898.0680 - _calculate_reconstruction_loss: 0.0048 - _calculate_kl_loss: 84.2273\n",
            "Epoch 262/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4783.5836 - _calculate_reconstruction_loss: 0.0047 - _calculate_kl_loss: 80.3592\n",
            "Epoch 263/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4763.4898 - _calculate_reconstruction_loss: 0.0047 - _calculate_kl_loss: 77.3449\n",
            "Epoch 264/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4732.6512 - _calculate_reconstruction_loss: 0.0047 - _calculate_kl_loss: 76.2529\n",
            "Epoch 265/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4766.5921 - _calculate_reconstruction_loss: 0.0047 - _calculate_kl_loss: 75.5711\n",
            "Epoch 266/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4753.0482 - _calculate_reconstruction_loss: 0.0047 - _calculate_kl_loss: 73.9084\n",
            "Epoch 267/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4718.9841 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 71.5935\n",
            "Epoch 268/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4777.9405 - _calculate_reconstruction_loss: 0.0047 - _calculate_kl_loss: 71.6608\n",
            "Epoch 269/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4781.9469 - _calculate_reconstruction_loss: 0.0047 - _calculate_kl_loss: 74.0202\n",
            "Epoch 270/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4717.3631 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 73.8030\n",
            "Epoch 271/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4675.6215 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 70.3413\n",
            "Epoch 272/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4693.5250 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 67.7991\n",
            "Epoch 273/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4671.4122 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 65.6336\n",
            "Epoch 274/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4710.7046 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 64.0372\n",
            "Epoch 275/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4731.3511 - _calculate_reconstruction_loss: 0.0047 - _calculate_kl_loss: 66.6172\n",
            "Epoch 276/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4773.6540 - _calculate_reconstruction_loss: 0.0047 - _calculate_kl_loss: 66.5425\n",
            "Epoch 277/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4751.3604 - _calculate_reconstruction_loss: 0.0047 - _calculate_kl_loss: 64.6563\n",
            "Epoch 278/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4707.8513 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 63.2924\n",
            "Epoch 279/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4657.9615 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 60.8038\n",
            "Epoch 280/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4635.9653 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 59.2034\n",
            "Epoch 281/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4646.8079 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 57.8964\n",
            "Epoch 282/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4732.5046 - _calculate_reconstruction_loss: 0.0047 - _calculate_kl_loss: 58.3652\n",
            "Epoch 283/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4765.1474 - _calculate_reconstruction_loss: 0.0047 - _calculate_kl_loss: 60.0508\n",
            "Epoch 284/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4742.4514 - _calculate_reconstruction_loss: 0.0047 - _calculate_kl_loss: 59.4466\n",
            "Epoch 285/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4715.3266 - _calculate_reconstruction_loss: 0.0047 - _calculate_kl_loss: 58.2713\n",
            "Epoch 286/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4618.3644 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 57.1683\n",
            "Epoch 287/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4594.9384 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 55.1643\n",
            "Epoch 288/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4634.9349 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 54.7048\n",
            "Epoch 289/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 5176.8832 - _calculate_reconstruction_loss: 0.0049 - _calculate_kl_loss: 299.6199\n",
            "Epoch 290/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4748.9900 - _calculate_reconstruction_loss: 0.0047 - _calculate_kl_loss: 67.2341\n",
            "Epoch 291/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4647.5798 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 64.3111\n",
            "Epoch 292/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4623.9802 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 62.4901\n",
            "Epoch 293/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4637.1448 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 61.7489\n",
            "Epoch 294/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4653.4872 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 60.6456\n",
            "Epoch 295/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4699.7107 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 61.2744\n",
            "Epoch 296/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4738.8127 - _calculate_reconstruction_loss: 0.0047 - _calculate_kl_loss: 61.4978\n",
            "Epoch 297/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4694.4145 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 61.0591\n",
            "Epoch 298/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4702.2977 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 60.6956\n",
            "Epoch 299/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4617.3798 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 59.9900\n",
            "Epoch 300/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4576.4142 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 58.1592\n",
            "Epoch 301/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4575.4248 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 58.3603\n",
            "Epoch 302/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4569.7694 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 56.7286\n",
            "Epoch 303/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4600.9626 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 55.7396\n",
            "Epoch 304/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4595.8625 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 56.6578\n",
            "Epoch 305/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4570.2599 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 54.8961\n",
            "Epoch 306/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4603.6584 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 54.4105\n",
            "Epoch 307/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4631.7241 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 54.0281\n",
            "Epoch 308/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4635.1404 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 57.2851\n",
            "Epoch 309/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4697.5558 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 55.7097\n",
            "Epoch 310/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4699.0696 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 56.3699\n",
            "Epoch 311/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4629.9605 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 56.8552\n",
            "Epoch 312/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4585.3246 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 54.4026\n",
            "Epoch 313/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4539.4805 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 52.4398\n",
            "Epoch 314/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4516.2664 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 51.0793\n",
            "Epoch 315/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4539.6479 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 49.8433\n",
            "Epoch 316/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4542.5080 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 48.7700\n",
            "Epoch 317/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4663.2399 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 49.4638\n",
            "Epoch 318/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4626.4891 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 49.0676\n",
            "Epoch 319/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4637.4851 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 48.5935\n",
            "Epoch 320/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4672.9100 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 48.8255\n",
            "Epoch 321/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4627.4017 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 48.6541\n",
            "Epoch 322/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4575.5432 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 48.1205\n",
            "Epoch 323/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4536.7460 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 47.2809\n",
            "Epoch 324/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4534.3595 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 46.6084\n",
            "Epoch 325/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4528.2079 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 45.9667\n",
            "Epoch 326/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4562.0264 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 45.9291\n",
            "Epoch 327/500\n",
            "400/400 [==============================] - 42s 104ms/step - batch: 199.5000 - size: 27.0000 - loss: 4604.4716 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 46.5203\n",
            "Epoch 328/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4591.9872 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 45.9789\n",
            "Epoch 329/500\n",
            "400/400 [==============================] - 41s 104ms/step - batch: 199.5000 - size: 27.0000 - loss: 4589.2863 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 45.9164\n",
            "Epoch 330/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4645.9415 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 46.0835\n",
            "Epoch 331/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4617.3681 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 46.7120\n",
            "Epoch 332/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4621.1401 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 46.0021\n",
            "Epoch 333/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4552.9789 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 45.7453\n",
            "Epoch 334/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4501.5534 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 44.8756\n",
            "Epoch 335/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4479.3074 - _calculate_reconstruction_loss: 0.0044 - _calculate_kl_loss: 43.4390\n",
            "Epoch 336/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4468.7867 - _calculate_reconstruction_loss: 0.0044 - _calculate_kl_loss: 42.4355\n",
            "Epoch 337/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4471.0248 - _calculate_reconstruction_loss: 0.0044 - _calculate_kl_loss: 41.7161\n",
            "Epoch 338/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4494.2335 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 41.9436\n",
            "Epoch 339/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4529.3949 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 41.9103\n",
            "Epoch 340/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4550.3962 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 42.0356\n",
            "Epoch 341/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4576.4643 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 41.9907\n",
            "Epoch 342/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4635.6517 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 42.8219\n",
            "Epoch 343/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4582.1047 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 42.1979\n",
            "Epoch 344/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4521.1083 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 41.4592\n",
            "Epoch 345/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4460.1186 - _calculate_reconstruction_loss: 0.0044 - _calculate_kl_loss: 40.5102\n",
            "Epoch 346/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4478.4569 - _calculate_reconstruction_loss: 0.0044 - _calculate_kl_loss: 40.4138\n",
            "Epoch 347/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4476.4714 - _calculate_reconstruction_loss: 0.0044 - _calculate_kl_loss: 41.3952\n",
            "Epoch 348/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4486.4596 - _calculate_reconstruction_loss: 0.0044 - _calculate_kl_loss: 40.7830\n",
            "Epoch 349/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4505.1323 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 40.0094\n",
            "Epoch 350/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4482.1720 - _calculate_reconstruction_loss: 0.0044 - _calculate_kl_loss: 39.2752\n",
            "Epoch 351/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4496.8700 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 39.2237\n",
            "Epoch 352/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4534.0254 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 39.3970\n",
            "Epoch 353/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4494.8600 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 39.2899\n",
            "Epoch 354/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4491.5565 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 38.8830\n",
            "Epoch 355/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4499.5684 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 38.8325\n",
            "Epoch 356/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4491.8632 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 37.9183\n",
            "Epoch 357/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4529.3706 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 39.6385\n",
            "Epoch 358/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4532.7307 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 38.6565\n",
            "Epoch 359/500\n",
            "400/400 [==============================] - 42s 104ms/step - batch: 199.5000 - size: 27.0000 - loss: 4488.3462 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 37.9514\n",
            "Epoch 360/500\n",
            "400/400 [==============================] - 41s 104ms/step - batch: 199.5000 - size: 27.0000 - loss: 4453.8112 - _calculate_reconstruction_loss: 0.0044 - _calculate_kl_loss: 37.2698\n",
            "Epoch 361/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4443.9390 - _calculate_reconstruction_loss: 0.0044 - _calculate_kl_loss: 37.0469\n",
            "Epoch 362/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4443.6418 - _calculate_reconstruction_loss: 0.0044 - _calculate_kl_loss: 37.0143\n",
            "Epoch 363/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4476.6891 - _calculate_reconstruction_loss: 0.0044 - _calculate_kl_loss: 36.7662\n",
            "Epoch 364/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4449.6518 - _calculate_reconstruction_loss: 0.0044 - _calculate_kl_loss: 37.1250\n",
            "Epoch 365/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4501.0605 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 36.5147\n",
            "Epoch 366/500\n",
            "400/400 [==============================] - 41s 103ms/step - batch: 199.5000 - size: 27.0000 - loss: 4527.0017 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 36.1997\n",
            "Epoch 367/500\n",
            "190/400 [=============>................] - ETA: 21s - batch: 94.5000 - size: 27.0000 - loss: 4292.3183 - _calculate_reconstruction_loss: 0.0043 - _calculate_kl_loss: 33.0551"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHMhVJwH18LP"
      },
      "source": [
        "### Save Meta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMl9yD7Z193L",
        "outputId": "509c48ac-ed41-4425-ad91-0d2614d48281"
      },
      "source": [
        "# Training History\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
        "ws = gc.open_by_url('https://docs.google.com/spreadsheets/d/1ipVFC30pOjxDpsIrSqPiYxqGhbXiLjsFSBajyzo0gew/edit#gid=1946289387').sheet1\n",
        "all = ws.get_all_records()\n",
        "last_ts = all[-1]['Timestamp']\n",
        "ws.resize(len(all)+1)\n",
        "if last_ts != ts.strftime(\"%Y/%m/%d %H:%M:%S\"):\n",
        "    ws.append_row([\n",
        "                  ts.strftime(\"%Y/%m/%d %H:%M:%S\"),\n",
        "                  str(AMP_IDS),\n",
        "                  str(CLIP_IDS),\n",
        "                  str(CONV_FILTERS),\n",
        "                  str(CONV_KERNELS),\n",
        "                  str(CONV_STRIDES),\n",
        "                  str(TIMBRE_LATENT_SPACE_DIM),\n",
        "                  str(LEARNING_RATE),\n",
        "                  str(BATCH_SIZE),\n",
        "                  str(EPOCHS),\n",
        "                  str(int(min(losses))),\n",
        "                  str(losses)\n",
        "    ])\n",
        "else:\n",
        "    print(\"Already added to Training history!\")\n",
        "\n",
        "print(\"Metadata Saved!!\")\n",
        "\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metadata Saved!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-a2zPm2-nQd2"
      },
      "source": [
        "## Generate the embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2IhMH3guEs_"
      },
      "source": [
        "# # https://github.com/musikalkemist/generating-sound-with-neural-networks/blob/49d7db32c43d1a04c596cbbb282a9521be1e7fc8/11%20Implementing%20VAE/code/analysis.py\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa\n",
        "import librosa.display\n",
        "\n",
        "\n",
        "# Same method as above\n",
        "def load_fsdd(spectrograms_path):\n",
        "    dataset = {}\n",
        "    for root, _, file_names in os.walk(spectrograms_path):\n",
        "        for file_name in file_names:\n",
        "\n",
        "            if True: # re.match(regex, file_name):\n",
        "                file_path = os.path.join(root, file_name)\n",
        "                spectrogram = np.load(file_path) # (n_bins, n_frames, 1) \n",
        "                dataset[file_name] = spectrogram[..., np.newaxis]\n",
        "    return dataset\n",
        "SPECTROGRAMS_PATH = \"/content/drive/MyDrive/Music/VAE/spectrogram\"\n",
        "\n",
        "LATENT_REPRESENTATIONS_PATH = '/content/drive/MyDrive/Music/VAE/model-' + str(LATENT_SPACE_DIM) + '-' + str(BATCH_SIZE) + '-' + str(EPOCHS) + '/'\n",
        "MODEL_PATH = '/content/drive/MyDrive/Music/VAE/model-8-50-100'\n",
        "\n",
        "def select_random_images(dataset, num_images=10):\n",
        "    sample_keys = np.random.choice(list(dataset.keys()), num_images)\n",
        "    sample_ds = { key: dataset[key] for key in sample_keys }\n",
        "\n",
        "    return sample_ds\n",
        "\n",
        "\n",
        "def plot_reconstructed_images(images, reconstructed_images):\n",
        "    num_images = len(images)\n",
        "    for i, (image, reconstructed_image) in enumerate(zip(images, reconstructed_images)):\n",
        "\n",
        "        fig, ax = plt.subplots()\n",
        "        image = image.squeeze()\n",
        "        img = librosa.display.specshow(image, y_axis='log', x_axis='time', ax=ax)\n",
        "        fig.colorbar(img, ax=ax, format=\"%+2.0f dB\")\n",
        "\n",
        "        fig, ax = plt.subplots()\n",
        "        reconstructed_image = reconstructed_image.squeeze()\n",
        "        recon_img = librosa.display.specshow(reconstructed_image, y_axis='log', x_axis='time', ax=ax)\n",
        "        fig.colorbar(recon_img, ax=ax, format=\"%+2.0f dB\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_images_encoded_in_latent_space(latent_representations, sample_labels):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.scatter(latent_representations[:, 0],\n",
        "                latent_representations[:, 1],\n",
        "                cmap=\"rainbow\",\n",
        "                c=sample_labels,\n",
        "                alpha=0.5,\n",
        "                s=2)\n",
        "    plt.colorbar()\n",
        "    plt.show()\n",
        "\n",
        "def download_vectors(autoencoder, sample_ds, download_path):\n",
        "    images = np.array(list(sample_ds.values()))\n",
        "    filenames = sample_ds.keys()\n",
        "    latent_representations = autoencoder.encoder.predict(images)\n",
        "\n",
        "    with open(download_path + 'embeddings.tsv', 'w', newline='') as f_output:\n",
        "        tsv_output = csv.writer(f_output, delimiter='\\t')\n",
        "        tsv_output.writerows(latent_representations)\n",
        "    # Write corresdonding filenames\n",
        "    with open(download_path + 'embedding-filenames.tsv', 'a') as f_output:\n",
        "        f_output.seek(0)\n",
        "        f_output.truncate()\n",
        "        for data in filenames:\n",
        "            f_output.write(data)\n",
        "            f_output.write('\\n')\n",
        "    return latent_representations, filenames\n",
        "\n",
        "\n",
        "autoencoder = VAE.load(MODEL_PATH)\n",
        "dataset = load_fsdd(SPECTROGRAMS_PATH)\n",
        "\n",
        "# num_sample_images_to_show = 30\n",
        "\n",
        "# sample_ds = select_random_images(dataset, num_sample_images_to_show)\n",
        "# reconstructed_images, _ = autoencoder.reconstruct(np.array(list(dataset.values())))\n",
        "download_vectors(autoencoder, dataset, LATENT_REPRESENTATIONS_PATH)\n",
        "\n",
        "# plot_reconstructed_images(sample_images, reconstructed_images)\n",
        "\n",
        "# num_images = 6000\n",
        "# sample_images, sample_labels = select_images(x_test, y_test, num_images)\n",
        "# _, latent_representations = autoencoder.reconstruct(sample_images)\n",
        "# plot_images_encoded_in_latent_space(latent_representations, sample_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcOnsyKht0R7"
      },
      "source": [
        "### Load the Data generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OM0eby5gt2Kv",
        "outputId": "23ebc43b-59b8-4b1b-ab42-fa3193f0d415",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "SPECTROGRAMS_PATH = \"/content/drive/MyDrive/Music/VAE/ICASSP/spectrogram\"\n",
        "MUSICAE_SAVE_PATH = \"/content/drive/MyDrive/Music/VAE/ICASSP/music-encoder/\"\n",
        "\n",
        "MUSICAE_MODEL_PATH = os.path.join(MUSICAE_SAVE_PATH, \"model\")\n",
        "\n",
        "EMBEDDINGS_FILE = \"embeddings-2021-10-04-06-08-29.tsv\"\n",
        "FILENAMES_FILE = \"embedding-filenames-2021-10-04-06-08-29.tsv\"\n",
        "\n",
        "AMP_IDS = [i for i in range(1, 81)] # 1-80\n",
        "CLIP_IDS = [i for i in range(1, 13)] # 1-12\n",
        "BATCH_SIZE = 27\n",
        "\n",
        "dsfilenames = get_valid_files(SPECTROGRAMS_PATH, AMP_IDS, CLIP_IDS)\n",
        "dslen = len(dsfilenames)\n",
        "print(\"Total dataset size: \" + str(dslen))\n",
        "\n",
        "d_name_vec = get_music_embeddings_dict(MUSICAE_MODEL_PATH, EMBEDDINGS_FILE, FILENAMES_FILE)\n",
        "\n",
        "musicds_gen = music_ds_generator(d_name_vec, SPECTROGRAMS_PATH, dsfilenames, BATCH_SIZE, False)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total dataset size: 10800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iE6yEfEKvKVU"
      },
      "source": [
        "### Load the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgs4tcBHvLr4"
      },
      "source": [
        "MODEL_PATH = \"/content/drive/MyDrive/Music/VAE/ICASSP/music-encoder/model\"\n",
        "WEIGHTS_FILE = \"weights.h5\"\n",
        "LEARNING_RATE = 0.0001\n",
        "\n",
        "# TODO before running this cell independently\n",
        "# 1. Update the WEIGHTS_FILE\n",
        "\n",
        "musicae = VAE.load(MODEL_PATH, WEIGHTS_FILE)\n",
        "\n",
        "musicae.compile(LEARNING_RATE)\n",
        "musicae.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POBtcIFUvMTo"
      },
      "source": [
        "### Generate Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41GACZi7vRCQ"
      },
      "source": [
        "# # https://github.com/musikalkemist/generating-sound-with-neural-networks/blob/49d7db32c43d1a04c596cbbb282a9521be1e7fc8/11%20Implementing%20VAE/code/analysis.py\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa\n",
        "import librosa.display\n",
        "import pytz\n",
        "from datetime import datetime\n",
        "\n",
        "ts = pytz.timezone('Asia/Tokyo').localize(datetime.now())\n",
        "tsf = ts.strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
        "\n",
        "SPECTROGRAMS_PATH = \"/content/drive/MyDrive/Music/VAE/ICASSP/spectrogram\"\n",
        "\n",
        "\n",
        "def save_embeddings(musicae, dspath, dsfilenames, download_path, tsf):\n",
        "\n",
        "    dsspectrogram = []\n",
        "    for filename in dsfilenames:\n",
        "        filepath = os.path.join(SPECTROGRAMS_PATH, filename)\n",
        "        spectrogram = np.load(filepath)\n",
        "        dsspectrogram.append(spectrogram[..., np.newaxis])\n",
        "\n",
        "    dsspectrogram = np.array(dsspectrogram)\n",
        "    latent_representations = musicae.encoder.predict(dsspectrogram)\n",
        "\n",
        "    with open(os.path.join(download_path, 'embeddings-' + tsf + '.tsv'), 'a', newline='') as f_output:\n",
        "        tsv_output = csv.writer(f_output, delimiter='\\t')\n",
        "        tsv_output.writerows(latent_representations)\n",
        "    # Write corresdonding filenames\n",
        "    with open(os.path.join(download_path, 'embedding-filenames-' + tsf + '.tsv'), 'a') as f_output:\n",
        "        # f_output.seek(0)\n",
        "        # f_output.truncate()\n",
        "        for data in dsfilenames:\n",
        "            f_output.write(data)\n",
        "            f_output.write('\\n')\n",
        "    print(\"Embeddings saved!!\")\n",
        "    return latent_representations\n",
        "\n",
        "## Driver coder\n",
        "times = 0\n",
        "for _, _, xfiles, _ in musicds_gen:\n",
        "    print(xfiles)\n",
        "    save_embeddings(musicae, SPECTROGRAMS_PATH, xfiles, MODEL_PATH, tsf)\n",
        "    times += 1\n",
        "    if times == dslen/BATCH_SIZE:\n",
        "        break\n",
        "\n",
        "# reconstructed_images, _ = autoencoder.reconstruct(np.array(list(dataset.values())))\n",
        "# plot_reconstructed_images(sample_images, reconstructed_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiwMcaxkLiiJ"
      },
      "source": [
        "### testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaZ5fxPQ61HX"
      },
      "source": [
        "import os\n",
        "import pickle\n",
        "import csv\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization, \\\n",
        "    Flatten, Dense, Reshape, Conv2DTranspose, Activation, Lambda, concatenate\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "import numpy as np\n",
        "import tensorflow as tf\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q99alenC7Ly8",
        "outputId": "edc7aef0-dd33-49fa-d751-4abe3ac1125f"
      },
      "source": [
        "musicinput = Input(shape=(16, ), name=\"musicinput\")\n",
        "timbreinput = Input(shape=(256, 64, ), name=\"timbreinput\")\n",
        "flatteninput = Flatten()(timbreinput)\n",
        "timbreoutput = Dense(4)(flatteninput)\n",
        "print(timbreoutput.get_shape())\n",
        "output = concatenate([timbreoutput, musicinput])  # merge the outputs of the two models\n",
        "\n",
        "model = Model(inputs=[timbreinput, musicinput], outputs=output)\n",
        "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
        "model.summary()\n",
        "\n",
        "music_input = np.random.random((128, 16))\n",
        "timbre_input = np.random.random((128, 256, 64))\n",
        "\n",
        "# timbre_output = np.random.random((128, 4))\n",
        "# model.fit(x=[timbre_input, music_input], y=[timbre_output, music_input])\n",
        "\n",
        "timbre_embedding = np.random.random((1, 256, 64))\n",
        "music_embedding = np.random.random((1, 16))\n",
        "print(music_embedding)\n",
        "model.predict((timbre_embedding, music_embedding))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 4)\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "timbreinput (InputLayer)        [(None, 256, 64)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_7 (Flatten)             (None, 16384)        0           timbreinput[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 4)            65540       flatten_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "musicinput (InputLayer)         [(None, 16)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 20)           0           dense_3[0][0]                    \n",
            "                                                                 musicinput[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 65,540\n",
            "Trainable params: 65,540\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "[[0.73231605 0.64960158 0.15110145 0.37318685 0.16791524 0.05101025\n",
            "  0.66146104 0.10814263 0.65915587 0.51410862 0.3769006  0.59756434\n",
            "  0.02245474 0.87082054 0.17650429 0.23186579]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.0071329 , -0.12648135, -0.7631175 ,  0.7477544 ,  0.7323161 ,\n",
              "         0.6496016 ,  0.15110146,  0.37318686,  0.16791524,  0.05101025,\n",
              "         0.66146106,  0.10814263,  0.65915585,  0.5141086 ,  0.37690058,\n",
              "         0.59756434,  0.02245474,  0.8708205 ,  0.17650428,  0.2318658 ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "HaME_ELR7nYH",
        "outputId": "64ecdfc5-88a0-40b2-bf70-ec85b7381cfc"
      },
      "source": [
        "model.predict(np.random.random((1, 32)))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.254264]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}