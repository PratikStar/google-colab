{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2.2 Music VAE",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PratikStar/google-colab/blob/main/2_2_Music_VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHIAgyMQE-60"
      },
      "source": [
        "### Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSpskSmkGT4C",
        "outputId": "c4578b4b-c62a-457a-dac0-3e75629b621a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',  force_remount=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdlnHSb1FDsJ"
      },
      "source": [
        "### Install tensorflow v2.4.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vr15BDmekCAy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "eb4807ce-541a-4827-c713-395ed60469dd"
      },
      "source": [
        "!pip uninstall --yes tensorflow\n",
        "!pip install tensorflow==2.4.0"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.6.0\n",
            "Uninstalling tensorflow-2.6.0:\n",
            "  Successfully uninstalled tensorflow-2.6.0\n",
            "Collecting tensorflow==2.4.0\n",
            "  Downloading tensorflow-2.4.0-cp37-cp37m-manylinux2010_x86_64.whl (394.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 394.7 MB 14 kB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (0.37.0)\n",
            "Collecting gast==0.3.3\n",
            "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (3.7.4.3)\n",
            "Collecting h5py~=2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 79.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (3.17.3)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.6.3)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.12.1)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (3.3.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.1.0)\n",
            "Collecting tensorflow-estimator<2.5.0,>=2.4.0rc0\n",
            "  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 68.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.12)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.1.2)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (0.12.0)\n",
            "Collecting grpcio~=1.32.0\n",
            "  Downloading grpcio-1.32.0-cp37-cp37m-manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 83.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.15.0)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (2.6.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.19.5)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (1.8.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (57.4.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (3.3.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (0.6.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (1.35.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.0) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.0) (4.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.0) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.0) (3.5.0)\n",
            "Installing collected packages: grpcio, tensorflow-estimator, h5py, gast, tensorflow\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.40.0\n",
            "    Uninstalling grpcio-1.40.0:\n",
            "      Successfully uninstalled grpcio-1.40.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.6.0\n",
            "    Uninstalling tensorflow-estimator-2.6.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.6.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "Successfully installed gast-0.3.3 grpcio-1.32.0 h5py-2.10.0 tensorflow-2.4.0 tensorflow-estimator-2.4.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gast",
                  "grpc",
                  "h5py",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTlUZZpvz9Xt"
      },
      "source": [
        "## Autoencoder Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlxNWPvvVn1L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bc3125f-9421-42b6-997e-964f1263f209"
      },
      "source": [
        "\"#@title\"\n",
        "import os\n",
        "import pickle\n",
        "import csv\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization, \\\n",
        "    Flatten, Dense, Reshape, Conv2DTranspose, Activation, Lambda\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "print(tf.__version__)\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "\n",
        "class VAE:\n",
        "    \"\"\"\n",
        "    VAE represents a Deep Convolutional variational autoencoder architecture\n",
        "    with mirrored encoder and decoder components.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 input_shape,\n",
        "                 conv_filters,\n",
        "                 conv_kernels,\n",
        "                 conv_strides,\n",
        "                 latent_space_dim):\n",
        "        self.input_shape = input_shape\n",
        "        self.conv_filters = conv_filters\n",
        "        self.conv_kernels = conv_kernels \n",
        "        self.conv_strides = conv_strides \n",
        "        self.latent_space_dim = latent_space_dim \n",
        "        self.reconstruction_loss_weight = 1000000\n",
        "\n",
        "        self.encoder = None\n",
        "        self.decoder = None\n",
        "        self.model = None\n",
        "\n",
        "        self._num_conv_layers = len(conv_filters)\n",
        "        self._shape_before_bottleneck = None\n",
        "        self._model_input = None\n",
        "\n",
        "        self._build()\n",
        "    def get_config(self):\n",
        "        return {}\n",
        "    def summary(self):\n",
        "        self.encoder.summary()\n",
        "        self.decoder.summary()\n",
        "        self.model.summary()\n",
        "\n",
        "    def compile(self, learning_rate=0.0001):\n",
        "        optimizer = Adam(learning_rate=learning_rate)\n",
        "        self.model.compile(optimizer=optimizer,\n",
        "                           loss=self._calculate_combined_loss,\n",
        "                           metrics=[self._calculate_reconstruction_loss,\n",
        "                                    self._calculate_kl_loss])\n",
        "\n",
        "    def train(self, generator, dataset_length, batch_size, num_epochs, callbacks):\n",
        "        if dataset_length % batch_size != 0:\n",
        "            raise Exception(\"dataset_length % batch_size = \" + str(dataset_length % batch_size) + \" != 0. Exiting!!\")\n",
        "        return self.model.fit(x=generator,\n",
        "                       steps_per_epoch= dataset_length/batch_size,\n",
        "                       epochs=num_epochs,\n",
        "                       callbacks=callbacks\n",
        "              )\n",
        "\n",
        "    def save(self, save_folder=\".\"):\n",
        "        self._create_folder_if_it_doesnt_exist(save_folder)\n",
        "        self.model.save(save_folder)\n",
        "\n",
        "    def savehdf5(self, save_folder=\".\"):\n",
        "        self._create_folder_if_it_doesnt_exist(save_folder)\n",
        "        self.save_parameters(save_folder)\n",
        "        self._save_weights(save_folder)\n",
        "\n",
        "    def save_parameters(self, save_folder):\n",
        "        self._create_folder_if_it_doesnt_exist(save_folder)\n",
        "        parameters = [\n",
        "            self.input_shape,\n",
        "            self.conv_filters,\n",
        "            self.conv_kernels,\n",
        "            self.conv_strides,\n",
        "            self.latent_space_dim\n",
        "        ]\n",
        "        save_path = os.path.join(save_folder, \"parameters.pkl\")\n",
        "        with open(save_path, \"wb\") as f:\n",
        "            print(parameters)\n",
        "            pickle.dump(parameters, f)\n",
        "\n",
        "    def _save_weights(self, save_folder):\n",
        "        save_path = os.path.join(save_folder, \"weights.h5\")\n",
        "        self.model.save_weights(save_path)\n",
        "\n",
        "    def reconstruct(self, images):\n",
        "        latent_representations = self.encoder.predict(images)\n",
        "        reconstructed_images = self.decoder.predict(latent_representations)\n",
        "        return reconstructed_images, latent_representations\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, save_folder=\".\", weights_file_name=\"weights.h5\"):\n",
        "        parameters_path = os.path.join(save_folder, \"parameters.pkl\")\n",
        "        weights_path = os.path.join(save_folder, weights_file_name)\n",
        "        if not os.path.exists(parameters_path) or not os.path.exists(weights_path):\n",
        "            return None\n",
        "        with open(parameters_path, \"rb\") as f:\n",
        "            parameters = pickle.load(f)\n",
        "        autoencoder = VAE(*parameters)\n",
        "        autoencoder.load_weights(weights_path)\n",
        "        return autoencoder\n",
        "\n",
        "    def load_weights(self, weights_path):\n",
        "        self.model.load_weights(weights_path)\n",
        "\n",
        "    def _calculate_combined_loss(self, y_target, y_predicted):\n",
        "        reconstruction_loss = self._calculate_reconstruction_loss(y_target, y_predicted)\n",
        "        kl_loss = self._calculate_kl_loss(y_target, y_predicted)\n",
        "        combined_loss = self.reconstruction_loss_weight * reconstruction_loss\\\n",
        "                                                         + kl_loss\n",
        "        return combined_loss\n",
        "\n",
        "    def _calculate_reconstruction_loss(self, y_target, y_predicted):\n",
        "        error = y_target - y_predicted\n",
        "        reconstruction_loss = K.mean(K.square(error), axis=[1, 2, 3])\n",
        "        return reconstruction_loss\n",
        "\n",
        "    def _calculate_kl_loss(self, y_target, y_predicted):\n",
        "        kl_loss = -0.5 * K.sum(1 + self.log_variance - K.square(self.mu) -\n",
        "                               K.exp(self.log_variance), axis=1)\n",
        "        return kl_loss\n",
        "\n",
        "    def _create_folder_if_it_doesnt_exist(self, folder):\n",
        "        if not os.path.exists(folder):\n",
        "            os.makedirs(folder)\n",
        "\n",
        "    def _build(self):\n",
        "        self._build_encoder()\n",
        "        self._build_decoder()\n",
        "        self._build_autoencoder()\n",
        "\n",
        "    def _build_autoencoder(self):\n",
        "        model_input = self._model_input\n",
        "        model_output = self.decoder(self.encoder(model_input))\n",
        "        self.model = Model(model_input, model_output, name=\"autoencoder\")\n",
        "\n",
        "    def _build_decoder(self):\n",
        "        decoder_input = self._add_decoder_input()\n",
        "        dense_layer = self._add_dense_layer(decoder_input)\n",
        "        reshape_layer = self._add_reshape_layer(dense_layer)\n",
        "        conv_transpose_layers = self._add_conv_transpose_layers(reshape_layer)\n",
        "        decoder_output = self._add_decoder_output(conv_transpose_layers)\n",
        "        self.decoder = Model(decoder_input, decoder_output, name=\"decoder\")\n",
        "\n",
        "    def _add_decoder_input(self):\n",
        "        return Input(shape=self.latent_space_dim, name=\"decoder_input\")\n",
        "\n",
        "    def _add_dense_layer(self, decoder_input):\n",
        "        num_neurons = np.prod(self._shape_before_bottleneck) # [1, 2, 4] -> 8\n",
        "        dense_layer = Dense(num_neurons, name=\"decoder_dense\")(decoder_input)\n",
        "        return dense_layer\n",
        "\n",
        "    def _add_reshape_layer(self, dense_layer):\n",
        "        return Reshape(self._shape_before_bottleneck)(dense_layer)\n",
        "\n",
        "    def _add_conv_transpose_layers(self, x):\n",
        "        \"\"\"Add conv transpose blocks.\"\"\"\n",
        "        # loop through all the conv layers in reverse order and stop at the\n",
        "        # first layer\n",
        "        for layer_index in reversed(range(1, self._num_conv_layers)):\n",
        "            x = self._add_conv_transpose_layer(layer_index, x)\n",
        "        return x\n",
        "\n",
        "    def _add_conv_transpose_layer(self, layer_index, x):\n",
        "        layer_num = self._num_conv_layers - layer_index\n",
        "        conv_transpose_layer = Conv2DTranspose(\n",
        "            filters=self.conv_filters[layer_index],\n",
        "            kernel_size=self.conv_kernels[layer_index],\n",
        "            strides=self.conv_strides[layer_index],\n",
        "            padding=\"same\",\n",
        "            name=f\"decoder_conv_transpose_layer_{layer_num}\"\n",
        "        )\n",
        "        x = conv_transpose_layer(x)\n",
        "        x = ReLU(name=f\"decoder_relu_{layer_num}\")(x)\n",
        "        x = BatchNormalization(name=f\"decoder_bn_{layer_num}\")(x)\n",
        "        return x\n",
        "\n",
        "    def _add_decoder_output(self, x):\n",
        "        conv_transpose_layer = Conv2DTranspose(\n",
        "            filters=1,\n",
        "            kernel_size=self.conv_kernels[0],\n",
        "            strides=self.conv_strides[0],\n",
        "            padding=\"same\",\n",
        "            name=f\"decoder_conv_transpose_layer_{self._num_conv_layers}\"\n",
        "        )\n",
        "        x = conv_transpose_layer(x)\n",
        "        output_layer = Activation(\"sigmoid\", name=\"sigmoid_layer\")(x)\n",
        "        return output_layer\n",
        "\n",
        "    def _build_encoder(self):\n",
        "        encoder_input = self._add_encoder_input()\n",
        "        conv_layers = self._add_conv_layers(encoder_input)\n",
        "        bottleneck = self._add_bottleneck(conv_layers)\n",
        "        self._model_input = encoder_input\n",
        "        self.encoder = Model(encoder_input, bottleneck, name=\"encoder\")\n",
        "\n",
        "    def _add_encoder_input(self):\n",
        "        return Input(shape=self.input_shape, name=\"encoder_input\")\n",
        "\n",
        "    def _add_conv_layers(self, encoder_input):\n",
        "        \"\"\"Create all convolutional blocks in encoder.\"\"\"\n",
        "        x = encoder_input\n",
        "        for layer_index in range(self._num_conv_layers):\n",
        "            x = self._add_conv_layer(layer_index, x)\n",
        "        return x\n",
        "\n",
        "    def _add_conv_layer(self, layer_index, x):\n",
        "        \"\"\"Add a convolutional block to a graph of layers, consisting of\n",
        "        conv 2d + ReLU + batch normalization.\n",
        "        \"\"\"\n",
        "        layer_number = layer_index + 1\n",
        "        conv_layer = Conv2D(\n",
        "            filters=self.conv_filters[layer_index],\n",
        "            kernel_size=self.conv_kernels[layer_index],\n",
        "            strides=self.conv_strides[layer_index],\n",
        "            padding=\"same\",\n",
        "            name=f\"encoder_conv_layer_{layer_number}\"\n",
        "        )\n",
        "        x = conv_layer(x)\n",
        "        x = ReLU(name=f\"encoder_relu_{layer_number}\")(x)\n",
        "        x = BatchNormalization(name=f\"encoder_bn_{layer_number}\")(x)\n",
        "        return x\n",
        "\n",
        "    def _add_bottleneck(self, x):\n",
        "        \"\"\"Flatten data and add bottleneck with Guassian sampling (Dense\n",
        "        layer).\n",
        "        \"\"\"\n",
        "        self._shape_before_bottleneck = K.int_shape(x)[1:]\n",
        "        x = Flatten()(x)\n",
        "        self.mu = Dense(self.latent_space_dim, name=\"mu\")(x)\n",
        "        self.log_variance = Dense(self.latent_space_dim,\n",
        "                                  name=\"log_variance\")(x)\n",
        "\n",
        "        def sample_point_from_normal_distribution(args):\n",
        "            mu, log_variance = args\n",
        "            epsilon = K.random_normal(shape=K.shape(self.mu), mean=0.,\n",
        "                                      stddev=1.)\n",
        "            sampled_point = mu + K.exp(log_variance / 2) * epsilon\n",
        "            return sampled_point\n",
        "\n",
        "        x = Lambda(sample_point_from_normal_distribution,\n",
        "                   name=\"encoder_output\")([self.mu, self.log_variance])\n",
        "        return x\n"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIykrk9Dz54n"
      },
      "source": [
        "## Load Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4XDb66wU0qt",
        "outputId": "b30102be-2236-4114-ab8c-bb2578dc04dc"
      },
      "source": [
        "import re\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "SPECTROGRAMS_PATH = \"/content/drive/MyDrive/Music/VAE/ICASSP/spectrogram\"\n",
        "AMP_IDS = [i for i in range(1, 81)] # 1-80\n",
        "CLIP_IDS = [i for i in range(1, 13)] # 1-12\n",
        "BATCH_SIZE = 27\n",
        "\n",
        "# Number of Reamped Clips (ampids): 80\n",
        "# Number of (Sub)clips each Reamped Clip(clipids): 12\n",
        "# Number of windows each Clip(windowid): different for clip:\n",
        "#     1: 13\n",
        "#     2: 12\n",
        "#     3: 13\n",
        "#     4: 11\n",
        "#     5: 11\n",
        "#     6: 14\n",
        "#     7: 11\n",
        "#     8: 14\n",
        "#     9: 11\n",
        "#     10: 08\n",
        "#     11: 09\n",
        "#     12: 15\n",
        "\n",
        "# Null Spectrograms/Windows. To be disregarded while training\n",
        "# 01-12\n",
        "# 04-10\n",
        "# 06-00\n",
        "# 07-10\n",
        "# 08-13\n",
        "# 11-08\n",
        "# 12-14\n",
        "\n",
        "def get_valid_files(spectrograms_path, ampids, clipids):\n",
        "\n",
        "    # Error checking\n",
        "    # ampid check: 1-80\n",
        "    invalidampids = [i for i in ampids if i>80 or i<1]\n",
        "    if len(invalidampids) > 0:\n",
        "        raise Exception(\"Invalid ampids: \" + str(invalidampids))\n",
        "    # clipid check: 1-12\n",
        "    invalidclipids = [i for i in clipids if i>12 or i<1]\n",
        "    if len(invalidclipids) > 0:\n",
        "        raise Exception(\"Invalid clipids: \" + str(invalidclipids))\n",
        "\n",
        "    clips_to_remove = [\"01-12\", \"04-10\", \"06-00\", \"07-10\", \"08-13\", \"11-08\", \"12-14\"]\n",
        "    # Actual DS creation\n",
        "    for root, _, filenames in os.walk(spectrograms_path):\n",
        "\n",
        "        ds = []\n",
        "        for filename in filenames:\n",
        "            fn_split = filename.split(\" \")[0].split(\"-\")\n",
        "\n",
        "            ampid = int(fn_split[0])\n",
        "            clipid = int(fn_split[1])\n",
        "            windowid = int(fn_split[2])\n",
        "\n",
        "            regex = \"^(?!00000.*$).*\"\n",
        "            if re.match(regex, filename) and (ampid in ampids and clipid in clipids) and (\"%02d\" % clipid + \"-\" + \"%02d\" % windowid) not in clips_to_remove:\n",
        "                ds.append(filename)\n",
        "\n",
        "        dslen = len(ds)\n",
        "    return sorted(ds)\n",
        "\n",
        "def music_ds_generator(spectrograms_path, filenames, batchsize):\n",
        "        i = 0\n",
        "        dslen = len(filenames)\n",
        "        while True:\n",
        "            x, y = [], []\n",
        "            xfiles, yfiles = [], []\n",
        "\n",
        "            st = i\n",
        "            end = (i + batchsize) % dslen\n",
        "            i = (end ) % dslen\n",
        "            \n",
        "            if end < st:\n",
        "                xfiles = filenames[st:dslen]\n",
        "                xfiles.extend(filenames[0:end])\n",
        "            else:\n",
        "                xfiles = filenames[st: end]\n",
        "        \n",
        "            for filename in xfiles:\n",
        "                fn_split = filename.split(\" \")[0].split(\"-\")\n",
        "                ampid = int(fn_split[0])\n",
        "                clipid = int(fn_split[1])\n",
        "                windowid = int(fn_split[2])\n",
        "                di_filename = \"00000-\" + \"%02d\" % clipid + \"-\" + \"%02d\" % windowid + \" DI.wav.npy\"\n",
        "\n",
        "                yfiles.append(di_filename)\n",
        "\n",
        "                filepath = os.path.join(spectrograms_path, filename)\n",
        "                di_filepath = os.path.join(spectrograms_path, di_filename)\n",
        "                \n",
        "                spectrogram = np.load(filepath)\n",
        "                di_spectrogram = np.load(di_filepath)\n",
        "                \n",
        "                x.append(spectrogram[..., np.newaxis])\n",
        "                y.append(di_spectrogram[..., np.newaxis])\n",
        "            yield (np.array(x), np.array(y))#, xfiles, yfiles\n",
        "\n",
        "\n",
        "def load_all_music_ds(spectrograms_path, ampids, clipids):\n",
        "\n",
        "    # ampid check: 1-80\n",
        "    invalidampids = [i for i in ampids if i>80 or i<1]\n",
        "    if len(invalidampids) > 0:\n",
        "        raise Exception(\"Invalid ampids: \" + str(invalidampids))\n",
        "    # clipid check: 1-12\n",
        "    invalidclipids = [i for i in clipids if i>12 or i<1]\n",
        "    if len(invalidclipids) > 0:\n",
        "        raise Exception(\"Invalid clipids: \" + str(invalidclipids))\n",
        "\n",
        "    # Creating a list of DI file names\n",
        "    x, y = [], []\n",
        "    xfiles, yfiles = [], []\n",
        "    dis = []\n",
        "    for root, _, filenames in os.walk(spectrograms_path):\n",
        "        for filename in filenames:\n",
        "            regex = \"^00000.*\"\n",
        "            if re.match(regex, filename):\n",
        "                dis.append(filename)\n",
        "\n",
        "    # Actual DS creation\n",
        "    for root, _, filenames in os.walk(spectrograms_path):\n",
        "\n",
        "        for filename in filenames:\n",
        "            fn_split = filename.split(\" \")[0].split(\"-\")\n",
        "\n",
        "            ampid = int(fn_split[0])\n",
        "            clipid = int(fn_split[1])\n",
        "            windowid = int(fn_split[2])\n",
        "\n",
        "            if ampid in ampids and clipid in clipids:\n",
        "                # print(filename)\n",
        "                xfiles.append(filename)\n",
        "                di_regex = \"^00000-\" + \"%02d\" % clipid + \"-\" + \"%02d\" % windowid + \".*\"\n",
        "                r = re.compile(di_regex)\n",
        "                di_filename = list(filter(r.match, dis))[0]\n",
        "                yfiles.append(di_filename)\n",
        "                # print(\"DI is: \" + di_filename)\n",
        "                filepath = os.path.join(root, filename)\n",
        "                di_filepath = os.path.join(root, di_filename)\n",
        "                \n",
        "                spectrogram = np.load(filepath) # (n_bins, n_frames, 1) \n",
        "                di_spectrogram = np.load(di_filepath) # (n_bins, n_frames, 1) \n",
        "                \n",
        "                x.append(spectrogram[..., np.newaxis])\n",
        "                y.append(di_spectrogram[..., np.newaxis])\n",
        "    return np.array(x), np.array(y), xfiles, yfiles\n",
        "\n",
        "# x, y, xfiles, yfiles = load_all_music_ds(SPECTROGRAMS_PATH, AMP_IDS, CLIP_IDS)\n",
        "dsfilenames = get_valid_files(SPECTROGRAMS_PATH, AMP_IDS, CLIP_IDS)\n",
        "dslen = len(dsfilenames)\n",
        "print(\"Total dataset size: \" + str(dslen))\n",
        "\n",
        "musicds_gen = music_ds_generator(SPECTROGRAMS_PATH, dsfilenames, BATCH_SIZE)\n"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total dataset size: 10800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoxtrbGxba-l"
      },
      "source": [
        "## Music AutoEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_GyWzngW2FB"
      },
      "source": [
        "### Instantiate Or Load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSivqKQZbeEp",
        "outputId": "40b72198-a69f-4d9e-e901-37a3994257de"
      },
      "source": [
        "MUSICAE_SAVE_PATH = \"/content/drive/MyDrive/Music/VAE/ICASSP/music-encoder/\"\n",
        "MODEL_PATH = os.path.join(MUSICAE_SAVE_PATH, \"model\")\n",
        "LEARNING_RATE = 0.0001\n",
        "\n",
        "musicae = VAE.load(MODEL_PATH, 'weights.h5')\n",
        "\n",
        "if musicae == None:\n",
        "    print(\"Instantiating the model\")\n",
        "    LATENT_SPACE_DIM= 16\n",
        "    CONV_FILTERS = (128, 64, 32, 32)\n",
        "    CONV_KERNELS = (3, 3, 3, 3)\n",
        "    CONV_STRIDES = (1, 2, 2, 1)\n",
        "\n",
        "    musicae = VAE(\n",
        "        input_shape=(256, 64, 1),\n",
        "        conv_filters= CONV_FILTERS, \n",
        "        conv_kernels= CONV_KERNELS,\n",
        "        conv_strides= CONV_STRIDES,\n",
        "        latent_space_dim=LATENT_SPACE_DIM\n",
        "    )\n",
        "    musicae.save_parameters(MODEL_PATH)\n",
        "\n",
        "musicae.compile(LEARNING_RATE)\n",
        "musicae.summary()"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instantiating the model\n",
            "[(256, 64, 1), (128, 64, 32, 32), (3, 3, 3, 3), (1, 2, 2, 1), 16]\n",
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "encoder_input (InputLayer)      [(None, 256, 64, 1)] 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "encoder_conv_layer_1 (Conv2D)   (None, 256, 64, 128) 1280        encoder_input[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "encoder_relu_1 (ReLU)           (None, 256, 64, 128) 0           encoder_conv_layer_1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "encoder_bn_1 (BatchNormalizatio (None, 256, 64, 128) 512         encoder_relu_1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "encoder_conv_layer_2 (Conv2D)   (None, 128, 32, 64)  73792       encoder_bn_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "encoder_relu_2 (ReLU)           (None, 128, 32, 64)  0           encoder_conv_layer_2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "encoder_bn_2 (BatchNormalizatio (None, 128, 32, 64)  256         encoder_relu_2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "encoder_conv_layer_3 (Conv2D)   (None, 64, 16, 32)   18464       encoder_bn_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "encoder_relu_3 (ReLU)           (None, 64, 16, 32)   0           encoder_conv_layer_3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "encoder_bn_3 (BatchNormalizatio (None, 64, 16, 32)   128         encoder_relu_3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "encoder_conv_layer_4 (Conv2D)   (None, 64, 16, 32)   9248        encoder_bn_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "encoder_relu_4 (ReLU)           (None, 64, 16, 32)   0           encoder_conv_layer_4[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "encoder_bn_4 (BatchNormalizatio (None, 64, 16, 32)   128         encoder_relu_4[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_16 (Flatten)            (None, 32768)        0           encoder_bn_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "mu (Dense)                      (None, 16)           524304      flatten_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "log_variance (Dense)            (None, 16)           524304      flatten_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "encoder_output (Lambda)         (None, 16)           0           mu[0][0]                         \n",
            "                                                                 log_variance[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 1,152,416\n",
            "Trainable params: 1,151,904\n",
            "Non-trainable params: 512\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "decoder_input (InputLayer)   [(None, 16)]              0         \n",
            "_________________________________________________________________\n",
            "decoder_dense (Dense)        (None, 32768)             557056    \n",
            "_________________________________________________________________\n",
            "reshape_16 (Reshape)         (None, 64, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "decoder_conv_transpose_layer (None, 64, 16, 32)        9248      \n",
            "_________________________________________________________________\n",
            "decoder_relu_1 (ReLU)        (None, 64, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "decoder_bn_1 (BatchNormaliza (None, 64, 16, 32)        128       \n",
            "_________________________________________________________________\n",
            "decoder_conv_transpose_layer (None, 128, 32, 32)       9248      \n",
            "_________________________________________________________________\n",
            "decoder_relu_2 (ReLU)        (None, 128, 32, 32)       0         \n",
            "_________________________________________________________________\n",
            "decoder_bn_2 (BatchNormaliza (None, 128, 32, 32)       128       \n",
            "_________________________________________________________________\n",
            "decoder_conv_transpose_layer (None, 256, 64, 64)       18496     \n",
            "_________________________________________________________________\n",
            "decoder_relu_3 (ReLU)        (None, 256, 64, 64)       0         \n",
            "_________________________________________________________________\n",
            "decoder_bn_3 (BatchNormaliza (None, 256, 64, 64)       256       \n",
            "_________________________________________________________________\n",
            "decoder_conv_transpose_layer (None, 256, 64, 1)        577       \n",
            "_________________________________________________________________\n",
            "sigmoid_layer (Activation)   (None, 256, 64, 1)        0         \n",
            "=================================================================\n",
            "Total params: 595,137\n",
            "Trainable params: 594,881\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n",
            "Model: \"autoencoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_input (InputLayer)   [(None, 256, 64, 1)]      0         \n",
            "_________________________________________________________________\n",
            "encoder (Functional)         (None, 16)                1152416   \n",
            "_________________________________________________________________\n",
            "decoder (Functional)         (None, 256, 64, 1)        595137    \n",
            "=================================================================\n",
            "Total params: 1,747,553\n",
            "Trainable params: 1,746,785\n",
            "Non-trainable params: 768\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Da9mV_T8vIz9"
      },
      "source": [
        "### Train Model (Iterative)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cL91qUHevKwM",
        "outputId": "61376a47-fc56-45bd-aa80-ac97150c6f35"
      },
      "source": [
        "import pytz\n",
        "from datetime import datetime\n",
        "\n",
        "EPOCHS = 500\n",
        "MUSICAE_SAVE_PATH = \"/content/drive/MyDrive/Music/VAE/ICASSP/music-encoder/\"\n",
        "ts = pytz.timezone('Asia/Tokyo').localize(datetime.now())\n",
        "tsf = ts.strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
        "MODEL_PATH = os.path.join(MUSICAE_SAVE_PATH, \"model\")\n",
        "CHECKPOINT_PATH = os.path.join(MODEL_PATH, \"checkpoints-\" + tsf)\n",
        "\n",
        "if not os.path.exists(CHECKPOINT_PATH):\n",
        "    os.makedirs(CHECKPOINT_PATH)\n",
        "\n",
        "class CustomCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        save_checkpoint_path = os.path.join(CHECKPOINT_PATH, \"weights-{}.h5\".format(epoch))\n",
        "        save_path = os.path.join(MODEL_PATH, \"weights.h5\")\n",
        "        self.model.save_weights(save_checkpoint_path)\n",
        "        self.model.save_weights(save_path)\n",
        "\n",
        "history = musicae.train(\n",
        "    generator=musicds_gen, \n",
        "    dataset_length=dslen,\n",
        "    batch_size=BATCH_SIZE, \n",
        "    num_epochs=EPOCHS,\n",
        "    callbacks=[CustomCallback()]\n",
        "    )\n",
        "losses = history.history['loss']\n"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "400/400 [==============================] - 1878s 5s/step - batch: 199.5000 - size: 27.0000 - loss: 44920.8416 - _calculate_reconstruction_loss: 0.0444 - _calculate_kl_loss: 514.7224\n",
            "Epoch 2/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 16056.9362 - _calculate_reconstruction_loss: 0.0156 - _calculate_kl_loss: 414.8702\n",
            "Epoch 3/100\n",
            "400/400 [==============================] - 42s 104ms/step - batch: 199.5000 - size: 27.0000 - loss: 11868.1404 - _calculate_reconstruction_loss: 0.0115 - _calculate_kl_loss: 347.5505\n",
            "Epoch 4/100\n",
            "400/400 [==============================] - 42s 104ms/step - batch: 199.5000 - size: 27.0000 - loss: 10045.3659 - _calculate_reconstruction_loss: 0.0096 - _calculate_kl_loss: 454.8722\n",
            "Epoch 5/100\n",
            "400/400 [==============================] - 42s 104ms/step - batch: 199.5000 - size: 27.0000 - loss: 8529.8199 - _calculate_reconstruction_loss: 0.0082 - _calculate_kl_loss: 377.8677\n",
            "Epoch 6/100\n",
            "400/400 [==============================] - 42s 104ms/step - batch: 199.5000 - size: 27.0000 - loss: 7426.9670 - _calculate_reconstruction_loss: 0.0071 - _calculate_kl_loss: 376.5253\n",
            "Epoch 7/100\n",
            "400/400 [==============================] - 42s 104ms/step - batch: 199.5000 - size: 27.0000 - loss: 6798.8631 - _calculate_reconstruction_loss: 0.0064 - _calculate_kl_loss: 362.2954\n",
            "Epoch 8/100\n",
            "400/400 [==============================] - 42s 104ms/step - batch: 199.5000 - size: 27.0000 - loss: 6211.6382 - _calculate_reconstruction_loss: 0.0059 - _calculate_kl_loss: 345.3073\n",
            "Epoch 9/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 5899.0757 - _calculate_reconstruction_loss: 0.0055 - _calculate_kl_loss: 360.3368\n",
            "Epoch 10/100\n",
            "400/400 [==============================] - 42s 104ms/step - batch: 199.5000 - size: 27.0000 - loss: 5657.2645 - _calculate_reconstruction_loss: 0.0053 - _calculate_kl_loss: 363.9996\n",
            "Epoch 11/100\n",
            "400/400 [==============================] - 42s 104ms/step - batch: 199.5000 - size: 27.0000 - loss: 7006.5593 - _calculate_reconstruction_loss: 0.0060 - _calculate_kl_loss: 976.3979\n",
            "Epoch 12/100\n",
            "400/400 [==============================] - 42s 104ms/step - batch: 199.5000 - size: 27.0000 - loss: 5853.3492 - _calculate_reconstruction_loss: 0.0054 - _calculate_kl_loss: 446.8540\n",
            "Epoch 13/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 4885.9088 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 392.1613\n",
            "Epoch 14/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 4752.3143 - _calculate_reconstruction_loss: 0.0044 - _calculate_kl_loss: 394.8857\n",
            "Epoch 15/100\n",
            "400/400 [==============================] - 42s 104ms/step - batch: 199.5000 - size: 27.0000 - loss: 4334.8357 - _calculate_reconstruction_loss: 0.0040 - _calculate_kl_loss: 376.6067\n",
            "Epoch 16/100\n",
            "400/400 [==============================] - 42s 104ms/step - batch: 199.5000 - size: 27.0000 - loss: 5467.0221 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 869.4946\n",
            "Epoch 17/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 4875.7641 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 398.8985\n",
            "Epoch 18/100\n",
            "400/400 [==============================] - 42s 104ms/step - batch: 199.5000 - size: 27.0000 - loss: 4288.0963 - _calculate_reconstruction_loss: 0.0039 - _calculate_kl_loss: 429.9972\n",
            "Epoch 19/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 3871.9793 - _calculate_reconstruction_loss: 0.0035 - _calculate_kl_loss: 397.7805\n",
            "Epoch 20/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 3769.3454 - _calculate_reconstruction_loss: 0.0034 - _calculate_kl_loss: 387.6512\n",
            "Epoch 21/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 3673.6409 - _calculate_reconstruction_loss: 0.0033 - _calculate_kl_loss: 393.3957\n",
            "Epoch 22/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 3610.4779 - _calculate_reconstruction_loss: 0.0032 - _calculate_kl_loss: 384.0110\n",
            "Epoch 23/100\n",
            "400/400 [==============================] - 42s 104ms/step - batch: 199.5000 - size: 27.0000 - loss: 3588.5650 - _calculate_reconstruction_loss: 0.0032 - _calculate_kl_loss: 406.6401\n",
            "Epoch 24/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 3485.7417 - _calculate_reconstruction_loss: 0.0031 - _calculate_kl_loss: 405.6996\n",
            "Epoch 25/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 3361.0714 - _calculate_reconstruction_loss: 0.0030 - _calculate_kl_loss: 389.9858\n",
            "Epoch 26/100\n",
            "400/400 [==============================] - 42s 104ms/step - batch: 199.5000 - size: 27.0000 - loss: 3206.0118 - _calculate_reconstruction_loss: 0.0028 - _calculate_kl_loss: 379.2183\n",
            "Epoch 27/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 3148.6507 - _calculate_reconstruction_loss: 0.0028 - _calculate_kl_loss: 365.1455\n",
            "Epoch 28/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 3126.3804 - _calculate_reconstruction_loss: 0.0028 - _calculate_kl_loss: 357.7818\n",
            "Epoch 29/100\n",
            "400/400 [==============================] - 42s 104ms/step - batch: 199.5000 - size: 27.0000 - loss: 3054.0980 - _calculate_reconstruction_loss: 0.0027 - _calculate_kl_loss: 350.5389\n",
            "Epoch 30/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 2924.9599 - _calculate_reconstruction_loss: 0.0026 - _calculate_kl_loss: 333.3908\n",
            "Epoch 31/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 2846.2752 - _calculate_reconstruction_loss: 0.0025 - _calculate_kl_loss: 319.3570\n",
            "Epoch 32/100\n",
            "400/400 [==============================] - 42s 104ms/step - batch: 199.5000 - size: 27.0000 - loss: 2805.6913 - _calculate_reconstruction_loss: 0.0025 - _calculate_kl_loss: 310.8137\n",
            "Epoch 33/100\n",
            "400/400 [==============================] - 42s 104ms/step - batch: 199.5000 - size: 27.0000 - loss: 2753.4996 - _calculate_reconstruction_loss: 0.0024 - _calculate_kl_loss: 307.4825\n",
            "Epoch 34/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 2682.1169 - _calculate_reconstruction_loss: 0.0024 - _calculate_kl_loss: 294.9144\n",
            "Epoch 35/100\n",
            "400/400 [==============================] - 42s 104ms/step - batch: 199.5000 - size: 27.0000 - loss: 2650.4940 - _calculate_reconstruction_loss: 0.0024 - _calculate_kl_loss: 286.1996\n",
            "Epoch 36/100\n",
            "400/400 [==============================] - 42s 104ms/step - batch: 199.5000 - size: 27.0000 - loss: 2627.0246 - _calculate_reconstruction_loss: 0.0023 - _calculate_kl_loss: 281.6834\n",
            "Epoch 37/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 2606.9252 - _calculate_reconstruction_loss: 0.0023 - _calculate_kl_loss: 279.8494\n",
            "Epoch 38/100\n",
            "400/400 [==============================] - 42s 104ms/step - batch: 199.5000 - size: 27.0000 - loss: 2604.7190 - _calculate_reconstruction_loss: 0.0023 - _calculate_kl_loss: 279.8488\n",
            "Epoch 39/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 2524.2983 - _calculate_reconstruction_loss: 0.0023 - _calculate_kl_loss: 271.7867\n",
            "Epoch 40/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 2437.4140 - _calculate_reconstruction_loss: 0.0022 - _calculate_kl_loss: 256.8413\n",
            "Epoch 41/100\n",
            "400/400 [==============================] - 42s 104ms/step - batch: 199.5000 - size: 27.0000 - loss: 2400.5705 - _calculate_reconstruction_loss: 0.0022 - _calculate_kl_loss: 246.6932\n",
            "Epoch 42/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 2361.4381 - _calculate_reconstruction_loss: 0.0021 - _calculate_kl_loss: 239.1432\n",
            "Epoch 43/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 2320.7134 - _calculate_reconstruction_loss: 0.0021 - _calculate_kl_loss: 231.1588\n",
            "Epoch 44/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 2289.4206 - _calculate_reconstruction_loss: 0.0021 - _calculate_kl_loss: 225.5511\n",
            "Epoch 45/100\n",
            "400/400 [==============================] - 42s 104ms/step - batch: 199.5000 - size: 27.0000 - loss: 2264.2592 - _calculate_reconstruction_loss: 0.0020 - _calculate_kl_loss: 222.9525\n",
            "Epoch 46/100\n",
            "400/400 [==============================] - 42s 104ms/step - batch: 199.5000 - size: 27.0000 - loss: 2229.8528 - _calculate_reconstruction_loss: 0.0020 - _calculate_kl_loss: 218.3051\n",
            "Epoch 47/100\n",
            "400/400 [==============================] - 42s 104ms/step - batch: 199.5000 - size: 27.0000 - loss: 2211.9644 - _calculate_reconstruction_loss: 0.0020 - _calculate_kl_loss: 214.5572\n",
            "Epoch 48/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 2181.7169 - _calculate_reconstruction_loss: 0.0020 - _calculate_kl_loss: 210.8268\n",
            "Epoch 49/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 2158.7194 - _calculate_reconstruction_loss: 0.0019 - _calculate_kl_loss: 210.2910\n",
            "Epoch 50/100\n",
            "400/400 [==============================] - 42s 104ms/step - batch: 199.5000 - size: 27.0000 - loss: 2114.4123 - _calculate_reconstruction_loss: 0.0019 - _calculate_kl_loss: 201.0963\n",
            "Epoch 51/100\n",
            "400/400 [==============================] - 42s 104ms/step - batch: 199.5000 - size: 27.0000 - loss: 2107.6783 - _calculate_reconstruction_loss: 0.0019 - _calculate_kl_loss: 197.1512\n",
            "Epoch 52/100\n",
            "400/400 [==============================] - 42s 104ms/step - batch: 199.5000 - size: 27.0000 - loss: 2086.9214 - _calculate_reconstruction_loss: 0.0019 - _calculate_kl_loss: 194.0926\n",
            "Epoch 53/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 2077.6699 - _calculate_reconstruction_loss: 0.0019 - _calculate_kl_loss: 191.0775\n",
            "Epoch 54/100\n",
            "400/400 [==============================] - 42s 104ms/step - batch: 199.5000 - size: 27.0000 - loss: 2037.9327 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 188.8756\n",
            "Epoch 55/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 2010.4435 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 184.1155\n",
            "Epoch 56/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 2280.5122 - _calculate_reconstruction_loss: 0.0021 - _calculate_kl_loss: 182.9233\n",
            "Epoch 57/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 2271.8373 - _calculate_reconstruction_loss: 0.0021 - _calculate_kl_loss: 207.8393\n",
            "Epoch 58/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 2115.8648 - _calculate_reconstruction_loss: 0.0019 - _calculate_kl_loss: 206.3074\n",
            "Epoch 59/100\n",
            "400/400 [==============================] - 42s 104ms/step - batch: 199.5000 - size: 27.0000 - loss: 2355.0461 - _calculate_reconstruction_loss: 0.0021 - _calculate_kl_loss: 229.9033\n",
            "Epoch 60/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 2069.6762 - _calculate_reconstruction_loss: 0.0019 - _calculate_kl_loss: 198.1456\n",
            "Epoch 61/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 1974.8588 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 192.6965\n",
            "Epoch 62/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 1952.0076 - _calculate_reconstruction_loss: 0.0018 - _calculate_kl_loss: 187.7656\n",
            "Epoch 63/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 1928.9216 - _calculate_reconstruction_loss: 0.0017 - _calculate_kl_loss: 185.4774\n",
            "Epoch 64/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 1893.5158 - _calculate_reconstruction_loss: 0.0017 - _calculate_kl_loss: 181.8026\n",
            "Epoch 65/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 1855.1002 - _calculate_reconstruction_loss: 0.0017 - _calculate_kl_loss: 176.8407\n",
            "Epoch 66/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 1838.8740 - _calculate_reconstruction_loss: 0.0017 - _calculate_kl_loss: 173.5201\n",
            "Epoch 67/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 1841.8452 - _calculate_reconstruction_loss: 0.0017 - _calculate_kl_loss: 172.2284\n",
            "Epoch 68/100\n",
            "400/400 [==============================] - 42s 106ms/step - batch: 199.5000 - size: 27.0000 - loss: 1838.9600 - _calculate_reconstruction_loss: 0.0017 - _calculate_kl_loss: 172.0216\n",
            "Epoch 69/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 1830.9213 - _calculate_reconstruction_loss: 0.0017 - _calculate_kl_loss: 171.2505\n",
            "Epoch 70/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 1817.2205 - _calculate_reconstruction_loss: 0.0016 - _calculate_kl_loss: 169.3246\n",
            "Epoch 71/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 1787.9850 - _calculate_reconstruction_loss: 0.0016 - _calculate_kl_loss: 166.2542\n",
            "Epoch 72/100\n",
            "400/400 [==============================] - 42s 104ms/step - batch: 199.5000 - size: 27.0000 - loss: 1771.8040 - _calculate_reconstruction_loss: 0.0016 - _calculate_kl_loss: 162.7480\n",
            "Epoch 73/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 1760.4850 - _calculate_reconstruction_loss: 0.0016 - _calculate_kl_loss: 160.3416\n",
            "Epoch 74/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 1767.1980 - _calculate_reconstruction_loss: 0.0016 - _calculate_kl_loss: 158.7774\n",
            "Epoch 75/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 1769.4013 - _calculate_reconstruction_loss: 0.0016 - _calculate_kl_loss: 156.8643\n",
            "Epoch 76/100\n",
            "400/400 [==============================] - 42s 104ms/step - batch: 199.5000 - size: 27.0000 - loss: 1773.1051 - _calculate_reconstruction_loss: 0.0016 - _calculate_kl_loss: 155.5893\n",
            "Epoch 77/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 1750.8684 - _calculate_reconstruction_loss: 0.0016 - _calculate_kl_loss: 153.1453\n",
            "Epoch 78/100\n",
            "400/400 [==============================] - 42s 104ms/step - batch: 199.5000 - size: 27.0000 - loss: 1718.1712 - _calculate_reconstruction_loss: 0.0016 - _calculate_kl_loss: 150.0046\n",
            "Epoch 79/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 1673.2465 - _calculate_reconstruction_loss: 0.0015 - _calculate_kl_loss: 145.9239\n",
            "Epoch 80/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 1641.1135 - _calculate_reconstruction_loss: 0.0015 - _calculate_kl_loss: 141.0667\n",
            "Epoch 81/100\n",
            "400/400 [==============================] - 42s 104ms/step - batch: 199.5000 - size: 27.0000 - loss: 1630.0780 - _calculate_reconstruction_loss: 0.0015 - _calculate_kl_loss: 137.7482\n",
            "Epoch 82/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 1626.3835 - _calculate_reconstruction_loss: 0.0015 - _calculate_kl_loss: 134.3585\n",
            "Epoch 83/100\n",
            "400/400 [==============================] - 42s 104ms/step - batch: 199.5000 - size: 27.0000 - loss: 1642.7408 - _calculate_reconstruction_loss: 0.0015 - _calculate_kl_loss: 132.7245\n",
            "Epoch 84/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 1657.7223 - _calculate_reconstruction_loss: 0.0015 - _calculate_kl_loss: 131.4647\n",
            "Epoch 85/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 1657.3403 - _calculate_reconstruction_loss: 0.0015 - _calculate_kl_loss: 130.8049\n",
            "Epoch 86/100\n",
            "400/400 [==============================] - 42s 104ms/step - batch: 199.5000 - size: 27.0000 - loss: 1639.8521 - _calculate_reconstruction_loss: 0.0015 - _calculate_kl_loss: 129.4542\n",
            "Epoch 87/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 1608.5685 - _calculate_reconstruction_loss: 0.0015 - _calculate_kl_loss: 127.3326\n",
            "Epoch 88/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 1584.7166 - _calculate_reconstruction_loss: 0.0015 - _calculate_kl_loss: 124.8424\n",
            "Epoch 89/100\n",
            "400/400 [==============================] - 42s 104ms/step - batch: 199.5000 - size: 27.0000 - loss: 1570.4509 - _calculate_reconstruction_loss: 0.0014 - _calculate_kl_loss: 122.6183\n",
            "Epoch 90/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 1566.8010 - _calculate_reconstruction_loss: 0.0014 - _calculate_kl_loss: 120.4411\n",
            "Epoch 91/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 1586.2520 - _calculate_reconstruction_loss: 0.0015 - _calculate_kl_loss: 118.9451\n",
            "Epoch 92/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 1585.6407 - _calculate_reconstruction_loss: 0.0015 - _calculate_kl_loss: 118.3594\n",
            "Epoch 93/100\n",
            "400/400 [==============================] - 42s 104ms/step - batch: 199.5000 - size: 27.0000 - loss: 1556.3964 - _calculate_reconstruction_loss: 0.0014 - _calculate_kl_loss: 116.6675\n",
            "Epoch 94/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 1528.4491 - _calculate_reconstruction_loss: 0.0014 - _calculate_kl_loss: 114.7702\n",
            "Epoch 95/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 1519.0007 - _calculate_reconstruction_loss: 0.0014 - _calculate_kl_loss: 112.7196\n",
            "Epoch 96/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 1509.7362 - _calculate_reconstruction_loss: 0.0014 - _calculate_kl_loss: 110.9099\n",
            "Epoch 97/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 1512.0516 - _calculate_reconstruction_loss: 0.0014 - _calculate_kl_loss: 109.7907\n",
            "Epoch 98/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 1512.4770 - _calculate_reconstruction_loss: 0.0014 - _calculate_kl_loss: 108.8614\n",
            "Epoch 99/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 1498.1139 - _calculate_reconstruction_loss: 0.0014 - _calculate_kl_loss: 107.6965\n",
            "Epoch 100/100\n",
            "400/400 [==============================] - 42s 105ms/step - batch: 199.5000 - size: 27.0000 - loss: 1481.3676 - _calculate_reconstruction_loss: 0.0014 - _calculate_kl_loss: 106.2648\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lg7LJLPT81b6"
      },
      "source": [
        "### Save Meta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvvbXQ1V82wM",
        "outputId": "9cea5ced-be2f-44a0-c61c-f1a42d04beca"
      },
      "source": [
        "# Training History\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
        "ws = gc.open_by_url('https://docs.google.com/spreadsheets/d/12Q6uF-Oy8-Cq6AYFalYJzOjzXCMJhR8HDU3wTmygDmY/edit#gid=1946289387').sheet1\n",
        "all = ws.get_all_records()\n",
        "last_ts = all[-1]['Timestamp']\n",
        "ws.resize(len(all)+1)\n",
        "if last_ts != ts.strftime(\"%Y/%m/%d %H:%M:%S\"):\n",
        "    ws.append_row([\n",
        "                  ts.strftime(\"%Y/%m/%d %H:%M:%S\"),\n",
        "                  str(AMP_IDS),\n",
        "                  str(CLIP_IDS),\n",
        "                  str(CONV_FILTERS),\n",
        "                  str(CONV_KERNELS),\n",
        "                  str(CONV_STRIDES),\n",
        "                  str(LATENT_SPACE_DIM),\n",
        "                  str(LEARNING_RATE),\n",
        "                  str(BATCH_SIZE),\n",
        "                  str(EPOCHS),\n",
        "                  str(int(min(losses))),\n",
        "                  str(losses)\n",
        "    ])\n",
        "else:\n",
        "    print(\"Already added to Training history!\")\n",
        "\n",
        "print(\"Metadata Saved!!\")\n",
        "\n"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metadata Saved!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-a2zPm2-nQd2"
      },
      "source": [
        "### [Broken] Generate the embeddings (Independently executable)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2IhMH3guEs_",
        "outputId": "e2240ee3-6113-4966-a17e-afb85be22bbc"
      },
      "source": [
        "# # https://github.com/musikalkemist/generating-sound-with-neural-networks/blob/49d7db32c43d1a04c596cbbb282a9521be1e7fc8/11%20Implementing%20VAE/code/analysis.py\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa\n",
        "import librosa.display\n",
        "\n",
        "# TODO before running this cell independently\n",
        "# 1. Update the MODEL_NAME\n",
        "# 2. Run the \"Load Data\" cell\n",
        "\n",
        "# UPDATE THE MODEL!!!\n",
        "SPECTROGRAMS_PATH = \"/content/drive/MyDrive/Music/VAE/ICASSP/spectrogram\"\n",
        "MODEL_PATH = \"/content/drive/MyDrive/Music/VAE/ICASSP/music-encoder/model\"\n",
        "\n",
        "# Comes from the Load Data cell\n",
        "dsfilenames = list(set(yfiles)) + xfiles\n",
        "\n",
        "# Not tested!!\n",
        "def plot_reconstructed_images(images, reconstructed_images):\n",
        "    num_images = len(images)\n",
        "    for i, (image, reconstructed_image) in enumerate(zip(images, reconstructed_images)):\n",
        "\n",
        "        fig, ax = plt.subplots()\n",
        "        image = image.squeeze()\n",
        "        img = librosa.display.specshow(image, y_axis='log', x_axis='time', ax=ax)\n",
        "        fig.colorbar(img, ax=ax, format=\"%+2.0f dB\")\n",
        "\n",
        "        fig, ax = plt.subplots()\n",
        "        reconstructed_image = reconstructed_image.squeeze()\n",
        "        recon_img = librosa.display.specshow(reconstructed_image, y_axis='log', x_axis='time', ax=ax)\n",
        "        fig.colorbar(recon_img, ax=ax, format=\"%+2.0f dB\")\n",
        "    plt.show()\n",
        "\n",
        "# Not tested!!\n",
        "def plot_images_encoded_in_latent_space(latent_representations, sample_labels):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.scatter(latent_representations[:, 0],\n",
        "                latent_representations[:, 1],\n",
        "                cmap=\"rainbow\",\n",
        "                c=sample_labels,\n",
        "                alpha=0.5,\n",
        "                s=2)\n",
        "    plt.colorbar()\n",
        "    plt.show()\n",
        "\n",
        "def save_embeddings(musicae, dsfilenames, download_path):\n",
        "\n",
        "\n",
        "    dsspectrogram = []\n",
        "    for filename in dsfilenames:\n",
        "        filepath = os.path.join(SPECTROGRAMS_PATH, filename)\n",
        "        spectrogram = np.load(filepath)\n",
        "        dsspectrogram.append(spectrogram[..., np.newaxis])\n",
        "\n",
        "    dsspectrogram = np.array(dsspectrogram)\n",
        "    latent_representations = musicae.encoder.predict(dsspectrogram)\n",
        "\n",
        "    with open(os.path.join(download_path, 'embeddings.tsv'), 'w', newline='') as f_output:\n",
        "        tsv_output = csv.writer(f_output, delimiter='\\t')\n",
        "        tsv_output.writerows(latent_representations)\n",
        "    # Write corresdonding filenames\n",
        "    with open(os.path.join(download_path, 'embedding-filenames.tsv'), 'a') as f_output:\n",
        "        f_output.seek(0)\n",
        "        f_output.truncate()\n",
        "        for data in dsfilenames:\n",
        "            f_output.write(data)\n",
        "            f_output.write('\\n')\n",
        "    print(\"Embeddings saved!!\")\n",
        "    return latent_representations\n",
        "\n",
        "## Driver coder\n",
        "\n",
        "if musicae == None:\n",
        "    musicae = VAE.load(MODEL_PATH)\n",
        "\n",
        "save_embeddings(musicae, dsfilenames, MODEL_PATH)\n",
        "\n",
        "# reconstructed_images, _ = autoencoder.reconstruct(np.array(list(dataset.values())))\n",
        "# plot_reconstructed_images(sample_images, reconstructed_images)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings saved!!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.94976586,  3.589117  , -5.6696005 , ..., -2.1024005 ,\n",
              "        -0.52547985,  0.53528875],\n",
              "       [-0.39703095,  0.09528753, -1.1663307 , ...,  3.14496   ,\n",
              "        -3.7484055 , -0.44704148],\n",
              "       [-3.3417277 ,  4.7321954 ,  1.7879758 , ..., -2.5602322 ,\n",
              "         0.777218  ,  2.006522  ],\n",
              "       ...,\n",
              "       [ 0.72897494,  4.4406204 ,  3.682107  , ...,  3.967624  ,\n",
              "         7.013556  ,  1.5005401 ],\n",
              "       [-3.957868  , -0.02090748, -1.6777387 , ...,  6.1119556 ,\n",
              "         2.5452788 ,  6.7693944 ],\n",
              "       [-4.885683  ,  2.5795383 , -1.1673104 , ...,  8.482125  ,\n",
              "         2.1263878 ,  3.0961082 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuDjZV1Fxs9d"
      },
      "source": [
        "### test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrMv7xaP5O8l"
      },
      "source": [
        "inputs = Input(shape=(32,))\n",
        "mid = Dense(2)(inputs)\n",
        "outputs = Dense(1)(mid)\n",
        "model = Model(inputs, outputs)\n",
        "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Z2OQsDi6kj0",
        "outputId": "31fabcf3-93e9-4e17-900a-1c74633c9e1a"
      },
      "source": [
        "test_input = np.random.random((128, 32))\n",
        "test_target = np.random.random((128, 1))\n",
        "model.fit(test_input, test_target)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 128 samples\n",
            "128/128 [==============================] - 1s 11ms/sample - loss: 0.2531\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7103de1bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OusbhJJo6oCc",
        "outputId": "2ed42b65-e7be-4a1b-aec9-c6120c785b27"
      },
      "source": [
        "model.save('/content/drive/MyDrive/Music/VAE/ICASSP/tmp')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Music/VAE/ICASSP/tmp/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1z6Oj79epepj",
        "outputId": "46f07952-6c14-41af-d166-6c13057fc078"
      },
      "source": [
        "print(model.outputs)\n",
        "print(model.layers[1].get_config())\n",
        "print(model.layers[1].get_weights())\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<tf.Tensor 'dense_1/BiasAdd:0' shape=(None, 1) dtype=float32>]\n",
            "{'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 2, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
            "[array([[-0.4075677 ,  0.03736704],\n",
            "       [ 0.33599454,  0.01744784],\n",
            "       [-0.05095035, -0.09282304],\n",
            "       [-0.01146705,  0.0266833 ],\n",
            "       [-0.2184882 , -0.38033777],\n",
            "       [-0.41455442, -0.4095814 ],\n",
            "       [ 0.40297043,  0.20315753],\n",
            "       [-0.12497225, -0.23888613],\n",
            "       [ 0.08572217,  0.20766038],\n",
            "       [ 0.04210095, -0.14410129],\n",
            "       [-0.02147608, -0.02591982],\n",
            "       [ 0.27241927,  0.28874815],\n",
            "       [-0.3938247 ,  0.4193524 ],\n",
            "       [ 0.3027814 , -0.3117693 ],\n",
            "       [ 0.13342443,  0.24553962],\n",
            "       [-0.18907784,  0.00208663],\n",
            "       [-0.40545473, -0.21231669],\n",
            "       [ 0.26950115,  0.42039087],\n",
            "       [-0.19123167, -0.01983401],\n",
            "       [ 0.01332134,  0.29213002],\n",
            "       [ 0.33358467, -0.2966309 ],\n",
            "       [-0.18340905, -0.29907537],\n",
            "       [ 0.37802315,  0.00852278],\n",
            "       [-0.08358875, -0.20628898],\n",
            "       [-0.15099894,  0.19588183],\n",
            "       [-0.15138943,  0.1879225 ],\n",
            "       [ 0.35929438,  0.2728458 ],\n",
            "       [-0.3536343 ,  0.37920487],\n",
            "       [-0.41077444,  0.18115307],\n",
            "       [ 0.39061818,  0.05495013],\n",
            "       [-0.2563238 , -0.16152485],\n",
            "       [-0.25270125,  0.33373627]], dtype=float32), array([0.00388095, 0.00388384], dtype=float32)]\n"
          ]
        }
      ]
    }
  ]
}