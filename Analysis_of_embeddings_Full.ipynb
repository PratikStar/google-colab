{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PratikStar/google-colab/blob/main/Analysis_of_embeddings_Full.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYURwxm9HGwG"
      },
      "source": [
        "# Instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k23eHnsF0OGl"
      },
      "source": [
        "Owner: pratik-sutar@g.ecc.u-tokyo.ac.jp\n",
        "\n",
        "**Inputs (Read-only)**\n",
        "\n",
        "Timbre Embeddings: \n",
        "```\n",
        "content/drive/MyDrive/utokyo/08. research/Music/VAE/ICASSP/timbre-encoder/model/embeddings-2021-10-05-11-08-20.tsv\n",
        "content/drive/MyDrive/utokyo/08. research/Music/VAE/ICASSP/timbre-encoder/model/embedding-filenames-2021-10-05-11-08-20.tsv\n",
        "```\n",
        "\n",
        "Music Embeddings: \n",
        "```\n",
        "content/drive/MyDrive/utokyo/08. research/Music/VAE/ICASSP/music-encoder/model/embeddings-2021-10-04-06-08-29.tsv\n",
        "content/drive/MyDrive/utokyo/08. research/Music/VAE/ICASSP/music-encoder/model/embedding-filenames-2021-10-04-06-08-29.tsv\n",
        "```\n",
        "\n",
        "Trained VAE\n",
        "```\n",
        "/content/drive/MyDrive/Music/VAE/ICASSP/timbre-encoder/\n",
        "```\n",
        "\n",
        "**Outputs (write)**\n",
        "\n",
        "Analysis stuff: \n",
        "```\n",
        "content/drive/MyDrive/research/scripts/analysis/\n",
        "```\n",
        "And more...\n",
        "\n",
        "\n",
        "On IST Node\n",
        "\n",
        "```!pip install matplotlib google.colab```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4oy4xthMsY5"
      },
      "source": [
        "# Imports & Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GxnhjT50OaFg"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "import os\n",
        "import inspect\n",
        "import math\n",
        "import json\n",
        "import random\n",
        "\n",
        "SHOW_LOGS = True\n",
        "LOG_LEVEL = 5 # {1-6} High Value -> High verbosity\n",
        "\n",
        "def log(logline, log_level = 1):\n",
        "    if SHOW_LOGS and log_level <= LOG_LEVEL:\n",
        "        stack = inspect.stack()\n",
        "        the_class = None\n",
        "        if \"self\" in stack[1][0].f_locals:\n",
        "            the_class = stack[1][0].f_locals[\"self\"].__class__.__name__\n",
        "        the_method = stack[1][0].f_code.co_name\n",
        "        print(\"{}.{}: {}\".format(the_class, the_method, logline))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Paths"
      ],
      "metadata": {
        "id": "bLVmcNJUpjui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TIMBRE_EMBEDDINGS_PATH = \"/content/drive/Shareddrives/timbre-space-drive/03-training/vae/icassp-2021/timbre-vae/model/embeddings-2021-10-05-11-08-20.tsv\"\n",
        "TIMBRE_EMBEDDINGS_FILENAMES_PATH = \"/content/drive/Shareddrives/timbre-space-drive/03-training/vae/icassp-2021/timbre-vae/model/embedding-filenames-2021-10-05-11-08-20.tsv\"\n",
        "DICTS_SAVE_PATH = '/content/drive/Shareddrives/timbre-space-drive/data/dicts'\n",
        "\n",
        "MUSIC_EMBEDDINGS_PATH = \"/content/drive/Shareddrives/timbre-space-drive/03-training/vae/icassp-2021/music-vae/model/embeddings-2021-10-04-06-08-29.tsv\"\n",
        "MUSIC_EMBEDDINGS_FILENAMES_PATH = \"/content/drive/Shareddrives/timbre-space-drive/03-training/vae/icassp-2021/music-vae/model/embedding-filenames-2021-10-04-06-08-29.tsv\"\n",
        "\n",
        "ANALYSIS_PATH = \"/content/drive/Shareddrives/timbre-space-drive/04-analysis\"\n"
      ],
      "metadata": {
        "id": "q_CLr6JopjR2"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sB5Vh1tu8zxZ"
      },
      "source": [
        "# Connect to Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06K7fkBCmYbW",
        "outputId": "c0049f80-036b-41ba-b8c1-a6b4f498f113"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnYkfQVf-_-d"
      },
      "source": [
        "# Embedding Data loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTlNxU3kzt6S"
      },
      "source": [
        "### get_segmentid_to_timbre_embedding_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OA1KhH-k19yW",
        "outputId": "3bc17b12-db44-4cb7-8e58-8fed3579d9aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None.get_segmentid_to_timbre_embedding_dict: Breaking at line: 10801, due to embedding. All OK!\n"
          ]
        }
      ],
      "source": [
        "# Prerequisite: Drive mounting\n",
        "#   HARD READS the embeddings from TIMBRE_EMBEDDINGS_PATH, TIMBRE_EMBEDDINGS_FILENAMES_PATH\n",
        "#   Needs nothing else\n",
        "def get_segmentid_to_timbre_embedding_dict(save_flg=True, save_path=DICTS_SAVE_PATH):\n",
        "    d_segmentid_to_timbre_embedding = {}\n",
        "    count = 0\n",
        "    with open(TIMBRE_EMBEDDINGS_FILENAMES_PATH, 'r') as keys, open(TIMBRE_EMBEDDINGS_PATH, 'r') as embeddings:\n",
        "        while True: \n",
        "            count += 1\n",
        "            embedding = embeddings.readline().strip().split('\\t')\n",
        "            if len(embedding) < 4:\n",
        "                log(\"Breaking at line: {}, due to embedding. All OK!\".format(count))\n",
        "                break # the length of embedding should be 4\n",
        "            embedding = list(map(float, embedding))\n",
        "            key = keys.readline().split(\" \")[0]\n",
        "            d_segmentid_to_timbre_embedding[key] = embedding\n",
        "            # if line is empty\n",
        "            # end of file is reached\n",
        "            if not key:\n",
        "                log(\"Breaking at line: {}, due to keys\".format(count))\n",
        "                break\n",
        "            # print(\"{}: {}\".format(key.strip(), embedding ))\n",
        "    ## save the dictionary\n",
        "    if save_flg:\n",
        "        with open(os.path.join(save_path, 'd_segmentid_to_timbre_embedding.json'), 'wt') as out:\n",
        "            json.dump(d_segmentid_to_timbre_embedding, out, sort_keys=True, indent=4)\n",
        "    return d_segmentid_to_timbre_embedding\n",
        "\n",
        "d_segmentid_to_timbre_embedding = get_segmentid_to_timbre_embedding_dict(save_flg=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gT2lZwR2BWU"
      },
      "source": [
        "### get_segmentid_to_music_embedding_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzCtm2PDzoOO",
        "outputId": "c95f031e-6d44-4a9c-8da7-f69698d34ab2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None.get_segmentid_to_music_embedding_dict: Breaking at line: 10936, due to embedding. All OK!\n"
          ]
        }
      ],
      "source": [
        "# Prerequisite: Drive mounting\n",
        "#   HARD READS the embeddings from MUSIC_EMBEDDINGS_PATH, MUSIC_EMBEDDINGS_FILENAMES_PATH\n",
        "#   Needs nothing else\n",
        "# Music encoding containes DI clip embeddings which is not included in Timbre embeddings\n",
        "def get_segmentid_to_music_embedding_dict(save_flg=True, save_path=DICTS_SAVE_PATH):\n",
        "    d_segmentid_to_music_embedding = {}\n",
        "    count = 0\n",
        "    with open(MUSIC_EMBEDDINGS_FILENAMES_PATH, 'r') as keys, open(MUSIC_EMBEDDINGS_PATH, 'r') as embeddings:\n",
        "        while True: \n",
        "            count += 1\n",
        "            embedding = embeddings.readline().strip().split('\\t')\n",
        "            if len(embedding) < 4:\n",
        "                log(\"Breaking at line: {}, due to embedding. All OK!\".format(count))\n",
        "                break # the length of embedding should be 4\n",
        "            embedding = list(map(float, embedding))\n",
        "\n",
        "            key = keys.readline().split(\" \")[0]\n",
        "\n",
        "            d_segmentid_to_music_embedding[key] = embedding\n",
        "            # if line is empty\n",
        "            # end of file is reached\n",
        "            if not key:\n",
        "                log(\"Breaking at line: {}, due to keys\".format(count))\n",
        "                break\n",
        "            # print(\"{}: {}\".format(key.strip(), embedding ))\n",
        "    ## save the dictionary\n",
        "    if save_flg:\n",
        "        with open(os.path.join(save_path, 'd_segmentid_to_music_embedding.json'), 'wt') as out:\n",
        "            json.dump(d_segmentid_to_music_embedding, out, sort_keys=True, indent=4)\n",
        "    return d_segmentid_to_music_embedding\n",
        "\n",
        "d_segmentid_to_music_embedding = get_segmentid_to_music_embedding_dict(save_flg=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipxOCcWAFZzf"
      },
      "source": [
        "# Playing with Embeddings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrBcIqDwFnCM"
      },
      "source": [
        "## Passage Embeddings "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5R13NBjrz5M8"
      },
      "source": [
        "### get_passageid_to_list_of_segment_embeddings_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "D6gA5EoZz3ej"
      },
      "outputs": [],
      "source": [
        "# Needs, segment to timbre embedding dict. which can be gotten by get_segment_to_timbre_embedding_dict function.\n",
        "# This function just needs the dict. no file paths etc required.\n",
        "def get_passageid_to_list_of_segment_embeddings_dict(d_segmentid_to_timbre_embedding, save_flg=True, save_path=DICTS_SAVE_PATH):\n",
        "    d_passageid_to_list_of_segment_embeddings = {}\n",
        "    for key, val in d_segmentid_to_timbre_embedding.items():\n",
        "\n",
        "        # In our embeddings file, we have the \"average\" embeddings as per the attributes, we are not interested in that\n",
        "        if re.search(\"^avg.*\", key):\n",
        "            continue\n",
        "        passage = key[:8]\n",
        "        if passage in d_passageid_to_list_of_segment_embeddings:\n",
        "            d_passageid_to_list_of_segment_embeddings[passage].append(val)\n",
        "        else:\n",
        "            d_passageid_to_list_of_segment_embeddings[passage] = [val]\n",
        "    ## save the dictionary\n",
        "    if save_flg:\n",
        "        with open(os.path.join(save_path, 'd_passageid_to_list_of_segment_embeddings.json'), 'wt') as out:\n",
        "            json.dump(d_passageid_to_list_of_segment_embeddings, out, sort_keys=True, indent=4)\n",
        "    return d_passageid_to_list_of_segment_embeddings\n",
        "\n",
        "d_passageid_to_list_of_segment_embeddings = get_passageid_to_list_of_segment_embeddings_dict(d_segmentid_to_timbre_embedding, save_flg=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_QhCO2l0r0_"
      },
      "source": [
        "### [calculate - save]\\_variance_of_passage_embeddings\\_[list - as_csv]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "L4ce8lhQ0rIf"
      },
      "outputs": [],
      "source": [
        "def calculate_variance_of_passage_embeddings_list(d_passageid_to_list_of_segment_embeddings):\n",
        "    d_var = {}\n",
        "    for key, val in d_passageid_to_list_of_segment_embeddings.items():\n",
        "        d_var[key] = np.var(val, axis=0)\n",
        "    return d_var\n",
        "\n",
        "d_passageid_to_variance_of_segment_embeddings = calculate_variance_of_passage_embeddings_list(d_passageid_to_list_of_segment_embeddings)\n",
        "\n",
        "# HARD saves at ANALYSIS_PATH\n",
        "def save_variance_of_passage_embeddings_as_csv(d_passageid_to_variance_of_segment_embeddings, save_path=ANALYSIS_PATH):\n",
        "    file_path = os.path.join(save_path, 'variance_of_passage_embeddings.csv')\n",
        "    with open(file_path, 'w') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\"passage\", \"w-axis\", \"x-axis\", \"y-axis\", \"z-axis\"])\n",
        "        for key, val in d_passageid_to_variance_of_segment_embeddings.items():\n",
        "            writer.writerow([key] + [str(x) for x in val])\n",
        "\n",
        "# Uncomment the following line to save as csv\n",
        "# save_variance_of_passage_embeddings_as_csv(d_passageid_to_variance_of_segment_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoVFiRM90wng"
      },
      "source": [
        "### [calculate - save]\\_mean_of_passage_embeddings\\_[list - as_csv]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "fBX6FgWe0v-X"
      },
      "outputs": [],
      "source": [
        "def calculate_mean_of_passage_embeddings_list(d_passageid_to_list_of_segment_embeddings):\n",
        "    d_mean = {}\n",
        "    for key, val in d_passageid_to_list_of_segment_embeddings.items():\n",
        "        d_mean[key] = np.mean(val, axis=0)\n",
        "\n",
        "    return d_mean\n",
        "\n",
        "d_passageid_to_mean_of_segment_embeddings = calculate_mean_of_passage_embeddings_list(d_passageid_to_list_of_segment_embeddings)\n",
        "\n",
        "# HARD saves at ANALYSIS_PATH\n",
        "def save_mean_of_passage_embeddings_as_csv(d_passageid_to_mean_of_segment_embeddings, save_path=ANALYSIS_PATH): \n",
        "    file_path = os.path.join(save_path, 'mean_of_passage_embeddings.csv')\n",
        "    with open(file_path, 'w') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\"passage\", \"w-axis\", \"x-axis\", \"y-axis\", \"z-axis\"])\n",
        "        for key,val in d_passageid_to_mean_of_segment_embeddings.items():\n",
        "            writer.writerow([key] + [str(x) for x in val])\n",
        "\n",
        "# Uncomment the following line to save as csv\n",
        "# save_mean_of_passage_embeddings_as_csv(d_passageid_to_mean_of_segment_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osFMuMiwF6I2"
      },
      "source": [
        "## Clip Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3lUqdY3_dPV"
      },
      "source": [
        "### get_clipid_to_list_of_segment_embeddings_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "-yW7my61_Zyi"
      },
      "outputs": [],
      "source": [
        "# Needs, segment to timbre embedding dict. which can be gotten by get_segment_to_timbre_embedding_dict function.\n",
        "# This function just needs the dict. no file paths etc required.\n",
        "def get_clipid_to_list_of_segment_embeddings_dict(d_segmentid_to_timbre_embedding, save_flg=True, save_path=DICTS_SAVE_PATH):\n",
        "    d_clipid_to_list_of_segment_embeddings = {}\n",
        "    for key, val in d_segmentid_to_timbre_embedding.items():\n",
        "        clip = key[:5]\n",
        "        if clip in d_clipid_to_list_of_segment_embeddings:\n",
        "            d_clipid_to_list_of_segment_embeddings[clip].append(val)\n",
        "        else:\n",
        "            d_clipid_to_list_of_segment_embeddings[clip] = [val]\n",
        "    ## save the dictionary\n",
        "    if save_flg:\n",
        "        with open(os.path.join(save_path, 'd_clipid_to_list_of_segment_embeddings.json'), 'wt') as out:\n",
        "            json.dump(d_passageid_to_list_of_segment_embeddings, out, sort_keys=True, indent=4)\n",
        "    return d_clipid_to_list_of_segment_embeddings\n",
        "\n",
        "d_clipid_to_list_of_segment_embeddings = get_clipid_to_list_of_segment_embeddings_dict(d_segmentid_to_timbre_embedding, save_flg=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jfvStelBPhS"
      },
      "source": [
        "### [calculate - save]\\_variance_of_clip_embeddings\\_[list - as_csv]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "v7dLlcYOBQ9A"
      },
      "outputs": [],
      "source": [
        "def calculate_variance_of_clip_embeddings_list(d_clipid_to_list_of_segment_embeddings):\n",
        "    d_var = {}\n",
        "    for key, val in d_clipid_to_list_of_segment_embeddings.items():\n",
        "        d_var[key] = np.var(val, axis=0)\n",
        "\n",
        "    return d_var\n",
        "\n",
        "d_clipid_to_variance_of_segment_embeddings = calculate_variance_of_clip_embeddings_list(d_clipid_to_list_of_segment_embeddings)\n",
        "\n",
        "# HARD saves in ANALYSIS_PATH\n",
        "def save_variance_of_clip_embeddings_as_csv(d_clipid_to_variance_of_segment_embeddings, save_path=ANALYSIS_PATH):\n",
        "    file_path = os.path.join(save_path, 'variance_of_clip_embeddings.csv')\n",
        "    with open(file_path, 'w') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\"passage\", \"w-axis\", \"x-axis\", \"y-axis\", \"z-axis\"])\n",
        "        for key, val in d_clipid_to_variance_of_segment_embeddings.items():\n",
        "            writer.writerow([key] + [str(x) for x in val])\n",
        "\n",
        "# save_variance_of_clip_embeddings_as_csv(d_clipid_to_variance_of_segment_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBKKEjUDBwZB"
      },
      "source": [
        "### [calculate - save]\\_mean_of_clip_embeddings\\_[list - as_csv]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "bVbPUvm3Bu3-"
      },
      "outputs": [],
      "source": [
        "def calculate_mean_of_clip_embeddings_list(d_clipid_to_list_of_segment_embeddings):\n",
        "    d_mean = {}\n",
        "    for key, val in d_clipid_to_list_of_segment_embeddings.items():\n",
        "        d_mean[key] = np.mean(val, axis=0)\n",
        "\n",
        "    return d_mean\n",
        "\n",
        "d_clipid_to_mean_of_segment_embeddings = calculate_mean_of_clip_embeddings_list(d_clipid_to_list_of_segment_embeddings)\n",
        "\n",
        "# HARD saves in ANALYSIS_PATH\n",
        "def save_mean_of_clip_embeddings_as_csv(d_clipid_to_mean_of_segment_embeddings, save_path=ANALYSIS_PATH):\n",
        "    file_path = os.path.join(save_path, 'mean_of_clip_embeddings.csv')\n",
        "    with open(file_path, 'w') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\"passage\", \"w-axis\", \"x-axis\", \"y-axis\", \"z-axis\"])\n",
        "        for key,val in d_clipid_to_mean_of_segment_embeddings.items():\n",
        "            writer.writerow([key] + [str(x) for x in val])\n",
        "\n",
        "# save_mean_of_clip_embeddings_as_csv(d_clipid_to_mean_of_segment_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntzk5UTp1s3c"
      },
      "source": [
        "## visualize_in_2d_any_key_to_embedding_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Wemlfb8a1sAe"
      },
      "outputs": [],
      "source": [
        "def visualize_in_2d_any_key_to_embedding_dict(d_key_to_embedding, name=\"Plot\", save_path=ANALYSIS_PATH, dpi=120, save_flg=False):\n",
        "    fig, axs = plt.subplots(nrows=2, ncols=3, constrained_layout=True, figsize=(20, 10), dpi=dpi)\n",
        "    fig.suptitle(name)\n",
        "    axs[0][0].scatter([v[0] for v in d_key_to_embedding.values()], [v[1] for v in d_key_to_embedding.values()], s=10, c='red')\n",
        "    axs[0][0].set_title('w-x plot')\n",
        "\n",
        "    axs[0][1].scatter([v[0] for v in d_key_to_embedding.values()], [v[2] for v in d_key_to_embedding.values()], s=10, c='blue')\n",
        "    axs[0][1].set_title('w-y plot')\n",
        "\n",
        "    axs[0][2].scatter([v[0] for v in d_key_to_embedding.values()], [v[3] for v in d_key_to_embedding.values()], s=10, c='green')\n",
        "    axs[0][2].set_title('w-z plot')\n",
        "\n",
        "    axs[1][0].scatter([v[1] for v in d_key_to_embedding.values()], [v[2] for v in d_key_to_embedding.values()], s=10, c='orange')\n",
        "    axs[1][0].set_title('x-y plot')\n",
        "\n",
        "    axs[1][1].scatter([v[1] for v in d_key_to_embedding.values()], [v[3] for v in d_key_to_embedding.values()], s=10, c='cyan')\n",
        "    axs[1][1].set_title('x-z plot')\n",
        "\n",
        "    axs[1][2].scatter([v[2] for v in d_key_to_embedding.values()], [v[3] for v in d_key_to_embedding.values()], s=10, c='pink')\n",
        "    axs[1][2].set_title('y-z plot')\n",
        "\n",
        "    for label in d_key_to_embedding.keys():\n",
        "        axs[0][0].annotate(label, (d_key_to_embedding[label][0], d_key_to_embedding[label][1]), fontsize=2)\n",
        "        axs[0][1].annotate(label, (d_key_to_embedding[label][0], d_key_to_embedding[label][2]), fontsize=2)\n",
        "        axs[0][2].annotate(label, (d_key_to_embedding[label][0], d_key_to_embedding[label][3]), fontsize=2)\n",
        "        axs[1][0].annotate(label, (d_key_to_embedding[label][1], d_key_to_embedding[label][2]), fontsize=2)\n",
        "        axs[1][1].annotate(label, (d_key_to_embedding[label][1], d_key_to_embedding[label][3]), fontsize=2)\n",
        "        axs[1][2].annotate(label, (d_key_to_embedding[label][2], d_key_to_embedding[label][3]), fontsize=2)\n",
        "    if save_flg:\n",
        "        plt.savefig(os.path.join(save_path, name +'.png'))\n",
        "    plt.show()\n",
        "    plt.close('all') \n",
        "    return fig, axs\n",
        "\n",
        "# fig, axs = visualize_in_2d_any_key_to_embedding_dict(d_clipid_to_mean_of_segment_embeddings, name=\"mean of clip embeddings\", dpi=120, save_flg=False)\n",
        "# fig, axs = visualize_in_2d_any_key_to_embedding_dict(d_clipid_to_variance_of_segment_embeddings, name=\"variance of clip embeddings\", dpi=120, save_flg=False)\n",
        "# fig, axs = visualize_in_2d_any_key_to_embedding_dict(d_passageid_to_mean_of_segment_embeddings, name=\"mean of passage embeddings\", dpi=120, save_flg=False)\n",
        "# fig, axs = visualize_in_2d_any_key_to_embedding_dict(d_passageid_to_variance_of_segment_embeddings, name=\"variance of passage embeddings\", dpi=120, save_flg=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Svm_rpbO12Wc"
      },
      "source": [
        "# Playing with Annotations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90vAT14EslAU"
      },
      "source": [
        "### Imports & setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "rofrWoIvsjge"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "import os.path\n",
        "import pandas as pd\n",
        "import pprint\n",
        "import json\n",
        "import sys\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paths"
      ],
      "metadata": {
        "id": "HBg6R1ph2Kbl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EXPORTS_DYNAMO_DIRECTORY = \"/content/drive/Shareddrives/timbre-space-drive/data/exports-dynamo\"\n",
        "TIMBRE_SURVEY_EXPORT = os.path.join(EXPORTS_DYNAMO_DIRECTORY, '20210905160610-timbre_survey.csv')"
      ],
      "metadata": {
        "id": "xlOYZtJq2Iwd"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAWpPnfuKNWD"
      },
      "source": [
        "### get_attribute_to_count_of_pairwise_annotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "gMvn3DmAs4Ri"
      },
      "outputs": [],
      "source": [
        "# Returns: { <attribute>: count}\n",
        "# Interpretation: <attribute> was asked in a pairwise question AND the answer chosen (clip_a/clip_b)\n",
        "def get_attribute_to_count_of_pairwise_annotations(timbre_survey_export, save_flg=True, save_path=DICTS_SAVE_PATH):\n",
        "    d_attribute_to_count_of_pairwise_annotations = {}\n",
        "    with open(timbre_survey_export, 'r', newline='')  as f:\n",
        "        reader = csv.DictReader(f, delimiter=',')\n",
        "        for row in reader:\n",
        "            ## The person has not actually listened. TODO: check when the feature was added and filter the data since that date.\n",
        "            # if len(row['clicks']) == 0:\n",
        "            #     print('Unclicked annotation')\n",
        "            #     continue\n",
        "\n",
        "            ans = row['answer']\n",
        "            ## The answer is 'Not Applicable'\n",
        "            if ans not in ['clip_a', 'clip_b']:\n",
        "                continue\n",
        "            attribute = row['attribute']\n",
        "\n",
        "            if attribute not in d_attribute_to_count_of_pairwise_annotations:\n",
        "                d_attribute_to_count_of_pairwise_annotations[attribute] = 1\n",
        "            else:\n",
        "                d_attribute_to_count_of_pairwise_annotations[attribute] += 1\n",
        "\n",
        "\n",
        "    ## save the dictionary\n",
        "    if save_flg:\n",
        "        with open(os.path.join(save_path, 'd_attribute_to_count_of_pairwise_annotations.json'), 'wt') as out:\n",
        "            json.dump(d_attribute_to_count_of_pairwise_annotations, out, sort_keys=True, indent=4)\n",
        "    return d_attribute_to_count_of_pairwise_annotations\n",
        "\n",
        "d_attribute_to_count_of_pairwise_annotations = get_attribute_to_count_of_pairwise_annotations(TIMBRE_SURVEY_EXPORT, save_flg=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqxB12aGs52q"
      },
      "source": [
        "### get_attribute_to_pairwise_comparision_result_for_arrow_plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "VjBFoLzLJtmG"
      },
      "outputs": [],
      "source": [
        "# Returns: { <attribute>: [[clip_a, clip_b], [..., ...]]}\n",
        "# Here clip_b is the answer\n",
        "def get_attribute_to_pairwise_comparision_result_for_arrow_plot(timbre_survey_export, save_flg=True, save_path=DICTS_SAVE_PATH):\n",
        "    d_attribute_to_pairwise_comparision_result = {} \n",
        "    with open(timbre_survey_export, 'r', newline='')  as f:\n",
        "        reader = csv.DictReader(f, delimiter=',')\n",
        "        for row in reader:\n",
        "            ## The person has not actually listened. TODO: check when the feature was added and filter the data since that date.\n",
        "            # if len(row['clicks']) == 0:\n",
        "            #     print('Unclicked annotation')\n",
        "            #     continue\n",
        "\n",
        "            ans = row['answer']\n",
        "            ## The answer is 'Not Applicable'\n",
        "            if ans not in ['clip_a', 'clip_b']:\n",
        "                continue\n",
        "\n",
        "            attribute = row['attribute']\n",
        "            ans_clip = row[ans]\n",
        "            nonans_clip = row['clip_b' if ans == 'clip_a' else 'clip_a']\n",
        "\n",
        "            if attribute not in d_attribute_to_pairwise_comparision_result:\n",
        "                d_attribute_to_pairwise_comparision_result[attribute] = []\n",
        "            d_attribute_to_pairwise_comparision_result[attribute].append(\n",
        "                [nonans_clip, ans_clip]\n",
        "            )\n",
        "\n",
        "\n",
        "    ## save the dictionary\n",
        "    if save_flg:\n",
        "        with open(os.path.join(save_path, 'd_attribute_to_pairwise_comparision_result.json'), 'wt') as out:\n",
        "            json.dump(d_attribute_to_pairwise_comparision_result, out, sort_keys=True, indent=4)\n",
        "    return d_attribute_to_pairwise_comparision_result\n",
        "\n",
        "d_attribute_to_pairwise_comparision_result = get_attribute_to_pairwise_comparision_result_for_arrow_plot(TIMBRE_SURVEY_EXPORT, save_flg=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWZNQmYguZMZ"
      },
      "source": [
        "### get_passage_vs_attribute_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "j12IheazuXmV"
      },
      "outputs": [],
      "source": [
        "def get_passage_vs_attribute_df(timbre_survey_export, save_flg_passage_to_attribute_to_score=True, save_path=DICTS_SAVE_PATH):\n",
        "    d = {} ## passage -> attribute\n",
        "    with open(timbre_survey_export, 'r', newline='')  as f:\n",
        "        reader = csv.DictReader(f, delimiter=',')\n",
        "        for row in reader:\n",
        "\n",
        "            ## The person has not actually listened\n",
        "            # if len(row['clicks']) == 0:\n",
        "            #     print('Unclicked annotation')\n",
        "            #     continue\n",
        "\n",
        "            ans = row['answer']\n",
        "            ## TODO. Improve the shabby code\n",
        "            if ans in ['clip_a', 'clip_b']:\n",
        "                passage = row[ans]\n",
        "\n",
        "                attribute = row['attribute']\n",
        "\n",
        "                if row['clip_a'] not in d:\n",
        "                    d[row['clip_a']] = {}\n",
        "                    d[row['clip_a']][attribute] = 1 if ans == 'clip_a' else -1\n",
        "                else:\n",
        "                    if attribute not in d[row['clip_a']]:\n",
        "                        d[row['clip_a']][attribute] = 1 if ans == 'clip_a' else -1\n",
        "                    else:\n",
        "                        if ans == 'clip_a':\n",
        "                            d[row['clip_a']][attribute] += 1\n",
        "                        else:\n",
        "                            d[row['clip_a']][attribute] -= 1\n",
        "\n",
        "                if row['clip_b'] not in d:\n",
        "                    d[row['clip_b']] = {}\n",
        "                    d[row['clip_b']][attribute] = 1 if ans == 'clip_b' else -1\n",
        "                else:\n",
        "                    if attribute not in d[row['clip_b']]:\n",
        "                        d[row['clip_b']][attribute] = 1 if ans == 'clip_b' else -1\n",
        "                    else:\n",
        "                        if ans == 'clip_b':\n",
        "                            d[row['clip_b']][attribute] += 1\n",
        "                        else:\n",
        "                            d[row['clip_b']][attribute] -= 1\n",
        "\n",
        "            # Processing \"others\"\n",
        "            ## The 'others' string is empty\n",
        "            ## Note: row['others'] is a string\n",
        "            if len(row['others']) <= 2:\n",
        "                continue\n",
        "\n",
        "            attributes = row['others'][1:-1].replace('\\'', '').replace(' ', '').split(',')\n",
        "            \n",
        "            for attribute in attributes:\n",
        "                if passage in d:\n",
        "                    if attribute in d[passage]:\n",
        "                        d[passage][attribute] += 1\n",
        "                    else:\n",
        "                        d[passage][attribute] = 1\n",
        "                else:\n",
        "                    d[passage] = {}\n",
        "                    d[passage][attribute] = 1\n",
        "\n",
        "    ## Save the dictionary\n",
        "    if save_flg_passage_to_attribute_to_score:\n",
        "        with open(os.path.join(save_path, 'd_passage_to_attribute_to_score.json'), 'wt') as out:\n",
        "            json.dump(d, out, sort_keys=True, indent=4)\n",
        "\n",
        "    df = pd.DataFrame.from_dict(data=d)\n",
        "    df = df.T # transpose the DF. Now, rows -> passages, columns -> attributes\n",
        "    \n",
        "    # print(df)\n",
        "    return df\n",
        "\n",
        "df = get_passage_vs_attribute_df(TIMBRE_SURVEY_EXPORT, save_flg_passage_to_attribute_to_score=True)\n",
        "# df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jv1ypffJvQ48"
      },
      "source": [
        "### get_attribute_to_passage_to_score_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "kW65zWvfvOMG"
      },
      "outputs": [],
      "source": [
        "# Input to this will be clips x attributes dataframe. Using get_passage_vs_attribute_df\n",
        "def get_attribute_to_passage_to_score_dict(df, save_flg=True, save_path=DICTS_SAVE_PATH):\n",
        "    d_attribute_to_passage_to_score = {}\n",
        "    for (attribute, passages) in df.iteritems():\n",
        "        # print(attribute)\n",
        "        # print(passages)\n",
        "        d_attribute_to_passage_to_score[attribute] = {}\n",
        "        for passage, score in passages.items():\n",
        "            if pd.notnull(score):\n",
        "                d_attribute_to_passage_to_score[attribute][passage] = score\n",
        "                # print(passage)\n",
        "                # print(score)\n",
        "    ## Save the dictionary\n",
        "    with open(os.path.join(save_path, 'd_attribute_to_passage_to_score.json'), 'wt') as out:\n",
        "        json.dump(d_attribute_to_passage_to_score, out, sort_keys=True, indent=4)\n",
        "    return d_attribute_to_passage_to_score\n",
        "\n",
        "d_attribute_to_passage_to_score = get_attribute_to_passage_to_score_dict(df, save_flg=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9RMl8Ou4a6e"
      },
      "source": [
        "### get_attribute_to_min_and_max_score_points_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "mX-vdCrp4W-O"
      },
      "outputs": [],
      "source": [
        "# Calculates the weighted mean of positive score points and negative score points\n",
        "def get_attribute_to_min_and_max_score_points_dict(d_attribute_to_passage_to_score, d_passage_to_mean_of_segment_embeddings, save_flg=True, save_path=DICTS_SAVE_PATH):\n",
        "    d_attribute_to_min_and_max_score_points = {}\n",
        "    for attribute, d_passage_to_score in d_attribute_to_passage_to_score.items():\n",
        "        d_neg_passages_to_scores = {passageid: score for passageid, score in d_passage_to_score.items() if score < 0}\n",
        "        d_pos_passages_to_scores = {passageid: score for passageid, score in d_passage_to_score.items() if score > 0} # excluding 0s\n",
        "\n",
        "        d_neg_passages_to_embeddings = {passageid: em for passageid, em in d_passage_to_mean_of_segment_embeddings.items() if passageid in d_neg_passages_to_scores.keys()}\n",
        "        d_pos_passages_to_embeddings = {passageid: em for passageid, em in d_passage_to_mean_of_segment_embeddings.items() if passageid in d_pos_passages_to_scores.keys()}\n",
        "\n",
        "        # calculating neg average\n",
        "        neg_embeddings = []\n",
        "        neg_scores = []\n",
        "        for passageid in d_neg_passages_to_scores:\n",
        "            neg_scores.append(abs(d_neg_passages_to_scores[passageid]))\n",
        "            neg_embeddings.append(d_neg_passages_to_embeddings[passageid])\n",
        "        # log(neg_embeddings)\n",
        "        # log(neg_scores)\n",
        "        if len(neg_embeddings) == 0 or len(neg_scores) == 0:\n",
        "            log(\"Skipping the passageid: {}\".format(passageid))\n",
        "            break\n",
        "        average_neg_embedding = np.average(neg_embeddings, weights=neg_scores, axis=0)\n",
        "        # log(average_neg_embedding)\n",
        "\n",
        "        # calculating pos average\n",
        "        pos_embeddings = []\n",
        "        pos_scores = []\n",
        "        for passageid in d_pos_passages_to_scores:\n",
        "            pos_scores.append(abs(d_pos_passages_to_scores[passageid]))\n",
        "            pos_embeddings.append(d_pos_passages_to_embeddings[passageid])\n",
        "        # log(pos_embeddings)\n",
        "        # log(pos_scores)\n",
        "        if len(pos_embeddings) == 0 or len(pos_scores) == 0:\n",
        "            log(\"Skipping the passageid: {}\".format(passageid))\n",
        "            break\n",
        "        average_pos_embedding = np.average(pos_embeddings, weights=pos_scores, axis=0)\n",
        "        # log(average_pos_embedding)\n",
        "\n",
        "        d_attribute_to_min_and_max_score_points[attribute] = {\"min\": average_neg_embedding.tolist(), \"max\": average_pos_embedding.tolist()}\n",
        "        ## Save the dictionary\n",
        "        with open(os.path.join(save_path, 'd_attribute_to_min_and_max_score_points.json'), 'wt') as out:\n",
        "            json.dump(d_attribute_to_min_and_max_score_points, out, sort_keys=True, indent=4)\n",
        "    return d_attribute_to_min_and_max_score_points\n",
        "\n",
        "d_attribute_to_min_and_max_score_points = get_attribute_to_min_and_max_score_points_dict(d_attribute_to_passage_to_score, d_passageid_to_mean_of_segment_embeddings, save_flg=True)\n",
        "# d_attribute_to_min_and_max_score_points"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YA4kfeEPPSW"
      },
      "source": [
        "### plot_arrow_plot_from_pairwise_comparision_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "iX-J3xXTPNvX"
      },
      "outputs": [],
      "source": [
        "ARROW_PLOT_SAVE_PATH = os.path.join(ANALYSIS_PATH, 'visualization/arrow')\n",
        "def plot_arrow_plot_from_pairwise_comparision_result(attribute, list_of_a_to_b_clips, filename, d_passageid_to_mean_of_segment_embeddings, dpi=120, visualize_flg=False, save_flg=True, save_path=ARROW_PLOT_SAVE_PATH):\n",
        "    print(attribute)\n",
        "    # print(list_of_a_to_b_clips)\n",
        "\n",
        "    a,b = [],[]\n",
        "    for pair in list_of_a_to_b_clips:\n",
        "        a.append(d_passageid_to_mean_of_segment_embeddings[pair[0]])\n",
        "        b.append(d_passageid_to_mean_of_segment_embeddings[pair[1]])\n",
        "\n",
        "    flat = [x for row in a+b for x in row]\n",
        "    neglim = -1 * min(flat) if min(flat) < 0 else min(flat)\n",
        "    poslim = max(flat)\n",
        "    lim = max(neglim, poslim)\n",
        "\n",
        "    if not os.path.exists(save_path):\n",
        "        os.makedirs(save_path)\n",
        "\n",
        "    fig, axs = plt.subplots(nrows=2, ncols=3, constrained_layout=True, figsize=(20, 10), dpi=dpi)\n",
        "    fig.suptitle(\"{}: arrow plot for pairwise annotations results\".format(attribute), fontsize='xx-large')\n",
        "  \n",
        "    for plot in range(6):\n",
        "        px = plot // 3\n",
        "        py = plot % 3\n",
        "        x = min (px, py)\n",
        "        y = px + py\n",
        "\n",
        "        for i in range(len(a)):\n",
        "            xi = a[i][x]\n",
        "            xj = a[i][y]\n",
        "            yi = b[i][x]\n",
        "            yj = b[i][y]\n",
        "            # print(\"For {} {} & {} {}\".format(xi, xj, yi, yj))\n",
        "\n",
        "            axs[px][py].arrow(xi, xj, yi - xi, yj - xj, width = 0.01, head_width=0.1)\n",
        "            axs[px][py].set_xlim([-1 * lim, lim])\n",
        "            axs[px][py].set_ylim([-1 * lim, lim])\n",
        "\n",
        "    if visualize_flg:\n",
        "        plt.show()\n",
        "    if save_flg:\n",
        "        plt.savefig(os.path.join(save_path, filename +'.png'))\n",
        "    plt.close(fig) \n",
        "\n",
        "\n",
        "# Driver: Tested OK! And generated .pngs\n",
        "# for attribute, pairwise_comparision_result in d_attribute_to_pairwise_comparision_result.items():\n",
        "#     filename = str(d_attribute_to_count_of_pairwise_annotations[attribute]) + \"-\" + attribute\n",
        "#     plot_arrow_plot_from_pairwise_comparision_result(attribute, pairwise_comparision_result, filename, d_passageid_to_mean_of_segment_embeddings, visualize_flg=False, save_flg=True, dpi=300)\n",
        "\n",
        "# Analysis. The below plots show good results\n",
        "# Airy Artificial, \"Bell-like\", \"Brilliant\", \"Brittle\", Brutal, buzzy, Clear, Cutting, Dirty, \"Distorted\"\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJ0IuuNE4OVM"
      },
      "source": [
        "### plot_negative_vs_positive_passages_by_score_for_given_attribute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "vvHpg-jHgdqN"
      },
      "outputs": [],
      "source": [
        "POS_NEG_PLOT_SAVE_PATH = os.path.join(ANALYSIS_PATH, 'visualization/pos_neg')\n",
        "def plot_negative_vs_positive_passages_by_score_for_given_attribute(attribute, d_passageid_to_mean_of_segment_embeddings, d_passage_to_score, dpi=120, visualize_flg=False, save_flg=True, save_path=POS_NEG_PLOT_SAVE_PATH):\n",
        "    print(attribute)\n",
        "    print(\"Number of annotations: {} \".format(len(d_passage_to_score)))\n",
        "    # print({k: v for k, v in sorted(d_passage_to_score.items(), key=lambda item: item[1], reverse=True)})\n",
        "\n",
        "    neg_passages = [k for k in d_passage_to_score if d_passage_to_score[k] < 0]\n",
        "    pos_passages = [k for k in d_passage_to_score if d_passage_to_score[k] >= 0]\n",
        "\n",
        "    neg_embeddings = [em for k, em in d_passageid_to_mean_of_segment_embeddings.items() if k in neg_passages]\n",
        "    pos_embeddings = [em for k, em in d_passageid_to_mean_of_segment_embeddings.items() if k in pos_passages]\n",
        "\n",
        "#   print(neg_embeddings)\n",
        "#   print(pos_embeddings)\n",
        "\n",
        "    if not os.path.exists(save_path):\n",
        "        os.makedirs(save_path)\n",
        "    fig, axs = plt.subplots(nrows=2, ncols=3, constrained_layout=True, figsize=(20, 10), dpi=dpi)\n",
        "    fig.suptitle(\"\\\"{}\\\": negative-score (red) v/s positive-score (blue) Annotations Plot. Anno-count: {}\".format(attribute, len(d_passage_to_score)), fontsize='xx-large')\n",
        "\n",
        "    axs[0][0].scatter([v[0] for v in neg_embeddings], [v[1] for v in neg_embeddings], s=10, c='red')\n",
        "    axs[0][0].scatter([v[0] for v in pos_embeddings], [v[1] for v in pos_embeddings], s=10, c='blue')\n",
        "    axs[0][0].set_title('w-x plot')\n",
        "\n",
        "    axs[0][1].scatter([v[0] for v in neg_embeddings], [v[2] for v in neg_embeddings], s=10, c='red')\n",
        "    axs[0][1].scatter([v[0] for v in pos_embeddings], [v[2] for v in pos_embeddings], s=10, c='blue')\n",
        "    axs[0][1].set_title('w-y plot')\n",
        "\n",
        "    axs[0][2].scatter([v[0] for v in neg_embeddings], [v[3] for v in neg_embeddings], s=10, c='red')\n",
        "    axs[0][2].scatter([v[0] for v in pos_embeddings], [v[3] for v in pos_embeddings], s=10, c='blue')\n",
        "    axs[0][2].set_title('w-z plot')\n",
        "\n",
        "    axs[1][0].scatter([v[1] for v in neg_embeddings], [v[2] for v in neg_embeddings], s=10, c='red')\n",
        "    axs[1][0].scatter([v[1] for v in pos_embeddings], [v[2] for v in pos_embeddings], s=10, c='blue')\n",
        "    axs[1][0].set_title('x-y plot')\n",
        "\n",
        "    axs[1][1].scatter([v[1] for v in neg_embeddings], [v[3] for v in neg_embeddings], s=10, c='red')\n",
        "    axs[1][1].scatter([v[1] for v in pos_embeddings], [v[3] for v in pos_embeddings], s=10, c='blue')\n",
        "    axs[1][1].set_title('x-z plot')\n",
        "\n",
        "    axs[1][2].scatter([v[2] for v in neg_embeddings], [v[3] for v in neg_embeddings], s=10, c='red')\n",
        "    axs[1][2].scatter([v[2] for v in pos_embeddings], [v[3] for v in pos_embeddings], s=10, c='blue')\n",
        "    axs[1][2].set_title('y-z plot')\n",
        "\n",
        "    if visualize_flg:\n",
        "        plt.show()\n",
        "    if save_flg:\n",
        "        plt.savefig(os.path.join(save_path, attribute +'.png'))\n",
        "    plt.close(fig)\n",
        "\n",
        "# Driver: Tested OK! And generated .pngs\n",
        "# for attribute, passage_to_score in d_attribute_to_passage_to_score.items():\n",
        "#     plot_negative_vs_positive_passages_by_score_for_given_attribute(attribute, d_passageid_to_mean_of_segment_embeddings, passage_to_score, dpi=300, visualize_flg=False, save_flg=True)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Playing with plotting"
      ],
      "metadata": {
        "id": "FkDy1EycreNp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "o1BKmR8lrcAo"
      },
      "outputs": [],
      "source": [
        "ANALYSIS_PATH = \"/content/drive/Shareddrives/timbre-space-drive/04-analysis\"\n",
        "def visualize_in_2d_list_of_dicts(list_of_d_key_to_embedding, attributes, colors, name=\"Plot\", save_path=ANALYSIS_PATH, annotate=True, dpi=120, save_flg=False):\n",
        "    if len(list_of_d_key_to_embedding) != len(colors):\n",
        "        print(\"len(list_of_d_key_to_embedding) != len(colors)...\")\n",
        "        return\n",
        "\n",
        "    fig, axs = plt.subplots(nrows=2, ncols=3, constrained_layout=True, figsize=(20, 10), dpi=dpi)\n",
        "    fig.suptitle(name)\n",
        "    for i in range(len(colors)):\n",
        "        axs[0][0].scatter([v[0] for v in list_of_d_key_to_embedding[i].values()], [v[1] for v in list_of_d_key_to_embedding[i].values()], s=10, c=colors[i], label=attributes[i])\n",
        "        axs[0][0].set_title('w-x plot')\n",
        "        axs[0][0].legend()\n",
        "\n",
        "        axs[0][1].scatter([v[0] for v in list_of_d_key_to_embedding[i].values()], [v[2] for v in list_of_d_key_to_embedding[i].values()], s=10, c=colors[i], label=attributes[i])\n",
        "        axs[0][1].set_title('w-y plot')\n",
        "        axs[0][1].legend()\n",
        "\n",
        "        axs[0][2].scatter([v[0] for v in list_of_d_key_to_embedding[i].values()], [v[3] for v in list_of_d_key_to_embedding[i].values()], s=10, c=colors[i], label=attributes[i])\n",
        "        axs[0][2].set_title('w-z plot')\n",
        "        axs[0][2].legend()\n",
        "\n",
        "        axs[1][0].scatter([v[1] for v in list_of_d_key_to_embedding[i].values()], [v[2] for v in list_of_d_key_to_embedding[i].values()], s=10, c=colors[i], label=attributes[i])\n",
        "        axs[1][0].set_title('x-y plot')\n",
        "        axs[1][0].legend()\n",
        "\n",
        "        axs[1][1].scatter([v[1] for v in list_of_d_key_to_embedding[i].values()], [v[3] for v in list_of_d_key_to_embedding[i].values()], s=10, c=colors[i], label=attributes[i])\n",
        "        axs[1][1].set_title('x-z plot')\n",
        "        axs[1][1].legend()\n",
        "\n",
        "        axs[1][2].scatter([v[2] for v in list_of_d_key_to_embedding[i].values()], [v[3] for v in list_of_d_key_to_embedding[i].values()], s=10, c=colors[i], label=attributes[i])\n",
        "        axs[1][2].set_title('y-z plot')\n",
        "        axs[1][2].legend()\n",
        "\n",
        "        if not annotate:\n",
        "            continue\n",
        "\n",
        "        for label in list_of_d_key_to_embedding[i].keys():\n",
        "            axs[0][0].annotate(label, (list_of_d_key_to_embedding[i][label][0], list_of_d_key_to_embedding[i][label][1]), fontsize=2)\n",
        "            axs[0][1].annotate(label, (list_of_d_key_to_embedding[i][label][0], list_of_d_key_to_embedding[i][label][2]), fontsize=2)\n",
        "            axs[0][2].annotate(label, (list_of_d_key_to_embedding[i][label][0], list_of_d_key_to_embedding[i][label][3]), fontsize=2)\n",
        "            axs[1][0].annotate(label, (list_of_d_key_to_embedding[i][label][1], list_of_d_key_to_embedding[i][label][2]), fontsize=2)\n",
        "            axs[1][1].annotate(label, (list_of_d_key_to_embedding[i][label][1], list_of_d_key_to_embedding[i][label][3]), fontsize=2)\n",
        "            axs[1][2].annotate(label, (list_of_d_key_to_embedding[i][label][2], list_of_d_key_to_embedding[i][label][3]), fontsize=2)\n",
        "\n",
        "    # handles, labels = axs[1][2].get_legend_handles_labels()\n",
        "    # fig.legend(handles, labels, loc='lower center', bbox_to_anchor=(0.5, -0.05),\n",
        "    #       fancybox=True, shadow=True, ncol=4)\n",
        "\n",
        "    if save_flg:\n",
        "        plt.savefig(os.path.join(save_path, name +'.png'))\n",
        "    plt.show()\n",
        "    # plt.close('all') \n",
        "    return fig, axs\n",
        "\n",
        "attributes = ['All', 'Bright', \"Distorted\"]\n",
        "colors = ['yellow', 'red', 'black']\n",
        "l = []\n",
        "for attr in attributes:\n",
        "    if attr.casefold() == \"all\":\n",
        "        l.append(d_passageid_to_mean_of_segment_embeddings)\n",
        "        continue\n",
        "    attr_passages = [k for k, v in d_attribute_to_passage_to_score[attr].items() if v > 0]\n",
        "    attr_passages_embeddings = {k: v for k, v in d_passageid_to_mean_of_segment_embeddings.items() if k in attr_passages}\n",
        "    l.append(attr_passages_embeddings)\n",
        "\n",
        "\n",
        "# fig, axs = visualize_in_2d_list_of_dicts(l, attributes, colors, name=\"Attributes: {}\".format(\", \".join(attributes)), annotate=False, dpi=120, save_flg=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8oHsjIMn9kw"
      },
      "source": [
        "# Decoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwjqaFJ2o74-"
      },
      "source": [
        "## Import Timbre VAE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZNkKifKhvUm"
      },
      "source": [
        "### downgrade to tf===2.4.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VfmNBU94oO4l",
        "outputId": "8db6cace-66f3-4999-ca77-1d966336e030"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.8.0\n",
            "Uninstalling tensorflow-2.8.0:\n",
            "  Successfully uninstalled tensorflow-2.8.0\n",
            "Collecting tensorflow==2.4.0\n",
            "  Downloading tensorflow-2.4.0-cp37-cp37m-manylinux2010_x86_64.whl (394.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 394.7 MB 13 kB/s \n",
            "\u001b[?25hCollecting wrapt~=1.12.1\n",
            "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
            "Collecting tensorflow-estimator<2.5.0,>=2.4.0rc0\n",
            "  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 43.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.1.2)\n",
            "Collecting numpy~=1.19.2\n",
            "  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.8 MB 462 kB/s \n",
            "\u001b[?25hRequirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.15.0)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (2.8.0)\n",
            "Collecting flatbuffers~=1.12.0\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Collecting grpcio~=1.32.0\n",
            "  Downloading grpcio-1.32.0-cp37-cp37m-manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 36.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (0.2.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.6.3)\n",
            "Collecting typing-extensions~=3.7.4\n",
            "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
            "Collecting gast==0.3.3\n",
            "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (0.37.1)\n",
            "Collecting absl-py~=0.10\n",
            "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 42.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (3.17.3)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.1.0)\n",
            "Collecting h5py~=2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 26.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (1.35.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (57.4.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (0.4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.0) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.0) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.0) (3.2.0)\n",
            "Building wheels for collected packages: wrapt\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=68701 sha256=33b53f97c9cca3241d1f6ac2bf70ca038b2087c48056a0d38b48f4b39ed34644\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
            "Successfully built wrapt\n",
            "Installing collected packages: typing-extensions, numpy, grpcio, absl-py, wrapt, tensorflow-estimator, h5py, gast, flatbuffers, tensorflow\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.2.0\n",
            "    Uninstalling typing-extensions-4.2.0:\n",
            "      Successfully uninstalled typing-extensions-4.2.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.44.0\n",
            "    Uninstalling grpcio-1.44.0:\n",
            "      Successfully uninstalled grpcio-1.44.0\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.0.0\n",
            "    Uninstalling absl-py-1.0.0:\n",
            "      Successfully uninstalled absl-py-1.0.0\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.14.0\n",
            "    Uninstalling wrapt-1.14.0:\n",
            "      Successfully uninstalled wrapt-1.14.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0\n",
            "    Uninstalling flatbuffers-2.0:\n",
            "      Successfully uninstalled flatbuffers-2.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed absl-py-0.15.0 flatbuffers-1.12 gast-0.3.3 grpcio-1.32.0 h5py-2.10.0 numpy-1.19.5 tensorflow-2.4.0 tensorflow-estimator-2.4.0 typing-extensions-3.7.4.3 wrapt-1.12.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip uninstall --yes tensorflow\n",
        "!pip install tensorflow==2.4.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcBtwkNcDlLM"
      },
      "source": [
        "### Import Timbre VAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ttt378QLN7NW",
        "outputId": "13231d8a-fac8-4876-ca46-3c195adbc5ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.4.0\n"
          ]
        }
      ],
      "source": [
        "import importlib.util\n",
        "music_vae_spec = importlib.util.spec_from_file_location(\"music_vae\", \"/content/drive/Shareddrives/timbre-space-drive/repos/timbre-space/training/vae/music_vae.py\")\n",
        "timbre_vae_spec = importlib.util.spec_from_file_location(\"timbre_vae\", \"/content/drive/Shareddrives/timbre-space-drive/repos/timbre-space/training/vae/timbre_vae.py\")\n",
        "music_vae = importlib.util.module_from_spec(music_vae_spec)\n",
        "timbre_vae = importlib.util.module_from_spec(timbre_vae_spec)\n",
        "music_vae_spec.loader.exec_module(music_vae)\n",
        "timbre_vae_spec.loader.exec_module(timbre_vae)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxJ7cIK5D_kw"
      },
      "source": [
        "### Load VAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQQQ2GO3oASs",
        "outputId": "780514c9-d4a1-4683-95c7-1fc03dd17ed7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "timbre_input (InputLayer)       [(None, 256, 64, 1)] 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "encoder_conv_layer_1 (Conv2D)   (None, 256, 64, 128) 1280        timbre_input[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "encoder_relu_1 (ReLU)           (None, 256, 64, 128) 0           encoder_conv_layer_1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "encoder_bn_1 (BatchNormalizatio (None, 256, 64, 128) 512         encoder_relu_1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "encoder_conv_layer_2 (Conv2D)   (None, 128, 32, 64)  73792       encoder_bn_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "encoder_relu_2 (ReLU)           (None, 128, 32, 64)  0           encoder_conv_layer_2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "encoder_bn_2 (BatchNormalizatio (None, 128, 32, 64)  256         encoder_relu_2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "encoder_conv_layer_3 (Conv2D)   (None, 64, 16, 32)   18464       encoder_bn_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "encoder_relu_3 (ReLU)           (None, 64, 16, 32)   0           encoder_conv_layer_3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "encoder_bn_3 (BatchNormalizatio (None, 64, 16, 32)   128         encoder_relu_3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "encoder_conv_layer_4 (Conv2D)   (None, 64, 16, 32)   9248        encoder_bn_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "encoder_relu_4 (ReLU)           (None, 64, 16, 32)   0           encoder_conv_layer_4[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "encoder_bn_4 (BatchNormalizatio (None, 64, 16, 32)   128         encoder_relu_4[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 32768)        0           encoder_bn_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "mu (Dense)                      (None, 4)            131076      flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "log_variance (Dense)            (None, 4)            131076      flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "encoder_output (Lambda)         (None, 4)            0           mu[0][0]                         \n",
            "                                                                 log_variance[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "music_input (InputLayer)        [(None, 16)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 20)           0           encoder_output[0][0]             \n",
            "                                                                 music_input[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 365,960\n",
            "Trainable params: 365,448\n",
            "Non-trainable params: 512\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "decoder_input (InputLayer)   [(None, 20)]              0         \n",
            "_________________________________________________________________\n",
            "decoder_dense (Dense)        (None, 32768)             688128    \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 64, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "decoder_conv_transpose_layer (None, 64, 16, 32)        9248      \n",
            "_________________________________________________________________\n",
            "decoder_relu_1 (ReLU)        (None, 64, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "decoder_bn_1 (BatchNormaliza (None, 64, 16, 32)        128       \n",
            "_________________________________________________________________\n",
            "decoder_conv_transpose_layer (None, 128, 32, 32)       9248      \n",
            "_________________________________________________________________\n",
            "decoder_relu_2 (ReLU)        (None, 128, 32, 32)       0         \n",
            "_________________________________________________________________\n",
            "decoder_bn_2 (BatchNormaliza (None, 128, 32, 32)       128       \n",
            "_________________________________________________________________\n",
            "decoder_conv_transpose_layer (None, 256, 64, 64)       18496     \n",
            "_________________________________________________________________\n",
            "decoder_relu_3 (ReLU)        (None, 256, 64, 64)       0         \n",
            "_________________________________________________________________\n",
            "decoder_bn_3 (BatchNormaliza (None, 256, 64, 64)       256       \n",
            "_________________________________________________________________\n",
            "decoder_conv_transpose_layer (None, 256, 64, 1)        577       \n",
            "_________________________________________________________________\n",
            "sigmoid_layer (Activation)   (None, 256, 64, 1)        0         \n",
            "=================================================================\n",
            "Total params: 726,209\n",
            "Trainable params: 725,953\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n",
            "Model: \"autoencoder\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "timbre_input (InputLayer)       [(None, 256, 64, 1)] 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "music_input (InputLayer)        [(None, 16)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "encoder (Functional)            (None, 20)           365960      timbre_input[0][0]               \n",
            "                                                                 music_input[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "decoder (Functional)            (None, 256, 64, 1)   726209      encoder[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 1,092,169\n",
            "Trainable params: 1,091,401\n",
            "Non-trainable params: 768\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "TIMBREAE_SAVE_PATH = \"/content/drive/Shareddrives/timbre-space-drive/03-training/vae/icassp-2021/timbre-vae\"\n",
        "TIMBREAE_MODEL_PATH = os.path.join(TIMBREAE_SAVE_PATH, \"model\")\n",
        "\n",
        "WEIGHTS_FILE = \"weights.h5\"\n",
        "LEARNING_RATE = 0.0001\n",
        "\n",
        "timbreae = timbre_vae.VAE.load(TIMBREAE_MODEL_PATH, WEIGHTS_FILE)\n",
        "\n",
        "timbreae.compile(LEARNING_RATE)\n",
        "timbreae.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeQzmXsGTFMK"
      },
      "source": [
        "## segmentid -> spectrogram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LesF8g1O8DU"
      },
      "source": [
        "### decode_to_spectrogram_from_segment_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "4C9qaRmLqwQN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "TIMBREAE_SAVE_PATH = \"/content/drive/Shareddrives/timbre-space-drive/03-training/vae/icassp-2021/timbre-vae\"\n",
        "TIMBREAE_MODEL_PATH = os.path.join(TIMBREAE_SAVE_PATH, \"model\")\n",
        "\n",
        "def decode_to_spectrogram_from_segment_id(d_segmentid_to_music_embedding, d_segmentid_to_timbre_embedding, segment_id):\n",
        "    music_embedding = d_segmentid_to_music_embedding[segment_id]\n",
        "    log(\"Music Embedding: {}\".format(music_embedding), 3)\n",
        "    timbre_embedding = d_segmentid_to_timbre_embedding[segment_id]\n",
        "    log(\"Timbre Embedding: {}\".format(timbre_embedding), 3)\n",
        "\n",
        "    embedding = np.append(timbre_embedding, music_embedding)\n",
        "    log(\"Total Embedding: {}\".format(embedding), 3)\n",
        "\n",
        "    spectrogram = timbreae.decoder.predict(embedding[np.newaxis,...])\n",
        "    spectrogram = spectrogram.reshape(spectrogram.shape[1], spectrogram.shape[2])\n",
        "    log(\"Decoded Spectrogram shape: {}\".format(spectrogram.shape), 3)\n",
        "\n",
        "    return spectrogram\n",
        "\n",
        "# segmentid = \"00003-09-09\"\n",
        "# decoded_spectrogram = decode_to_spectrogram_from_segment_id(d_segmentid_to_music_embedding, d_segmentid_to_timbre_embedding, segmentid)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GP1r3dE3oEe5"
      },
      "source": [
        "## timbre_embedding -> spectrogram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TS7rFp0YK5xh"
      },
      "source": [
        "### decode_to_spectrogram_from_given_timbre_embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "usAdW1QEKnIv"
      },
      "outputs": [],
      "source": [
        "# This function is useful after moving the timbre embeddings\n",
        "def decode_to_spectrogram_from_given_timbre_embedding(d_segmentid_to_music_embedding, timbre_embedding, segment_id):\n",
        "    music_embedding = d_segmentid_to_music_embedding[segment_id]\n",
        "    log(\"Music Embedding: {}\".format(music_embedding), 3)\n",
        "    log(\"Given Timbre Embedding: {}\".format(timbre_embedding), 3)\n",
        "\n",
        "    embedding = np.append(timbre_embedding, music_embedding)\n",
        "    log(\"Total Embedding: {}\".format(embedding), 3)\n",
        "\n",
        "    spectrogram = timbreae.decoder.predict(embedding[np.newaxis,...])\n",
        "    spectrogram = spectrogram.reshape(spectrogram.shape[1], spectrogram.shape[2])\n",
        "    log(\"Decoded Spectrogram shape: {}\".format(spectrogram.shape), 3)\n",
        "\n",
        "    return spectrogram\n",
        "\n",
        "# decoded_spectrogram = decode_to_spectrogram_from_given_timbre_embedding(d_segmentid_to_music_embedding, moved_timbre_embedding, \"00003-09-09\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NfqMldAdAxC"
      },
      "source": [
        "# Audio reconstruction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZDBncacF0nK"
      },
      "source": [
        "### segment reconstruction helpers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "EA7OoR8GTDWF"
      },
      "outputs": [],
      "source": [
        "import soundfile as sf\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import re \n",
        "import pickle\n",
        "\n",
        "# for segment\n",
        "def get_original_spectrogram_from_path(spectrogram_path, segmentid):\n",
        "    original_spectrogram = None\n",
        "    for filename in os.listdir(spectrogram_path):\n",
        "        if re.match(\"^\" + segmentid + \".*\\.npy$\", filename):\n",
        "            log(\"Original spectrogram file : {}\".format(filename), 3)\n",
        "            original_spectrogram = np.load(os.path.join(spectrogram_path, filename))\n",
        "            log(\"Shape of og spectrogram: {}\".format(original_spectrogram.shape), 3)\n",
        "    if original_spectrogram is None:\n",
        "        exit(\"Original file not found! Exiting\")\n",
        "    return original_spectrogram\n",
        "\n",
        "# Spectrogram -> Audio\n",
        "def convert_segment_spectrogram_to_audio_signal(spectrogram, segmentid, save_flg=True, filename=\"reconstructed-audio\", save_path='/content/audio'):\n",
        "    log(\"segmentid: {}\".format(segmentid), 3)\n",
        "    log(\"shape of spectrogram: {}\".format(spectrogram.shape), 3)\n",
        "    if not os.path.exists(save_path):\n",
        "        os.makedirs(save_path)\n",
        "    # Denormalize\n",
        "    with open(os.path.join(MIN_MAX_VALUES_SAVE_DIR, MIN_MAX_VALUES_FILE_NAME), 'rb') as f:\n",
        "        min_max_values = pickle.load(f)\n",
        "    min_value, max_value = None, None\n",
        "\n",
        "    for key, val in min_max_values.items():\n",
        "        if re.match(\"^\" + segmentid + \".*\", key):\n",
        "            min_value = val[\"min\"]\n",
        "            max_value = val[\"max\"]\n",
        "            log(\"Min: {}, Max: {}\".format(str(min_value), str(max_value)), 3)\n",
        "    if not min_value or not max_value:\n",
        "        log(\"Min Max values not found for {}. Returning!\".format(segmentid))\n",
        "        return\n",
        "    \n",
        "    denormalized_db_spectrogram = spectrogram * (max_value - min_value) + min_value\n",
        "    log(\"shape of denormalized db spectrogram: {}\".format(denormalized_db_spectrogram.shape), 3)\n",
        "\n",
        "    # db_to_amplitude\n",
        "    inverted_magnitude_spectrogram = librosa.db_to_amplitude(denormalized_db_spectrogram)\n",
        "    log(\"shape after db_to_amplitude: {}\".format(inverted_magnitude_spectrogram.shape), 3)\n",
        "\n",
        "    # griffinlim\n",
        "    reconstructed_segment = librosa.griffinlim(inverted_magnitude_spectrogram, hop_length=HOP_LENGTH)\n",
        "    log(\"shape after griffinlim: {}\".format(reconstructed_segment.shape), 3)\n",
        "\n",
        "    if save_flg:\n",
        "        file_path = os.path.join(save_path, filename + \".wav\")\n",
        "        log(\"saving to: {}\".format(file_path))\n",
        "        sf.write(file_path, reconstructed_segment, SAMPLE_RATE)\n",
        "    \n",
        "    return reconstructed_segment\n",
        "\n",
        "\n",
        "# Spectrogram -> Image\n",
        "def convert_spectrogram_to_spectrogramimg(spectrogram, filename, visualize_flg=False, save_flg=True, save_path=\"/content/\"):\n",
        "    log(\"Shape of spectrogram img: {}\".format(spectrogram.shape))\n",
        "    if not os.path.exists(save_path):\n",
        "        os.makedirs(save_path)\n",
        "    plt.ioff()\n",
        "    fig, ax = plt.subplots(dpi=120)\n",
        "    img = librosa.display.specshow(spectrogram, y_axis='log', x_axis='time', ax=ax)\n",
        "\n",
        "    ax.set_title(filename)\n",
        "    fig.colorbar(img, ax=ax, format=\"%+2.2f dB\")\n",
        "    if save_flg:\n",
        "        fig.savefig(os.path.join(save_path, filename + \".png\"))  \n",
        "    if visualize_flg:\n",
        "        plt.show()\n",
        "    plt.close(fig)\n",
        "\n",
        "def remove_ampid_from_spectrogram(spectrogram):\n",
        "    return spectrogram[:, 1:]\n",
        "\n",
        "def get_differential_spectrogram(spectrogram_a, spectrogram_b, filename=\"differential_spectrogram\",visualize_flg=False, save_flg=True, save_path=\"/content/\"):\n",
        "    if spectrogram_a.shape != spectrogram_b.shape:\n",
        "        log(\"Shapes of the spectrogram differ. Cannot calculate the differential\")\n",
        "        return None\n",
        "    if not os.path.exists(save_path):\n",
        "        os.makedirs(save_path)\n",
        "    diff_spectrogram = np.abs(spectrogram_b - spectrogram_a)\n",
        "    plt.ioff()  \n",
        "    fig, ax = plt.subplots(dpi=120)\n",
        "    img = librosa.display.specshow(diff_spectrogram, y_axis='log', x_axis='time', ax=ax)\n",
        "\n",
        "    ax.set_title(filename)\n",
        "    fig.colorbar(img, ax=ax, format=\"%+2.2f dB\")\n",
        "    if save_flg:\n",
        "        fig.savefig(os.path.join(save_path, filename + \".png\"))  \n",
        "    if visualize_flg:\n",
        "        plt.show()\n",
        "    plt.close(fig)\n",
        "    return diff_spectrogram\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c8s477kF3Vn"
      },
      "source": [
        "### passage reconstruction helpers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "c3WBp-WqF7Do"
      },
      "outputs": [],
      "source": [
        "# Null Spectrograms: <passage-segment>\n",
        "# 01-12\n",
        "# 04-10\n",
        "# 06-00\n",
        "# 07-10\n",
        "# 08-13\n",
        "# 11-08\n",
        "# 12-14\n",
        "\n",
        "def decode_and_construct_passage(passageid, save_flg=True, filename=\"reconstructed-passage\", save_path=\"/content\"):\n",
        "    # passageid to segmentids\n",
        "    segmentids = sorted([key for key in d_segmentid_to_music_embedding.keys() if key.startswith(passageid)])\n",
        "    log(\"segmentids in passage: {}\".format(segmentids), 2)\n",
        "\n",
        "    passage_signal = np.array([])\n",
        "    for segmentid in segmentids:\n",
        "        # get spectrograms of segmentid\n",
        "        spectrogram = decode_to_spectrogram_from_segment_id(d_segmentid_to_music_embedding, d_segmentid_to_timbre_embedding, segmentid)\n",
        "\n",
        "        # griffinlim on spectrogram\n",
        "        reconstructed_signal = convert_segment_spectrogram_to_audio_signal(spectrogram[:,1:], segmentid, save_flg=False)\n",
        "\n",
        "        # append to passage signal\n",
        "        passage_signal = np.append(passage_signal, reconstructed_signal)\n",
        "        # print(spectrogram)\n",
        "\n",
        "    if save_flg:\n",
        "        file_path = os.path.join(save_path, filename + \".wav\")\n",
        "        log(\"saving to: {}\".format(file_path))\n",
        "        sf.write(file_path, passage_signal, SAMPLE_RATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Csh65uZGMac7"
      },
      "source": [
        "\n",
        "# **Segment decoding and reconstruction Pipeline**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "id": "clFyXKbMMdPs",
        "outputId": "09596fa6-8f0d-41a6-b84b-c241ae032891"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ],
      "source": [
        "sys.exit()\n",
        "## Driver code: Audio reconstruction for segments\n",
        "# Config. PLEASE SET THE SEGMENTID\n",
        "segmentid = \"00003-07-04\"\n",
        "\n",
        "# Other Config\n",
        "SAMPLE_RATE = 22050 # known\n",
        "FRAME_SIZE = 512 # known\n",
        "HOP_LENGTH = FRAME_SIZE // 2 # known\n",
        "SPECTROGRAMS_PATH = \"/content/drive/Shareddrives/timbre-space-drive/02-spectrograms-data/spectrogram-2022\"\n",
        "MIN_MAX_VALUES_SAVE_DIR = SPECTROGRAMS_PATH\n",
        "MIN_MAX_VALUES_FILE_NAME = \"min_max_values.pkl\"\n",
        "\n",
        "# 1. segment id -> spectrogram\n",
        "decoded_spectrogram = decode_to_spectrogram_from_segment_id(d_segmentid_to_music_embedding, d_segmentid_to_timbre_embedding, segmentid)\n",
        "\n",
        "# 2. spectrogram -> audio\n",
        "\n",
        "#   just for comparision\n",
        "original_spectrogram = get_original_spectrogram_from_path(SPECTROGRAMS_PATH, segmentid)\n",
        "\n",
        "convert_segment_spectrogram_to_audio_signal(original_spectrogram, segmentid, save_flg=True, filename=\"original-\" + segmentid , save_path=\"/content/\")\n",
        "convert_segment_spectrogram_to_audio_signal(decoded_spectrogram, segmentid, save_flg=True, filename=\"reconstructed-\" + segmentid, save_path=\"/content/\")\n",
        "\n",
        "# 3. spectrogram -> image\n",
        "convert_spectrogram_to_spectrogramimg(\n",
        "    remove_ampid_from_spectrogram(original_spectrogram), \n",
        "    \"original-\" + segmentid, visualize_flg=True, save_flg=True, save_path=\"/content\")\n",
        "convert_spectrogram_to_spectrogramimg(\n",
        "    remove_ampid_from_spectrogram(decoded_spectrogram), \n",
        "    \"decoded-\" + segmentid, visualize_flg=True, save_flg=True, save_path=\"/content\")\n",
        "\n",
        "# 4. differential spectrogram\n",
        "differential_spectrogram = get_differential_spectrogram(decoded_spectrogram, original_spectrogram, \n",
        "                                                        filename=\"differential-\" + segmentid + \"-og-recons\", \n",
        "                                                        visualize_flg=True, save_flg=True, save_path=\"/content\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFbxCRDLOTl6"
      },
      "source": [
        "# **Passage decoding and reconstruction Pipeline**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fA6JzwQj2J-o"
      },
      "outputs": [],
      "source": [
        "sys.exit()\n",
        "passageid = \"00003-09\"\n",
        "LOG_LEVEL = 1\n",
        "# Null Spectrograms: <passage-segment>\n",
        "# 01-12\n",
        "# 04-10\n",
        "# 06-00\n",
        "# 07-10\n",
        "# 08-13\n",
        "# 11-08\n",
        "# 12-14\n",
        "decode_and_construct_passage(passageid, save_flg=True, filename=\"reconstructed-\" + passageid, save_path=\"/content\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rp1HYcp8-e3j"
      },
      "source": [
        "# Moving the points"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bM3N3mKm2st6"
      },
      "source": [
        "## Helpers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6x4U5kCeU7uv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def move_point_in_direction_of_vector(point, vector, units_to_move):\n",
        "    v_hat = vector / np.linalg.norm(vector)\n",
        "    res = point + v_hat * units_to_move\n",
        "    return res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pqGxkUeAhKa"
      },
      "source": [
        "## **Moving the segments Pipeline**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JgKEvCGjJeG6"
      },
      "outputs": [],
      "source": [
        "###### PLEASE SET THE FOLLOWING PARAMS ######\n",
        "SHOW_LOGS=False\n",
        "save_reconstructed_audio = True\n",
        "\n",
        "visualize_moved_spectrogram = False\n",
        "save_moved_spectrogram = True\n",
        "\n",
        "visualize_og_to_moved_diff_spectrogram = False\n",
        "save_og_to_moved_diff_spectrogram = True\n",
        "\n",
        "visualize_prev_to_new_moved_diff_spectrogram = False\n",
        "save_prev_to_new_moved_diff_spectrogram = True\n",
        "\n",
        "save_relevant_points_plotted = True\n",
        "#############################################\n",
        "\n",
        "# Static Config Here#####\n",
        "#############################################\n",
        "\n",
        "# uses a ton of global variables. Name does Not accurately describe the input params.\n",
        "def pipeline_move_segment(segmentid, attribute, range_of_units_to_move): # get segment embedding\n",
        "    segment_embedding = d_segmentid_to_timbre_embedding[segmentid]\n",
        "    log(\"OG Segment embedding: {}\".format(segment_embedding))\n",
        "\n",
        "    # get original embedding for comparision\n",
        "    original_spectrogram = get_original_spectrogram_from_path(SPECTROGRAMS_PATH, segmentid)\n",
        "\n",
        "    # get attribute and min-max\n",
        "    attribute_min_point = np.array(d_attribute_to_min_and_max_score_points[attribute]['min'])\n",
        "    attribute_max_point = np.array(d_attribute_to_min_and_max_score_points[attribute]['max'])\n",
        "    log(\"Attribute min point: {}\".format(attribute_min_point))\n",
        "    log(\"Attribute max point: {}\".format(attribute_max_point))\n",
        "\n",
        "    # distance between min-max\n",
        "    distance_min_max_points = np.linalg.norm(attribute_max_point - attribute_min_point, ord=2)\n",
        "    log(\"Distance between min max points: {}\".format(distance_min_max_points), log_level=1)\n",
        "    vector_min_to_max = attribute_max_point - attribute_min_point\n",
        "\n",
        "    # For plotting the points\n",
        "    d_moved_points_by_units = {segmentid: segment_embedding, **d_attribute_to_min_and_max_score_points[attribute]}\n",
        "\n",
        "    prev_spectrogram = original_spectrogram\n",
        "    prev_units_moved = 0\n",
        "    number_of_spectrograms = len(range_of_units_to_move)\n",
        "    for units_to_move in range_of_units_to_move:\n",
        "        # Move the timbre embeddings\n",
        "        moved_timbre_embedding = move_point_in_direction_of_vector(segment_embedding, vector_min_to_max, units_to_move)\n",
        "        log(\"{} units_moved: {}\".format(units_to_move, moved_timbre_embedding))\n",
        "        d_moved_points_by_units[str(units_to_move)] = moved_timbre_embedding\n",
        "\n",
        "        # Decode to spectrograms\n",
        "        moved_decoded_spectrogram = decode_to_spectrogram_from_given_timbre_embedding(d_segmentid_to_music_embedding, moved_timbre_embedding, segmentid)\n",
        "\n",
        "        # Spectrogram to audio\n",
        "        moved_audio_segments_save_path = os.path.join(\"/content/drive/Shareddrives/timbre-space-drive/04-analysis/moving/segments/\", segmentid, attribute, \"audio\")\n",
        "        filename = \"[\" + segmentid + \" \" + attribute + \" moved] \" + str(units_to_move) + \" units\"\n",
        "        convert_segment_spectrogram_to_audio_signal(moved_decoded_spectrogram, segmentid, save_flg=save_reconstructed_audio, filename=filename,\n",
        "                                                    save_path=moved_audio_segments_save_path)\n",
        "        # spectrogram -> spectrogramimg\n",
        "        moved_spectrogramimg_save_path = os.path.join(\"/content/drive/Shareddrives/timbre-space-drive/04-analysis/moving/segments/\", segmentid, attribute)\n",
        "        convert_spectrogram_to_spectrogramimg(\n",
        "            remove_ampid_from_spectrogram(moved_decoded_spectrogram), filename=filename, \n",
        "            visualize_flg=visualize_moved_spectrogram, save_flg=save_moved_spectrogram,\n",
        "            save_path=moved_spectrogramimg_save_path)\n",
        "        \n",
        "        # OG-moved differential spectrogram imgs\n",
        "        og_spectrogramimg_diff_save_path = os.path.join(moved_spectrogramimg_save_path, \"diff-with-original\")\n",
        "        og_diff_filename = \"[\" + segmentid + \" \" + attribute + \" diff] OG and \" + str(units_to_move) + \"units\"\n",
        "        og_to_moved_diff_spectrogram = get_differential_spectrogram(moved_decoded_spectrogram, original_spectrogram, \n",
        "                                                            filename=og_diff_filename, \n",
        "                                                            visualize_flg=visualize_og_to_moved_diff_spectrogram, \n",
        "                                                            save_flg=save_og_to_moved_diff_spectrogram, save_path=og_spectrogramimg_diff_save_path)\n",
        "        # prev-moved differential spectrogram imgs\n",
        "        prev_spectrogramimg_diff_save_path = os.path.join(moved_spectrogramimg_save_path, \"diff-with-previous\")\n",
        "        diff_filename = \"[\" + segmentid + \" \" + attribute + \" diff] \" + str(prev_units_moved)+\" and \" + str(units_to_move) + \"units\"\n",
        "        prev_to_new_moved_diff_spectrogram = get_differential_spectrogram(moved_decoded_spectrogram, prev_spectrogram, \n",
        "                                                            filename=diff_filename, \n",
        "                                                            visualize_flg=visualize_prev_to_new_moved_diff_spectrogram, \n",
        "                                                            save_flg=save_prev_to_new_moved_diff_spectrogram, save_path=prev_spectrogramimg_diff_save_path)\n",
        "        prev_spectrogram = moved_decoded_spectrogram\n",
        "        prev_units_moved = units_to_move\n",
        "\n",
        "    plt.close('all')\n",
        "\n",
        "    # Plotting the moved points and the timbre embedding space\n",
        "    random_keys = random.sample(d_segmentid_to_timbre_embedding.keys(), 1000) # total is about 10.5k\n",
        "    sampled_points = {k:d_segmentid_to_timbre_embedding[k] for k in random_keys}\n",
        "    points_to_plot = {**d_moved_points_by_units, **sampled_points}\n",
        "\n",
        "    print(\"Plotting {} points\".format(len(points_to_plot.keys())))\n",
        "    visualize_in_2d_any_key_to_embedding_dict(\n",
        "        points_to_plot, \n",
        "        name=\"Moved segment and sampled timbre embeddings points\", dpi=120, save_flg=save_relevant_points_plotted, save_path=moved_spectrogramimg_save_path)\n",
        "\n",
        "segmentid = \"00033-07-05\"\n",
        "attribute = \"Clean\"\n",
        "range_of_units_to_move = range(1,10,1)\n",
        "\n",
        "# Driver\n",
        "# pipeline_move_segment(segmentid, attribute, range_of_units_to_move)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Q_KvMHdUX5F"
      },
      "source": [
        "## **Moving the Passages Pipeline**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tF4fGfpVUnuu"
      },
      "outputs": [],
      "source": [
        "save_reconstructed_audio = True\n",
        "\n",
        "visualize_original_passage_spectrogram = False\n",
        "save_original_passage_spectrogram = True\n",
        "\n",
        "visualize_moved_spectrogram = False\n",
        "save_moved_spectrogram = True\n",
        "\n",
        "visualize_og_to_moved_diff_spectrogram = False\n",
        "save_og_to_moved_diff_spectrogram = True\n",
        "\n",
        "visualize_prev_to_new_moved_diff_spectrogram = False\n",
        "save_prev_to_new_moved_diff_spectrogram = True\n",
        "\n",
        "save_relevant_points_plotted = True\n",
        "\n",
        "# Other Config\n",
        "SAMPLE_RATE = 22050 # known\n",
        "FRAME_SIZE = 512 # known\n",
        "HOP_LENGTH = FRAME_SIZE // 2 # known\n",
        "SPECTROGRAMS_PATH = \"/content/drive/Shareddrives/timbre-space-drive/02-spectrograms-data/spectrogram-2022\"\n",
        "MIN_MAX_VALUES_SAVE_DIR = SPECTROGRAMS_PATH\n",
        "MIN_MAX_VALUES_FILE_NAME = \"min_max_values.pkl\"\n",
        "\n",
        "SHOW_LOGS=True\n",
        "LOG_LEVEL = 5\n",
        "# Null Spectrograms: <passage-segment>\n",
        "# 01-12\n",
        "# 04-10\n",
        "# 06-00\n",
        "# 07-10\n",
        "# 08-13\n",
        "# 11-08\n",
        "# 12-14\n",
        "\n",
        "def move_decode_and_construct_passage(attribute, passageid, range_of_units_to_move, save_flg=True):\n",
        "    # passageid to segmentids\n",
        "    segmentids = sorted([key for key in d_segmentid_to_music_embedding.keys() if key.startswith(passageid)])\n",
        "    log(\"segmentids in passage: {}\".format(segmentids), 2)\n",
        "\n",
        "    # get attribute and min-max\n",
        "    attribute_min_point = np.array(d_attribute_to_min_and_max_score_points[attribute]['min'])\n",
        "    attribute_max_point = np.array(d_attribute_to_min_and_max_score_points[attribute]['max'])\n",
        "    log(\"Attribute min point: {}\".format(attribute_min_point))\n",
        "    log(\"Attribute max point: {}\".format(attribute_max_point))\n",
        "\n",
        "    # distance between min-max\n",
        "    distance_min_max_points = np.linalg.norm(attribute_max_point - attribute_min_point, ord=2)\n",
        "    log(\"Distance between min max points: {}\".format(distance_min_max_points), log_level=1)\n",
        "    vector_min_to_max = attribute_max_point - attribute_min_point\n",
        "\n",
        "    d_for_plotting = d_attribute_to_min_and_max_score_points[attribute]\n",
        "\n",
        "    prev_passage_spectrogram = None\n",
        "    prev_units_moved = 0\n",
        "    for units_to_move in range_of_units_to_move:\n",
        "\n",
        "        moved_audio_signal = np.array([])\n",
        "        moved_passage_spectrogram = None\n",
        "        original_passage_spectrogram = None\n",
        "        for segmentid in segmentids:\n",
        "            segment_embedding = d_segmentid_to_timbre_embedding[segmentid]\n",
        "            d_for_plotting[segmentid + \" - OG\"] = segment_embedding\n",
        "            # get original spectrogram for comparision\n",
        "            original_spectrogram = get_original_spectrogram_from_path(SPECTROGRAMS_PATH, segmentid)[:, 1:]\n",
        "\n",
        "            # Move the timbre embeddings\n",
        "            moved_timbre_embedding = move_point_in_direction_of_vector(segment_embedding, vector_min_to_max, units_to_move)\n",
        "            d_for_plotting[\"{} - {}units\".format(segmentid, units_to_move)] = moved_timbre_embedding\n",
        "            log(\"{} moved {} units: {}\".format(segmentid, units_to_move, moved_timbre_embedding))\n",
        "\n",
        "            # Decode to spectrograms\n",
        "            moved_segment_spectrogram = decode_to_spectrogram_from_given_timbre_embedding(d_segmentid_to_music_embedding, moved_timbre_embedding, segmentid)[:, 1:]\n",
        "\n",
        "            # Spectrogram to audio\n",
        "            reconstructed_signal = convert_segment_spectrogram_to_audio_signal(moved_segment_spectrogram, segmentid, save_flg=False)\n",
        "        \n",
        "            # append to moved spectrogram\n",
        "            if moved_passage_spectrogram is None:\n",
        "                moved_passage_spectrogram = moved_segment_spectrogram\n",
        "            else:\n",
        "                moved_passage_spectrogram = np.append(moved_passage_spectrogram, moved_segment_spectrogram, axis=1)\n",
        "\n",
        "            # append to original spectrogram\n",
        "            if original_passage_spectrogram is None:\n",
        "                original_passage_spectrogram = original_spectrogram\n",
        "            else:\n",
        "                original_passage_spectrogram = np.append(original_passage_spectrogram, original_spectrogram, axis=1)\n",
        "\n",
        "            # append to audio segment\n",
        "            moved_audio_signal = np.append(moved_audio_signal, reconstructed_signal)\n",
        "\n",
        "        log(\"{} moved {} units spectrogram shape: {}\".format(passageid, units_to_move, moved_passage_spectrogram.shape))\n",
        "        log(\"{} reconstructed audio signal shape {}\".format(passageid, moved_audio_signal.shape))\n",
        "\n",
        "        # Save Audio\n",
        "        moved_audio_segments_save_path = os.path.join(\"/content/drive/Shareddrives/timbre-space-drive/04-analysis/moving/passages/\", passageid, attribute, \"audio\")\n",
        "        filename = \"[\" + passageid + \" \" + attribute + \" moved] \" + str(units_to_move) + \" units\"\n",
        "        if save_reconstructed_audio:\n",
        "            if not os.path.exists(moved_audio_segments_save_path):\n",
        "                os.makedirs(moved_audio_segments_save_path)\n",
        "            file_path = os.path.join(moved_audio_segments_save_path, filename + \".wav\")\n",
        "            log(\"saving to: {}\".format(file_path))\n",
        "            sf.write(file_path, moved_audio_signal, SAMPLE_RATE)\n",
        "\n",
        "        # Save moved spectrogram img\n",
        "        moved_spectrogramimg_save_path = os.path.join(\"/content/drive/Shareddrives/timbre-space-drive/04-analysis/moving/passages/\", passageid, attribute)\n",
        "        convert_spectrogram_to_spectrogramimg(\n",
        "            moved_passage_spectrogram, filename=filename, \n",
        "            visualize_flg=visualize_moved_spectrogram, save_flg=save_moved_spectrogram,\n",
        "            save_path=moved_spectrogramimg_save_path)\n",
        "        \n",
        "        # Save original spectrogram img\n",
        "        original_spectrogramimg_save_path = os.path.join(\"/content/drive/Shareddrives/timbre-space-drive/04-analysis/moving/passages/\", passageid)\n",
        "        convert_spectrogram_to_spectrogramimg(\n",
        "            original_passage_spectrogram, filename=passageid, \n",
        "            visualize_flg=visualize_original_passage_spectrogram, save_flg=save_original_passage_spectrogram,\n",
        "            save_path=original_spectrogramimg_save_path)\n",
        "\n",
        "        ## for calculating differential\n",
        "        if prev_passage_spectrogram is None:\n",
        "            prev_passage_spectrogram = original_passage_spectrogram\n",
        "\n",
        "        # OG-moved differential spectrogram imgs\n",
        "        og_spectrogramimg_diff_save_path = os.path.join(moved_spectrogramimg_save_path, \"diff-with-original\")\n",
        "        og_diff_filename = \"[\" + passageid + \" \" + attribute + \" diff] OG and \" + str(units_to_move) + \"units\"\n",
        "        og_to_moved_diff_spectrogram = get_differential_spectrogram(moved_passage_spectrogram, original_passage_spectrogram, \n",
        "                                                            filename=og_diff_filename, \n",
        "                                                            visualize_flg=visualize_og_to_moved_diff_spectrogram, \n",
        "                                                            save_flg=save_og_to_moved_diff_spectrogram, save_path=og_spectrogramimg_diff_save_path)\n",
        "\n",
        "        # prev-moved differential spectrogram imgs\n",
        "        prev_spectrogramimg_diff_save_path = os.path.join(moved_spectrogramimg_save_path, \"diff-with-previous\")\n",
        "        diff_filename = \"[\" + passageid + \" \" + attribute + \" diff] \" + str(prev_units_moved)+\" and \" + str(units_to_move) + \"units\"\n",
        "        prev_to_new_moved_diff_spectrogram = get_differential_spectrogram(moved_passage_spectrogram, prev_passage_spectrogram, \n",
        "                                                            filename=diff_filename, \n",
        "                                                            visualize_flg=visualize_prev_to_new_moved_diff_spectrogram, \n",
        "                                                            save_flg=save_prev_to_new_moved_diff_spectrogram, save_path=prev_spectrogramimg_diff_save_path)\n",
        "        prev_passage_spectrogram = moved_passage_spectrogram\n",
        "        prev_units_moved = units_to_move\n",
        "\n",
        "    plt.close('all')\n",
        "\n",
        "    # Plotting the moved points and the timbre embedding space\n",
        "    # random_keys = random.sample(d_segmentid_to_timbre_embedding.keys(), 1000) # total is about 10.5k\n",
        "    # sampled_points = {k:d_segmentid_to_timbre_embedding[k] for k in random_keys}\n",
        "    # points_to_plot = {**d_moved_points_by_units, **sampled_points}\n",
        "\n",
        "    print(\"Plotting {} points\".format(len(d_for_plotting.keys())))\n",
        "    visualize_in_2d_any_key_to_embedding_dict(\n",
        "        d_for_plotting, \n",
        "        name=\"Moved segments embeddings\", dpi=120, save_flg=save_relevant_points_plotted, save_path=moved_spectrogramimg_save_path)\n",
        "\n",
        "passageid = \"00033-05\"\n",
        "attribute = \"Bright\"\n",
        "range_of_units_to_move = range(1,25,3)\n",
        "\n",
        "# move_decode_and_construct_passage(attribute, passageid, range_of_units_to_move=range_of_units_to_move)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVxXCcAPTlhp"
      },
      "outputs": [],
      "source": [
        "!sudo apt-get update \n",
        "!sudo apt-get install texlive-xetex texlive-fonts-recommended texlive-generic-recommended\n",
        "!jupyter nbconvert --to pdf \"/content/drive/MyDrive/Colab Notebooks/Analysis of embeddings - Full\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Analysis of embeddings - Full",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}