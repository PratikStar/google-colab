{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PratikStar/google-colab/blob/main/1_2_Create_Audio_Spectrogram_(Windowed_version)_LATEST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lHfnqiV9z91"
      },
      "source": [
        "### Some notes\n",
        "Original owner: sutarpratik2012@gmail.com\n",
        "\n",
        "But now we need to run this as pratik-sutar@g.ecc.u-tokyo.ac.jp since the [cross account drive sharing is not possible since Dec 2021](https://github.com/googlecolab/colabtools/issues/2418#issuecomment-996238324)\n",
        "\n",
        "This the LATEST Notebook for Spectrogram creation.\n",
        "\n",
        "Exported to scripts/audio-to-spectrogram\n",
        "### References: \n",
        "\n",
        "*   Sound of AI: https://www.youtube.com/watch?v=O04v3cgHNeM&list=PL-wATfeyAMNpEyENTc-tVH5tfLGKtSWPp&index=12 \n",
        "*   https://musicinformationretrieval.com/stft.html. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KMFwAcHRdjx",
        "outputId": "f9ab2d5a-f8e8-4334-f189-0a9ed23dcc32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfChkUfy4wwH"
      },
      "source": [
        "## Pipeline Classes & Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "geYxumIg3a6L"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "1- load a file..\n",
        "2- pad the signal (if necessary)\n",
        "3- extracting log spectrogram from signal\n",
        "4- normalise spectrogram\n",
        "5- save the normalised spectrogram\n",
        "\n",
        "PreprocessingPipeline\n",
        "\"\"\"\n",
        "import os\n",
        "import pickle\n",
        "import re\n",
        "import librosa\n",
        "import librosa.display\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import inspect\n",
        "import soundfile as sf\n",
        "\n",
        "SHOW_LOGS = True\n",
        "LOG_LEVEL = 1 # {1-6} High Value -> High verbosity\n",
        "\n",
        "def log(logline, log_level = 1):\n",
        "    if SHOW_LOGS and log_level <= LOG_LEVEL:\n",
        "        stack = inspect.stack()\n",
        "        the_class = stack[1][0].f_locals[\"self\"].__class__.__name__\n",
        "        the_method = stack[1][0].f_code.co_name\n",
        "        print(the_class + \": \" + logline)\n",
        "\n",
        "class Loader:\n",
        "    \"\"\"Loader is responsible for loading an audio file.\"\"\"\n",
        "\n",
        "    def __init__(self, sample_rate, offset, load_duration, segment_duration, mono):\n",
        "        self.sample_rate = sample_rate\n",
        "        self.load_duration = load_duration\n",
        "        self.segment_duration = segment_duration # This is required to calculate if padding is necessary to a segment\n",
        "        self.offset = offset\n",
        "        self.mono = mono\n",
        "\n",
        "    def load(self, file_path):\n",
        "        signal = librosa.load(file_path,\n",
        "                              sr=self.sample_rate,\n",
        "                              duration=self.load_duration,\n",
        "                              offset=self.offset,\n",
        "                              mono=self.mono)[0]\n",
        "        log(\"Shape of the loaded signal: \" + str(signal.shape), 2)\n",
        "        log(\"Mean of the loaded signal: \" + str(np.mean(signal)), 5)\n",
        "        log(\"Min of the loaded signal: \" + str(np.amin(signal)), 5)\n",
        "        log(\"Max of the loaded signal: \" + str(np.amax(signal)), 5)\n",
        "        log(\"Raw signal: \" + str(signal), 6)\n",
        "        return signal\n",
        "\n",
        "\n",
        "class Padder:\n",
        "    \"\"\"Padder is responsible to apply padding to an array.\"\"\"\n",
        "\n",
        "    def __init__(self, mode=\"constant\"):\n",
        "        self.mode = mode\n",
        "\n",
        "    def left_pad(self, array, num_missing_items):\n",
        "        log(\"Applying Left Padding: \" + str(num_missing_items), 5)\n",
        "        padded_array = np.pad(array,\n",
        "                              (num_missing_items, 0),\n",
        "                              mode=self.mode)\n",
        "        return padded_array\n",
        "\n",
        "    def right_pad(self, array, num_missing_items):\n",
        "        log(\"Applying Right Padding: \" + str(num_missing_items), 5)\n",
        "        padded_array = np.pad(array,\n",
        "                              (0, num_missing_items),\n",
        "                              mode=self.mode)\n",
        "        return padded_array\n",
        "\n",
        "\n",
        "class LogSpectrogramExtractor:\n",
        "    \"\"\"LogSpectrogramExtractor extracts log spectrograms (in dB) from a\n",
        "    time-series signal.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, frame_size, hop_length):\n",
        "        self.frame_size = frame_size\n",
        "        self.hop_length = hop_length\n",
        "\n",
        "    def extract(self, signal):\n",
        "        stft = librosa.stft(signal,\n",
        "                            n_fft=self.frame_size,\n",
        "                            hop_length=self.hop_length)[:-1]\n",
        "        log(\"Shape of stft: \" + str(stft.shape), 2)\n",
        "        spectrogram = np.abs(stft)\n",
        "        log_spectrogram = librosa.amplitude_to_db(spectrogram)\n",
        "        return log_spectrogram\n",
        "\n",
        "class FeatureExtractor:\n",
        "    \"\"\" Extracts some features like Clip ID and Passage ID\"\"\"\n",
        "\n",
        "    # Clip ID is same as AmpID\n",
        "    def extract_clipid_from_name(self, filename):\n",
        "        clip_id = int(filename.split('-')[0])\n",
        "        log(\"Clip ID: \" + str(clip_id), 5)\n",
        "        return clip_id\n",
        "\n",
        "    # Passage ID is equivalent to what used to be 'subclip' ID\n",
        "    def extract_passageid_from_name(self, filename):\n",
        "        passage_id = int(filename.split('-')[1].split(' ')[0])\n",
        "        log(\"Passage ID: \" + str(passage_id), 5)\n",
        "        return passage_id\n",
        "\n",
        "class MinMaxNormaliser:\n",
        "    \"\"\"MinMaxNormaliser applies min max normalisation to an array.\"\"\"\n",
        "\n",
        "    def __init__(self, min_val, max_val):\n",
        "        self.min = min_val\n",
        "        self.max = max_val\n",
        "\n",
        "    def normalise(self, array):\n",
        "\n",
        "        norm_array = (array - array.min()) / (array.max() - array.min())\n",
        "        norm_array = norm_array * (self.max - self.min) + self.min\n",
        "        log(\"Shape of normalized array: \" + str(norm_array.shape), 2)\n",
        "        log(\"Max of norm_array: \" + str((array.max())), 5)\n",
        "        log(\"Min of norm_array: \" + str((array.min())), 5)\n",
        "        return norm_array\n",
        "\n",
        "    def denormalise(self, norm_array, original_min, original_max):\n",
        "        array = (norm_array - self.min) / (self.max - self.min)\n",
        "        array = array * (original_max - original_min) + original_min\n",
        "        return array\n",
        "\n",
        "\n",
        "class Saver:\n",
        "    \"\"\"saver is responsible to save features, and the min max values.\"\"\"\n",
        "\n",
        "    def __init__(self, feature_save_dir, min_max_values_save_dir):\n",
        "        self.feature_save_dir = feature_save_dir\n",
        "        Utils._create_folder_if_it_doesnt_exist(self.feature_save_dir)\n",
        "        self.min_max_values_save_dir = min_max_values_save_dir\n",
        "        Utils._create_folder_if_it_doesnt_exist(self.min_max_values_save_dir)\n",
        "\n",
        "    def save_feature(self, feature, file_name):\n",
        "        save_path = self._generate_save_path(file_name)\n",
        "        np.save(save_path, feature)\n",
        "\n",
        "    def save_min_max_values(self, min_max_values):\n",
        "        save_path = os.path.join(self.min_max_values_save_dir,\n",
        "                                 \"min_max_values.pkl\")\n",
        "        self._save(min_max_values, save_path)\n",
        "\n",
        "    @staticmethod\n",
        "    def _save(data, save_path):\n",
        "        with open(save_path, \"wb\") as f:\n",
        "            pickle.dump(data, f)\n",
        "\n",
        "    def _generate_save_path(self, file_name):\n",
        "        save_path = os.path.join(self.feature_save_dir, file_name + \".npy\")\n",
        "        return save_path\n",
        "\n",
        "class Visualizer:\n",
        "    def __init__(self, file_dir, frame_size, hop_length, offset):\n",
        "        self.file_dir = file_dir\n",
        "        self.frame_size = frame_size\n",
        "        self.hop_length = hop_length\n",
        "        self.offset = offset\n",
        "    \n",
        "    def visualize(self, spectrogram, file_name, spectrogram_img_save_flg=False):\n",
        "        plt.ioff()\n",
        "        fig, ax = plt.subplots(dpi=120)\n",
        "        try:\n",
        "            img = librosa.display.specshow(spectrogram, y_axis='log', x_axis='time', ax=ax)\n",
        "        except IndexError as e:\n",
        "            log(\"Null spectrogram for file: \" + file_name, 1)\n",
        "            return\n",
        "        ax.set_title(\"Frame Size: {}, Hop length: {}, Offset: {}\\n{}\".format(self.frame_size, self.hop_length, self.offset, file_name.split(\".\")[0]))\n",
        "        fig.colorbar(img, ax=ax, format=\"%+2.0f dB\")\n",
        "        Utils._create_folder_if_it_doesnt_exist(self.file_dir)\n",
        "        if spectrogram_img_save_flg:\n",
        "            fig.savefig(os.path.join(self.file_dir, re.sub('\\.[a-z]*$', '.png', file_name)))        \n",
        "        plt.close(fig)\n",
        "\n",
        "class Utils:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    @staticmethod\n",
        "    def _create_folder_if_it_doesnt_exist(folder):\n",
        "        if not os.path.exists(folder):\n",
        "            os.makedirs(folder)\n",
        "\n",
        "class AudioReconstructor:\n",
        "    \"\"\"Processes stft inverse and saves the audio file\"\"\"\n",
        "    def __init__(self, file_dir, hop_length, frame_size):\n",
        "        self.file_dir = file_dir\n",
        "        self.hop_length = hop_length\n",
        "        self.frame_size = frame_size\n",
        "        Utils._create_folder_if_it_doesnt_exist(self.file_dir)\n",
        "\n",
        "    def reconstruct(self, features, file_name):\n",
        "        # Invert using Griffin-Lim\n",
        "        log(\"Shape of features: \" + str(features.shape), 1)\n",
        "        features_inv = librosa.griffinlim(features,\n",
        "                                          hop_length=self.hop_length,\n",
        "                                          win_length=self.frame_size)\n",
        "        log(\"Shape of Inverse features: \" + str(features_inv.shape), 1)\n",
        "        Utils._create_folder_if_it_doesnt_exist(self.file_dir)\n",
        "        sf.write(os.path.join(self.file_dir, file_name ), y_inv, 22050)\n",
        "        # save audio\n",
        "    def reconstruct_from_path(self, file_path):\n",
        "        # Invert using Griffin-Lim\n",
        "        features = np.load(file_path)\n",
        "        self.reconstruct(features, os.path.basename(file_path))\n",
        "    \n",
        "class PreprocessingPipeline:\n",
        "    \"\"\"PreprocessingPipeline processes a single audio file, applying\n",
        "    the following steps to each file:\n",
        "        1- load a file\n",
        "        2- pad the signal (if necessary)\n",
        "        3- extracting log spectrogram from signal\n",
        "        4- normalise spectrogram\n",
        "        5- save the normalised spectrogram\n",
        "\n",
        "    Storing the min max values for all the log spectrograms.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.padder = None\n",
        "        self.spectrogram_extractor = None\n",
        "        self.feature_extractor = None\n",
        "        self.normaliser = None\n",
        "        self.saver = None\n",
        "        self.visualizer = None\n",
        "        self.reconstructor = None\n",
        "        self.min_max_values = {}\n",
        "        self._loader = None\n",
        "        self._num_expected_samples = None\n",
        "\n",
        "    @property\n",
        "    def loader(self):\n",
        "        return self._loader\n",
        "\n",
        "    @loader.setter\n",
        "    def loader(self, loader):\n",
        "        self._loader = loader\n",
        "        self._num_expected_samples = int(loader.sample_rate * loader.segment_duration)\n",
        "\n",
        "    # Processes Single file\n",
        "    def process_file(self, audio_files_dir, audio_passage_file_name, segment_id, spectrogram_save_flg=False, spectrogram_img_save_flg=False, visualize_flg=True, external_features_flg=False):\n",
        "        name_split = audio_passage_file_name.split(\" \")\n",
        "        file_name = name_split[0] + \"-{:02d} \".format(segment_id) + \" \".join(name_split[1:])\n",
        "        log(\"Processing Segment: \" + file_name)\n",
        "\n",
        "        file_path = os.path.join(audio_files_dir, audio_passage_file_name)\n",
        "        signal = self.loader.load(file_path)\n",
        "        if external_features_flg:\n",
        "            external_features = [ self.feature_extractor.extract_clipid_from_name(audio_passage_file_name),\n",
        "                                  self.feature_extractor.extract_passageid_from_name(audio_passage_file_name),\n",
        "                                  segment_id                         \n",
        "                                ]\n",
        "            signal = np.concatenate((external_features, signal))\n",
        "\n",
        "        if self._is_padding_necessary(signal):\n",
        "            signal = self._apply_padding(signal)\n",
        "        feature = self.spectrogram_extractor.extract(signal)\n",
        "\n",
        "        norm_feature = self.normaliser.normalise(feature)\n",
        "\n",
        "\n",
        "        if visualize_flg or spectrogram_img_save_flg:\n",
        "            self.visualizer.visualize(norm_feature, file_name, spectrogram_img_save_flg)\n",
        "\n",
        "        if spectrogram_save_flg:\n",
        "            save_path = self.saver.save_feature(norm_feature, file_name)\n",
        "            # self._store_min_max_value(save_path, feature.min(), feature.max())\n",
        "            self.saver.save_min_max_values(self.min_max_values)\n",
        "\n",
        "    def _is_padding_necessary(self, signal):\n",
        "        if len(signal) < self._num_expected_samples:\n",
        "            log(\"Padding necessary\", 1)\n",
        "            log(\"Actual Signal length: \" + str(len(signal)), 5)\n",
        "            log(\"Expected samples in signal: \" + str(self._num_expected_samples), 5)\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def _apply_padding(self, signal):\n",
        "        num_missing_samples = self._num_expected_samples - len(signal)\n",
        "        padded_signal = self.padder.right_pad(signal, num_missing_samples)\n",
        "        return padded_signal\n",
        "\n",
        "    def _store_min_max_value(self, save_path, min_val, max_val):\n",
        "        self.min_max_values[save_path] = {\n",
        "            \"min\": min_val,\n",
        "            \"max\": max_val\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsUH1H5z4syc"
      },
      "source": [
        "## Driver Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRRijJuhxnYl",
        "outputId": "150b162a-9081-4888-b747-ed399e3ffbc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PreprocessingPipeline: Processing Segment: 00000-05-00 DI.wav\n",
            "PreprocessingPipeline: Processing Segment: 00000-05-01 DI.wav\n",
            "PreprocessingPipeline: Processing Segment: 00000-05-02 DI.wav\n",
            "PreprocessingPipeline: Processing Segment: 00000-05-03 DI.wav\n",
            "PreprocessingPipeline: Processing Segment: 00000-05-04 DI.wav\n",
            "PreprocessingPipeline: Processing Segment: 00000-05-05 DI.wav\n",
            "PreprocessingPipeline: Processing Segment: 00000-05-06 DI.wav\n",
            "PreprocessingPipeline: Processing Segment: 00000-05-07 DI.wav\n",
            "PreprocessingPipeline: Processing Segment: 00000-05-08 DI.wav\n",
            "PreprocessingPipeline: Processing Segment: 00000-05-09 DI.wav\n"
          ]
        }
      ],
      "source": [
        "## TOBE <CLIP_ID>-<PASSAGE_ID>-<SEGMENT_ID> <AMP_NAME>.wav.npy\n",
        "## 00000-06-00 DI.wav.png is not present\n",
        "\n",
        "### For Audio Loading\n",
        "SAMPLE_RATE = 22050\n",
        "MONO = True\n",
        "\n",
        "### For STFT\n",
        "FRAME_SIZE = 512\n",
        "HOP_LENGTH = FRAME_SIZE // 2 \n",
        "SEGMENT_DURATION = 0.74  # in seconds\n",
        "\n",
        "# Dimensions: (FRAME_SIZE / 2) x ceil(SAMPLE_RATE * DURATION / HOP_LENGTH)\n",
        "\n",
        "### For Processing\n",
        "MAX_NUMBER_OF_SEGMENTS = 10\n",
        "SPECTROGRAM_SAVE_FLG=True\n",
        "SPECTROGRAM_IMG_SAVE_FLG=True\n",
        "VISUALIZE_FLG=True\n",
        "EXTERNAL_FEATURES_FLG=True\n",
        "\n",
        "\n",
        "### INPUT. Read-only\n",
        "AUDIO_FILES_DIR = \"/content/drive/MyDrive/Music/VAE/audio/\"\n",
        "AUDIO_REGEX = \"^00000.*\\.wav$\"\n",
        "\n",
        "\n",
        "### OUTPUT\n",
        "SPECTROGRAMS_SAVE_DIR = \"/content/drive/MyDrive/Music/VAE/spectrogram-2022/\"\n",
        "SPECTROGRAMS_IMG_SAVE_DIR = \"/content/drive/MyDrive/Music/VAE/spectrogram-img-2022/\"\n",
        "RECONSTRUCTED_AUDIO_SAVE_DIR = \"/content/drive/MyDrive/Music/VAE/audio-reconstructed/\"\n",
        "MIN_MAX_VALUES_SAVE_DIR = \"/content/drive/MyDrive/Music/VAE/spectrogram-2022/\"\n",
        "\n",
        "\n",
        "# instantiate all objects\n",
        "# loader = None # Loader is initialized later\n",
        "padder = Padder()\n",
        "log_spectrogram_extractor = LogSpectrogramExtractor(FRAME_SIZE, HOP_LENGTH)\n",
        "feature_extractor = FeatureExtractor()\n",
        "min_max_normaliser = MinMaxNormaliser(0, 1)\n",
        "saver = Saver(SPECTROGRAMS_SAVE_DIR, MIN_MAX_VALUES_SAVE_DIR)\n",
        "# visualizer = Visualizer(SPECTROGRAMS_IMG_SAVE_DIR, FRAME_SIZE, HOP_LENGTH, OFFSET) # Initialized later since we need to calculate Offset\n",
        "reconstructor = AudioReconstructor(RECONSTRUCTED_AUDIO_SAVE_DIR, HOP_LENGTH, FRAME_SIZE)\n",
        "\n",
        "preprocessing_pipeline = PreprocessingPipeline()\n",
        "# preprocessing_pipeline.loader = loader\n",
        "preprocessing_pipeline.padder = padder\n",
        "preprocessing_pipeline.spectrogram_extractor = log_spectrogram_extractor\n",
        "preprocessing_pipeline.feature_extractor = feature_extractor\n",
        "preprocessing_pipeline.normaliser = min_max_normaliser\n",
        "preprocessing_pipeline.saver = saver\n",
        "preprocessing_pipeline.reconstructor = reconstructor\n",
        "\n",
        "processed_segments = 0\n",
        "for root, _, files in os.walk(AUDIO_FILES_DIR):\n",
        "    for file in files:\n",
        "        if re.match(AUDIO_REGEX, file):\n",
        "\n",
        "            # Load file just to get duration\n",
        "            y, sr = librosa.load(os.path.join(AUDIO_FILES_DIR, file), sr=SAMPLE_RATE, mono=MONO)\n",
        "            duration = librosa.get_duration(y=y, sr=sr)\n",
        "            segment_id = 0\n",
        "            while True:\n",
        "                if (segment_id) * SEGMENT_DURATION >= duration:\n",
        "                    break\n",
        "                if processed_segments == MAX_NUMBER_OF_SEGMENTS:\n",
        "                    break\n",
        "                processed_segments += 1                \n",
        "                offset = segment_id * SEGMENT_DURATION\n",
        "                loader = Loader(SAMPLE_RATE, offset, min(SEGMENT_DURATION, duration - offset), SEGMENT_DURATION, MONO)\n",
        "                preprocessing_pipeline.loader = loader\n",
        "                visualizer = Visualizer(SPECTROGRAMS_IMG_SAVE_DIR, FRAME_SIZE, HOP_LENGTH, offset)\n",
        "                preprocessing_pipeline.visualizer = visualizer\n",
        "\n",
        "                preprocessing_pipeline.process_file(AUDIO_FILES_DIR, file, segment_id,  spectrogram_save_flg=SPECTROGRAM_SAVE_FLG, spectrogram_img_save_flg=SPECTROGRAM_IMG_SAVE_FLG, visualize_flg=VISUALIZE_FLG, external_features_flg=EXTERNAL_FEATURES_FLG)\n",
        "                segment_id += 1\n",
        "    else:\n",
        "        continue  # only executed if the inner loop did NOT break\n",
        "    break # only executed if the inner loop DID break\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afRc5JoGurc6"
      },
      "source": [
        "## Test clips (Not tested in 2022)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7v7NqMPupV_",
        "outputId": "622cdf0e-a4f2-4f56-b1ad-3c891599f71e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "livin-on-a-prayer.wav\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\trock-livin-on-a-prayer.wav\n",
            "smells-like-teen-spirit.wav\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\trock-smells-like-teen-spirit.wav\n",
            "sweet-child-o-mine.wav\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\trock-sweet-child-o-mine.wav\n",
            "black-hole-sun.wav\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\trock-black-hole-sun.wav\n",
            "sultans-of-swing.wav\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\trock-sultans-of-swing.wav\n",
            "november-rain.wav\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\trock-november-rain.wav\n",
            "here-i-go-again.wav\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\trock-here-i-go-again.wav\n",
            "basket-case.wav\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\trock-basket-case.wav\n",
            "eye-of-the-tiger.wav\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\trock-eye-of-the-tiger.wav\n",
            "heart-shaped-box.wav\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\trock-heart-shaped-box.wav\n"
          ]
        }
      ],
      "source": [
        "## TOBE <AMP_ID>-<CLIP_ID>-<SEGMENT_ID> <AMP_NAME>.wav.npy\n",
        "## 00000-06-00 DI.wav.png is not present\n",
        "# rock acoustic: https://www.youtube.com/watch?v=hf7e0eRu5Jg\n",
        "# rock: https://www.youtube.com/watch?v=w6MiJUTZ6n8\n",
        "\n",
        "FRAME_SIZE = 512\n",
        "HOP_LENGTH = FRAME_SIZE // 2 # smaller better?\n",
        "OFFSET = 0\n",
        "WINDOW_DURATION = 0.74  # in seconds\n",
        "SAMPLE_RATE = 22050\n",
        "MONO = True\n",
        "\n",
        "# Dimensions: (FRAME_SIZE / 2) x ceil(SAMPLE_RATE * DURATION / HOP_LENGTH)\n",
        "\n",
        "## SOURCE\n",
        "AUDIO_FILES_DIR = \"/content/drive/MyDrive/Music/VAE/audio-test/rock-samples\"\n",
        "AUDIO_REGEX = \".*\"\n",
        "\n",
        "## OUTPUT\n",
        "SPECTROGRAMS_SAVE_DIR = \"/content/drive/MyDrive/Music/VAE/ICASSP/spectrogram-testing/\"\n",
        "SPECTROGRAMS_IMG_SAVE_DIR = \"/content/drive/MyDrive/Music/VAE/ICASSP/spectrogram-img-testing/\"\n",
        "RECONSTRUCTED_AUDIO_SAVE_DIR = \"/content/drive/MyDrive/Music/VAE/ICASSP/audio-reconstructed-test/\"\n",
        "MIN_MAX_VALUES_SAVE_DIR = \"/content/drive/MyDrive/Music/VAE/ICASSP\"\n",
        "\n",
        "NUMBER_OF_CLIPS = 10000000\n",
        "\n",
        "# instantiate all objects\n",
        "# loader = Loader(SAMPLE_RATE, OFFSET, WINDOW_DURATION, MONO)\n",
        "padder = Padder()\n",
        "log_spectrogram_extractor = LogSpectrogramExtractor(FRAME_SIZE, HOP_LENGTH)\n",
        "feature_extractor = FeatureExtractor()\n",
        "min_max_normaliser = MinMaxNormaliser(0, 1)\n",
        "saver = Saver(SPECTROGRAMS_SAVE_DIR, MIN_MAX_VALUES_SAVE_DIR)\n",
        "visualizer = Visualizer(SPECTROGRAMS_IMG_SAVE_DIR, FRAME_SIZE, HOP_LENGTH, OFFSET)\n",
        "reconstructor = AudioReconstructor(RECONSTRUCTED_AUDIO_SAVE_DIR, HOP_LENGTH, FRAME_SIZE)\n",
        "\n",
        "preprocessing_pipeline = PreprocessingPipeline()\n",
        "# preprocessing_pipeline.loader = loader\n",
        "preprocessing_pipeline.padder = padder\n",
        "preprocessing_pipeline.extractor = log_spectrogram_extractor\n",
        "preprocessing_pipeline.feature_extractor = feature_extractor\n",
        "preprocessing_pipeline.normaliser = min_max_normaliser\n",
        "preprocessing_pipeline.saver = saver\n",
        "preprocessing_pipeline.reconstructor = reconstructor\n",
        "\n",
        "number_of_clips = NUMBER_OF_CLIPS\n",
        "for root, _, files in os.walk(AUDIO_FILES_DIR):\n",
        "    for file in files:\n",
        "\n",
        "        if re.match(AUDIO_REGEX, file) and number_of_clips > 0:\n",
        "            print(file)\n",
        "            number_of_clips -= 1\n",
        "            y, sr = librosa.load(os.path.join(AUDIO_FILES_DIR, file), sr=SAMPLE_RATE, mono=MONO)\n",
        "                \n",
        "            offset = 0\n",
        "            loader = Loader(SAMPLE_RATE, offset, WINDOW_DURATION, WINDOW_DURATION, MONO)\n",
        "            preprocessing_pipeline.loader = loader\n",
        "            visualizer = Visualizer(SPECTROGRAMS_IMG_SAVE_DIR, FRAME_SIZE, HOP_LENGTH, offset)\n",
        "            preprocessing_pipeline.visualizer = visualizer\n",
        "\n",
        "            preprocessing_pipeline.process_file(AUDIO_FILES_DIR, file, 0, save_flg=True, visualize_flg=True, external_features_flg=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Miscellaneous "
      ],
      "metadata": {
        "id": "vb4vSzyFbChD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### To find optimal length (Independently Executable)"
      ],
      "metadata": {
        "id": "c4swV29ubFad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### For Audio Loading\n",
        "SAMPLE_RATE = 22050\n",
        "MONO = True\n",
        "\n",
        "### For STFT\n",
        "FRAME_SIZE = 512\n",
        "SEGMENT_DURATION = 0.74 # in seconds\n",
        "\n",
        "### For Processing\n",
        "SPECTROGRAM_IMG_SAVE_FLG=True\n",
        "VISUALIZE_FLG=True\n",
        "\n",
        "\n",
        "### INPUT. Read-only\n",
        "AUDIO_FILES_DIR = \"/content/drive/MyDrive/Music/VAE/audio/\"\n",
        "AUDIO_FILE_NAME = \"00000-05 DI.wav\"\n",
        "\n",
        "### OUTPUT\n",
        "SPECTROGRAMS_SAVE_DIR = \"/content/\"\n",
        "SPECTROGRAMS_IMG_SAVE_DIR = \"/content/drive/MyDrive/Music/VAE/spectrogram-img-hop_length-test/\"\n",
        "MIN_MAX_VALUES_SAVE_DIR = \"/content/\"\n",
        "\n",
        "\n",
        "# instantiate all objects\n",
        "padder = Padder()\n",
        "min_max_normaliser = MinMaxNormaliser(0, 1)\n",
        "saver = Saver(SPECTROGRAMS_SAVE_DIR, MIN_MAX_VALUES_SAVE_DIR)\n",
        "\n",
        "preprocessing_pipeline = PreprocessingPipeline()\n",
        "preprocessing_pipeline.padder = padder\n",
        "preprocessing_pipeline.normaliser = min_max_normaliser\n",
        "preprocessing_pipeline.saver = saver\n",
        "\n",
        "for i in range(2, 512, 20):\n",
        "    print(i)\n",
        "    OFFSET = 0.7\n",
        "\n",
        "    loader = Loader(SAMPLE_RATE, OFFSET, SEGMENT_DURATION, SEGMENT_DURATION, MONO)\n",
        "    preprocessing_pipeline.loader = loader\n",
        "\n",
        "    log_spectrogram_extractor = LogSpectrogramExtractor(FRAME_SIZE, i)\n",
        "    preprocessing_pipeline.spectrogram_extractor = log_spectrogram_extractor\n",
        "\n",
        "    visualizer = Visualizer(SPECTROGRAMS_IMG_SAVE_DIR, FRAME_SIZE, i, OFFSET)\n",
        "    preprocessing_pipeline.visualizer = visualizer\n",
        "\n",
        "    preprocessing_pipeline.process_file(AUDIO_FILES_DIR, AUDIO_FILE_NAME, i, spectrogram_img_save_flg=SPECTROGRAM_IMG_SAVE_FLG, visualize_flg=VISUALIZE_FLG)\n",
        "    # break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NTmbvO3bCRe",
        "outputId": "097fa770-9cd9-4027-b97c-90440f27bc88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "PreprocessingPipeline: Processing Segment: 00000-05-02 DI.wav\n",
            "22\n",
            "PreprocessingPipeline: Processing Segment: 00000-05-22 DI.wav\n",
            "42\n",
            "PreprocessingPipeline: Processing Segment: 00000-05-42 DI.wav\n",
            "62\n",
            "PreprocessingPipeline: Processing Segment: 00000-05-62 DI.wav\n",
            "82\n",
            "PreprocessingPipeline: Processing Segment: 00000-05-82 DI.wav\n",
            "102\n",
            "PreprocessingPipeline: Processing Segment: 00000-05-102 DI.wav\n",
            "122\n",
            "PreprocessingPipeline: Processing Segment: 00000-05-122 DI.wav\n",
            "142\n",
            "PreprocessingPipeline: Processing Segment: 00000-05-142 DI.wav\n",
            "162\n",
            "PreprocessingPipeline: Processing Segment: 00000-05-162 DI.wav\n",
            "182\n",
            "PreprocessingPipeline: Processing Segment: 00000-05-182 DI.wav\n",
            "202\n",
            "PreprocessingPipeline: Processing Segment: 00000-05-202 DI.wav\n",
            "222\n",
            "PreprocessingPipeline: Processing Segment: 00000-05-222 DI.wav\n",
            "242\n",
            "PreprocessingPipeline: Processing Segment: 00000-05-242 DI.wav\n",
            "262\n",
            "PreprocessingPipeline: Processing Segment: 00000-05-262 DI.wav\n",
            "282\n",
            "PreprocessingPipeline: Processing Segment: 00000-05-282 DI.wav\n",
            "302\n",
            "PreprocessingPipeline: Processing Segment: 00000-05-302 DI.wav\n",
            "322\n",
            "PreprocessingPipeline: Processing Segment: 00000-05-322 DI.wav\n",
            "342\n",
            "PreprocessingPipeline: Processing Segment: 00000-05-342 DI.wav\n",
            "362\n",
            "PreprocessingPipeline: Processing Segment: 00000-05-362 DI.wav\n",
            "382\n",
            "PreprocessingPipeline: Processing Segment: 00000-05-382 DI.wav\n",
            "402\n",
            "PreprocessingPipeline: Processing Segment: 00000-05-402 DI.wav\n",
            "422\n",
            "PreprocessingPipeline: Processing Segment: 00000-05-422 DI.wav\n",
            "442\n",
            "PreprocessingPipeline: Processing Segment: 00000-05-442 DI.wav\n",
            "462\n",
            "PreprocessingPipeline: Processing Segment: 00000-05-462 DI.wav\n",
            "482\n",
            "PreprocessingPipeline: Processing Segment: 00000-05-482 DI.wav\n",
            "502\n",
            "PreprocessingPipeline: Processing Segment: 00000-05-502 DI.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Try: Reconstructing the Audio (Independent)"
      ],
      "metadata": {
        "id": "rd2o1uJJdLeW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import soundfile as sf\n",
        "import librosa\n",
        "y, sr = librosa.load('/content/drive/MyDrive/Music/VAE/audio/00001-01 01A US Double Nrm.wav')\n",
        "print(y.shape)\n",
        "# Get the magnitude spectrogram\n",
        "S = np.abs(librosa.stft(y))\n",
        "print(S.shape)\n",
        "\n",
        "\n",
        "# Invert using Griffin-Lim\n",
        "y_inv = librosa.griffinlim(S)\n",
        "print(y_inv.shape)\n",
        "sf.write('/content/drive/MyDrive/Music/VAE/reconstructed 00001-01 01A US Double Nrm.wav', y_inv, sr)\n",
        "\n",
        "\n",
        "# Invert without estimating phase\n",
        "y_istft = librosa.istft(S)\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "fig, ax = plt.subplots(nrows=3, sharex=True, sharey=True)\n",
        "\n",
        "\n",
        "librosa.display.waveshow(y, sr=sr, color='b', ax=ax[0])\n",
        "ax[0].set(title='Original', xlabel=None)\n",
        "ax[0].label_outer()\n",
        "librosa.display.waveshow(y_inv, sr=sr, color='g', ax=ax[1])\n",
        "ax[1].set(title='Griffin-Lim reconstruction', xlabel=None)\n",
        "ax[1].label_outer()\n",
        "librosa.display.waveshow(y_istft, sr=sr, color='r', ax=ax[2])\n",
        "ax[2].set_title('Magnitude-only istft reconstruction')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "JpK7AA7GdKrl",
        "outputId": "822c680e-71de-4c12-8b37-18c41558ca81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoundFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msf_desc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m             \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msf_desc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[1;32m    628\u001b[0m                                          format, subtype, endian)\n\u001b[0;32m--> 629\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missuperset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'r+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseekable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1183\u001b[0m         _error_check(_snd.sf_error(file_ptr),\n\u001b[0;32m-> 1184\u001b[0;31m                      \"Error opening {0!r}: \".format(self.name))\n\u001b[0m\u001b[1;32m   1185\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode_int\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_snd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSFM_WRITE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m_error_check\u001b[0;34m(err, prefix)\u001b[0m\n\u001b[1;32m   1356\u001b[0m         \u001b[0merr_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_snd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msf_error_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1357\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0m_ffi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'replace'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error opening '/content/drive/MyDrive/Music/VAE/audio/00001-01 01A US Double Nrm.wav': System error.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-de961b8a036d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msoundfile\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Music/VAE/audio/00001-01 01A US Double Nrm.wav'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Get the magnitude spectrogram\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPurePath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PySoundFile failed. Trying audioread instead.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__audioread_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36m__audioread_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0maudioread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mn_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/audioread/__init__.py\u001b[0m in \u001b[0;36maudio_open\u001b[0;34m(path, backends)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mBackendClass\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackends\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mBackendClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/audioread/rawread.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \"\"\"\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Music/VAE/audio/00001-01 01A US Double Nrm.wav'"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "1.2 Create Audio Spectrogram (Windowed version) LATEST",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}