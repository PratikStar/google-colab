{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PratikStar/google-colab/blob/main/All_in_one_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lHfnqiV9z91"
      },
      "source": [
        "### Some notes\n",
        "Original owner: pratik-sutar@g.ecc.u-tokyo.ac.jp\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports & Drive mount"
      ],
      "metadata": {
        "id": "UFK5W2uaYcyT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KMFwAcHRdjx",
        "outputId": "f930b395-808c-4daa-d0d3-36461979c565"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pickle\n",
        "import re\n",
        "import librosa\n",
        "import librosa.display\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import inspect\n",
        "import soundfile as sf\n",
        "import math\n",
        "import sys\n",
        "from random import random\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfChkUfy4wwH"
      },
      "source": [
        "## Pipeline Classes & Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "geYxumIg3a6L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "112fc0f9-d274-498e-fbc9-6e54969ac226"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading clip from offset: 55.18323405609419s\n",
            "(256, 640)\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Get a clip\n",
        "Randomly select a batch\n",
        "    - chop into segments\n",
        "    - Convert to spectrogram\n",
        "Input to VAE\n",
        "\n",
        "'''\n",
        "CLIPS_DIR = \"/content/drive/Shareddrives/timbre-space-drive/01-audio-data/01-clips\"\n",
        "DI_CLIP = \"/content/drive/Shareddrives/timbre-space-drive/01-audio-data/DI.wav\"\n",
        "CLIP_DURATION = None\n",
        "CLIP_STFT_MIN = None\n",
        "CLIP_STFT_MAX = None\n",
        "SAMPLE_RATE = 22050\n",
        "STFT_FRAMESIZE = 512\n",
        "\n",
        "\n",
        "segment_size = 0.743 # in sec.\n",
        "batch_size = 10\n",
        "\n",
        "\n",
        "# Extracts duration and min/max of stft from the original clip as a whole\n",
        "def run_once():\n",
        "    global CLIP_DURATION, CLIP_STFT_MIN, CLIP_STFT_MAX\n",
        "    y, sr = librosa.load(DI_CLIP, sr=SAMPLE_RATE, mono=True)\n",
        "    CLIP_DURATION = librosa.get_duration(y=y, sr=sr)\n",
        "\n",
        "    stft = librosa.stft(y,\n",
        "                        n_fft=STFT_FRAMESIZE,\n",
        "                        hop_length=STFT_FRAMESIZE // 2)[:-1]\n",
        "    spectrogram = np.abs(stft)\n",
        "    phases = np.angle(stft)\n",
        "    log_spectrogram = librosa.amplitude_to_db(spectrogram)\n",
        "    CLIP_STFT_MIN = log_spectrogram.min()\n",
        "    CLIP_STFT_MAX = log_spectrogram.max()\n",
        "\n",
        "run_once()\n",
        "\n",
        "def get_random_batch():\n",
        "    load_duration = segment_size * batch_size # in sec\n",
        "    if load_duration > CLIP_DURATION:\n",
        "        print(\"ERROR: Insufficient Clip duration. Reduce the batch_size or segment_size\")\n",
        "        return None\n",
        "    random_seed = random()\n",
        "    load_offset = random_seed * (CLIP_DURATION - (load_duration))\n",
        "    print(f\"Loading clip from offset: {load_offset}s\")\n",
        "\n",
        "    di_signal = librosa.load(DI_CLIP,\n",
        "                        sr=SAMPLE_RATE,\n",
        "                        duration=load_duration,\n",
        "                        offset=load_offset,\n",
        "                        mono=True)[0]\n",
        "\n",
        "    stft = librosa.stft(di_signal,\n",
        "                        n_fft=STFT_FRAMESIZE,\n",
        "                        hop_length=STFT_FRAMESIZE // 2)[:-1]\n",
        "    spectrogram = np.abs(stft)\n",
        "    print(spectrogram.shape)\n",
        "    phases = np.angle(stft)\n",
        "    log_spectrogram = librosa.amplitude_to_db(spectrogram)\n",
        "    normalized_spectrogram = (log_spectrogram - CLIP_STFT_MIN) / (CLIP_STFT_MAX - CLIP_STFT_MIN)\n",
        "    batch = normalized_spectrogram.reshape(normalized_spectrogram.shape[0],\n",
        "                                           normalized_spectrogram.shape[1] // batch_size, \n",
        "                                           batch_size)\n",
        "    return batch\n",
        "\n",
        "batch = get_random_batch()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch; torch.manual_seed(0)\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils\n",
        "import torch.distributions\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt; plt.rcParams['figure.dpi'] = 200\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n"
      ],
      "metadata": {
        "id": "b7DjthwsKBZw"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, latent_dims):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.linear1 = nn.Linear(784, 512)\n",
        "        self.linear2 = nn.Linear(512, latent_dims)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = F.relu(self.linear1(x))\n",
        "        return self.linear2(x)"
      ],
      "metadata": {
        "id": "xSj00KhpOFrh"
      },
      "execution_count": 29,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "All in one Notebook",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}