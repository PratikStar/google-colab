{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "2. Creating & Training Audio VAE",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PratikStar/google-colab/blob/main/2_Creating_%26_Training_Audio_VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHIAgyMQE-60"
      },
      "source": [
        "### Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSpskSmkGT4C",
        "outputId": "cb0f2a84-e43a-49af-e2a6-2f8419fa4508"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',  force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdlnHSb1FDsJ"
      },
      "source": [
        "### Install tensorflow v2.4.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vr15BDmekCAy",
        "outputId": "a1ab961c-bfb6-4110-e6ae-9375fba1bc9d"
      },
      "source": [
        "!pip uninstall tensorflow\n",
        "!pip install tensorflow==2.4.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.6.0\n",
            "Uninstalling tensorflow-2.6.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/import_pb_to_tensorboard\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow-2.6.0.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled tensorflow-2.6.0\n",
            "Collecting tensorflow==2.4.0\n",
            "  Downloading tensorflow-2.4.0-cp37-cp37m-manylinux2010_x86_64.whl (394.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 394.7 MB 17 kB/s \n",
            "\u001b[?25hRequirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.6.3)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (3.3.0)\n",
            "Collecting h5py~=2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 46.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (3.7.4.3)\n",
            "Collecting tensorflow-estimator<2.5.0,>=2.4.0rc0\n",
            "  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 56.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.1.2)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (2.6.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.12)\n",
            "Collecting gast==0.3.3\n",
            "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.1.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (0.37.0)\n",
            "Collecting grpcio~=1.32.0\n",
            "  Downloading grpcio-1.32.0-cp37-cp37m-manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 51.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.19.5)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (0.12.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.12.1)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (0.2.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (3.17.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (0.6.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (1.34.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (0.4.5)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (1.8.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (57.4.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.0) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.0) (4.6.4)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.0) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.0) (3.5.0)\n",
            "Installing collected packages: grpcio, tensorflow-estimator, h5py, gast, tensorflow\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.39.0\n",
            "    Uninstalling grpcio-1.39.0:\n",
            "      Successfully uninstalled grpcio-1.39.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.6.0\n",
            "    Uninstalling tensorflow-estimator-2.6.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.6.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "Successfully installed gast-0.3.3 grpcio-1.32.0 h5py-2.10.0 tensorflow-2.4.0 tensorflow-estimator-2.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTlUZZpvz9Xt"
      },
      "source": [
        "## VAE Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlxNWPvvVn1L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17b0b9a1-987a-44ce-f59c-767962cfe88b"
      },
      "source": [
        "import os\n",
        "import pickle\n",
        "import csv\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization, \\\n",
        "    Flatten, Dense, Reshape, Conv2DTranspose, Activation, Lambda\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "\n",
        "class VAE:\n",
        "    \"\"\"\n",
        "    VAE represents a Deep Convolutional variational autoencoder architecture\n",
        "    with mirrored encoder and decoder components.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 input_shape,\n",
        "                 conv_filters,\n",
        "                 conv_kernels,\n",
        "                 conv_strides,\n",
        "                 latent_space_dim):\n",
        "        self.input_shape = input_shape\n",
        "        self.conv_filters = conv_filters\n",
        "        self.conv_kernels = conv_kernels \n",
        "        self.conv_strides = conv_strides \n",
        "        self.latent_space_dim = latent_space_dim \n",
        "        self.reconstruction_loss_weight = 1000000\n",
        "\n",
        "        self.encoder = None\n",
        "        self.decoder = None\n",
        "        self.model = None\n",
        "\n",
        "        self._num_conv_layers = len(conv_filters)\n",
        "        self._shape_before_bottleneck = None\n",
        "        self._model_input = None\n",
        "\n",
        "        self._build()\n",
        "\n",
        "    def summary(self):\n",
        "        self.encoder.summary()\n",
        "        self.decoder.summary()\n",
        "        self.model.summary()\n",
        "\n",
        "    def compile(self, learning_rate=0.0001):\n",
        "        optimizer = Adam(learning_rate=learning_rate)\n",
        "        self.model.compile(optimizer=optimizer,\n",
        "                           loss=self._calculate_combined_loss,\n",
        "                           metrics=[self._calculate_reconstruction_loss,\n",
        "                                    self._calculate_kl_loss])\n",
        "\n",
        "    def train(self, x_train, batch_size, num_epochs):\n",
        "        self.model.fit(x_train,\n",
        "                       x_train,\n",
        "                       batch_size=batch_size,\n",
        "                       epochs=num_epochs,\n",
        "                       shuffle=True)\n",
        "\n",
        "    def save(self, save_folder=\".\"):\n",
        "        self._create_folder_if_it_doesnt_exist(save_folder)\n",
        "        self._save_parameters(save_folder)\n",
        "        self._save_weights(save_folder)\n",
        "\n",
        "    def reconstruct(self, images):\n",
        "        latent_representations = self.encoder.predict(images)\n",
        "        reconstructed_images = self.decoder.predict(latent_representations)\n",
        "        return reconstructed_images, latent_representations\n",
        "\n",
        "    def _save_parameters(self, save_folder):\n",
        "        parameters = [\n",
        "            self.input_shape,\n",
        "            self.conv_filters,\n",
        "            self.conv_kernels,\n",
        "            self.conv_strides,\n",
        "            self.latent_space_dim\n",
        "        ]\n",
        "        save_path = os.path.join(save_folder, \"parameters.pkl\")\n",
        "        with open(save_path, \"wb\") as f:\n",
        "            print(parameters)\n",
        "            pickle.dump(parameters, f)\n",
        "\n",
        "    def _save_weights(self, save_folder):\n",
        "        save_path = os.path.join(save_folder, \"weights.h5\")\n",
        "        self.model.save_weights(save_path)\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, save_folder=\".\"):\n",
        "        parameters_path = os.path.join(save_folder, \"parameters.pkl\")\n",
        "        with open(parameters_path, \"rb\") as f:\n",
        "            parameters = pickle.load(f)\n",
        "        autoencoder = VAE(*parameters)\n",
        "        weights_path = os.path.join(save_folder, \"weights.h5\")\n",
        "        autoencoder.load_weights(weights_path)\n",
        "        return autoencoder\n",
        "\n",
        "    def load_weights(self, weights_path):\n",
        "        self.model.load_weights(weights_path)\n",
        "\n",
        "    def _calculate_combined_loss(self, y_target, y_predicted):\n",
        "        reconstruction_loss = self._calculate_reconstruction_loss(y_target, y_predicted)\n",
        "        kl_loss = self._calculate_kl_loss(y_target, y_predicted)\n",
        "        combined_loss = self.reconstruction_loss_weight * reconstruction_loss\\\n",
        "                                                         + kl_loss\n",
        "        return combined_loss\n",
        "\n",
        "    def _calculate_reconstruction_loss(self, y_target, y_predicted):\n",
        "        error = y_target - y_predicted\n",
        "        reconstruction_loss = K.mean(K.square(error), axis=[1, 2, 3])\n",
        "        return reconstruction_loss\n",
        "\n",
        "    def _calculate_kl_loss(self, y_target, y_predicted):\n",
        "        kl_loss = -0.5 * K.sum(1 + self.log_variance - K.square(self.mu) -\n",
        "                               K.exp(self.log_variance), axis=1)\n",
        "        return kl_loss\n",
        "\n",
        "    def _create_folder_if_it_doesnt_exist(self, folder):\n",
        "        if not os.path.exists(folder):\n",
        "            os.makedirs(folder)\n",
        "\n",
        "    def _build(self):\n",
        "        self._build_encoder()\n",
        "        self._build_decoder()\n",
        "        self._build_autoencoder()\n",
        "\n",
        "    def _build_autoencoder(self):\n",
        "        model_input = self._model_input\n",
        "        model_output = self.decoder(self.encoder(model_input))\n",
        "        self.model = Model(model_input, model_output, name=\"autoencoder\")\n",
        "\n",
        "    def _build_decoder(self):\n",
        "        decoder_input = self._add_decoder_input()\n",
        "        dense_layer = self._add_dense_layer(decoder_input)\n",
        "        reshape_layer = self._add_reshape_layer(dense_layer)\n",
        "        conv_transpose_layers = self._add_conv_transpose_layers(reshape_layer)\n",
        "        decoder_output = self._add_decoder_output(conv_transpose_layers)\n",
        "        self.decoder = Model(decoder_input, decoder_output, name=\"decoder\")\n",
        "\n",
        "    def _add_decoder_input(self):\n",
        "        return Input(shape=self.latent_space_dim, name=\"decoder_input\")\n",
        "\n",
        "    def _add_dense_layer(self, decoder_input):\n",
        "        num_neurons = np.prod(self._shape_before_bottleneck) # [1, 2, 4] -> 8\n",
        "        dense_layer = Dense(num_neurons, name=\"decoder_dense\")(decoder_input)\n",
        "        return dense_layer\n",
        "\n",
        "    def _add_reshape_layer(self, dense_layer):\n",
        "        return Reshape(self._shape_before_bottleneck)(dense_layer)\n",
        "\n",
        "    def _add_conv_transpose_layers(self, x):\n",
        "        \"\"\"Add conv transpose blocks.\"\"\"\n",
        "        # loop through all the conv layers in reverse order and stop at the\n",
        "        # first layer\n",
        "        for layer_index in reversed(range(1, self._num_conv_layers)):\n",
        "            x = self._add_conv_transpose_layer(layer_index, x)\n",
        "        return x\n",
        "\n",
        "    def _add_conv_transpose_layer(self, layer_index, x):\n",
        "        layer_num = self._num_conv_layers - layer_index\n",
        "        conv_transpose_layer = Conv2DTranspose(\n",
        "            filters=self.conv_filters[layer_index],\n",
        "            kernel_size=self.conv_kernels[layer_index],\n",
        "            strides=self.conv_strides[layer_index],\n",
        "            padding=\"same\",\n",
        "            name=f\"decoder_conv_transpose_layer_{layer_num}\"\n",
        "        )\n",
        "        x = conv_transpose_layer(x)\n",
        "        x = ReLU(name=f\"decoder_relu_{layer_num}\")(x)\n",
        "        x = BatchNormalization(name=f\"decoder_bn_{layer_num}\")(x)\n",
        "        return x\n",
        "\n",
        "    def _add_decoder_output(self, x):\n",
        "        conv_transpose_layer = Conv2DTranspose(\n",
        "            filters=1,\n",
        "            kernel_size=self.conv_kernels[0],\n",
        "            strides=self.conv_strides[0],\n",
        "            padding=\"same\",\n",
        "            name=f\"decoder_conv_transpose_layer_{self._num_conv_layers}\"\n",
        "        )\n",
        "        x = conv_transpose_layer(x)\n",
        "        output_layer = Activation(\"sigmoid\", name=\"sigmoid_layer\")(x)\n",
        "        return output_layer\n",
        "\n",
        "    def _build_encoder(self):\n",
        "        encoder_input = self._add_encoder_input()\n",
        "        conv_layers = self._add_conv_layers(encoder_input)\n",
        "        bottleneck = self._add_bottleneck(conv_layers)\n",
        "        self._model_input = encoder_input\n",
        "        self.encoder = Model(encoder_input, bottleneck, name=\"encoder\")\n",
        "\n",
        "    def _add_encoder_input(self):\n",
        "        return Input(shape=self.input_shape, name=\"encoder_input\")\n",
        "\n",
        "    def _add_conv_layers(self, encoder_input):\n",
        "        \"\"\"Create all convolutional blocks in encoder.\"\"\"\n",
        "        x = encoder_input\n",
        "        for layer_index in range(self._num_conv_layers):\n",
        "            x = self._add_conv_layer(layer_index, x)\n",
        "        return x\n",
        "\n",
        "    def _add_conv_layer(self, layer_index, x):\n",
        "        \"\"\"Add a convolutional block to a graph of layers, consisting of\n",
        "        conv 2d + ReLU + batch normalization.\n",
        "        \"\"\"\n",
        "        layer_number = layer_index + 1\n",
        "        conv_layer = Conv2D(\n",
        "            filters=self.conv_filters[layer_index],\n",
        "            kernel_size=self.conv_kernels[layer_index],\n",
        "            strides=self.conv_strides[layer_index],\n",
        "            padding=\"same\",\n",
        "            name=f\"encoder_conv_layer_{layer_number}\"\n",
        "        )\n",
        "        x = conv_layer(x)\n",
        "        x = ReLU(name=f\"encoder_relu_{layer_number}\")(x)\n",
        "        x = BatchNormalization(name=f\"encoder_bn_{layer_number}\")(x)\n",
        "        return x\n",
        "\n",
        "    def _add_bottleneck(self, x):\n",
        "        \"\"\"Flatten data and add bottleneck with Guassian sampling (Dense\n",
        "        layer).\n",
        "        \"\"\"\n",
        "        self._shape_before_bottleneck = K.int_shape(x)[1:]\n",
        "        x = Flatten()(x)\n",
        "        self.mu = Dense(self.latent_space_dim, name=\"mu\")(x)\n",
        "        self.log_variance = Dense(self.latent_space_dim,\n",
        "                                  name=\"log_variance\")(x)\n",
        "\n",
        "        def sample_point_from_normal_distribution(args):\n",
        "            mu, log_variance = args\n",
        "            epsilon = K.random_normal(shape=K.shape(self.mu), mean=0.,\n",
        "                                      stddev=1.)\n",
        "            sampled_point = mu + K.exp(log_variance / 2) * epsilon\n",
        "            return sampled_point\n",
        "\n",
        "        x = Lambda(sample_point_from_normal_distribution,\n",
        "                   name=\"encoder_output\")([self.mu, self.log_variance])\n",
        "        return x\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    autoencoder = VAE(\n",
        "        input_shape=(512, 64, 1),\n",
        "        conv_filters=(32, 64, 64, 64),\n",
        "        conv_kernels=(3, 3, 3, 3),\n",
        "        conv_strides=(1, 2, 2, 1),\n",
        "        latent_space_dim=32\n",
        "    )\n",
        "    autoencoder.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "encoder_input (InputLayer)      [(None, 512, 64, 1)] 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "encoder_conv_layer_1 (Conv2D)   (None, 512, 64, 32)  320         encoder_input[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "encoder_relu_1 (ReLU)           (None, 512, 64, 32)  0           encoder_conv_layer_1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "encoder_bn_1 (BatchNormalizatio (None, 512, 64, 32)  128         encoder_relu_1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "encoder_conv_layer_2 (Conv2D)   (None, 256, 32, 64)  18496       encoder_bn_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "encoder_relu_2 (ReLU)           (None, 256, 32, 64)  0           encoder_conv_layer_2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "encoder_bn_2 (BatchNormalizatio (None, 256, 32, 64)  256         encoder_relu_2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "encoder_conv_layer_3 (Conv2D)   (None, 128, 16, 64)  36928       encoder_bn_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "encoder_relu_3 (ReLU)           (None, 128, 16, 64)  0           encoder_conv_layer_3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "encoder_bn_3 (BatchNormalizatio (None, 128, 16, 64)  256         encoder_relu_3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "encoder_conv_layer_4 (Conv2D)   (None, 128, 16, 64)  36928       encoder_bn_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "encoder_relu_4 (ReLU)           (None, 128, 16, 64)  0           encoder_conv_layer_4[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "encoder_bn_4 (BatchNormalizatio (None, 128, 16, 64)  256         encoder_relu_4[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 131072)       0           encoder_bn_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "mu (Dense)                      (None, 32)           4194336     flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "log_variance (Dense)            (None, 32)           4194336     flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "encoder_output (Lambda)         (None, 32)           0           mu[0][0]                         \n",
            "                                                                 log_variance[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 8,482,240\n",
            "Trainable params: 8,481,792\n",
            "Non-trainable params: 448\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "decoder_input (InputLayer)   [(None, 32)]              0         \n",
            "_________________________________________________________________\n",
            "decoder_dense (Dense)        (None, 131072)            4325376   \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 128, 16, 64)       0         \n",
            "_________________________________________________________________\n",
            "decoder_conv_transpose_layer (None, 128, 16, 64)       36928     \n",
            "_________________________________________________________________\n",
            "decoder_relu_1 (ReLU)        (None, 128, 16, 64)       0         \n",
            "_________________________________________________________________\n",
            "decoder_bn_1 (BatchNormaliza (None, 128, 16, 64)       256       \n",
            "_________________________________________________________________\n",
            "decoder_conv_transpose_layer (None, 256, 32, 64)       36928     \n",
            "_________________________________________________________________\n",
            "decoder_relu_2 (ReLU)        (None, 256, 32, 64)       0         \n",
            "_________________________________________________________________\n",
            "decoder_bn_2 (BatchNormaliza (None, 256, 32, 64)       256       \n",
            "_________________________________________________________________\n",
            "decoder_conv_transpose_layer (None, 512, 64, 64)       36928     \n",
            "_________________________________________________________________\n",
            "decoder_relu_3 (ReLU)        (None, 512, 64, 64)       0         \n",
            "_________________________________________________________________\n",
            "decoder_bn_3 (BatchNormaliza (None, 512, 64, 64)       256       \n",
            "_________________________________________________________________\n",
            "decoder_conv_transpose_layer (None, 512, 64, 1)        577       \n",
            "_________________________________________________________________\n",
            "sigmoid_layer (Activation)   (None, 512, 64, 1)        0         \n",
            "=================================================================\n",
            "Total params: 4,437,505\n",
            "Trainable params: 4,437,121\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n",
            "Model: \"autoencoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_input (InputLayer)   [(None, 512, 64, 1)]      0         \n",
            "_________________________________________________________________\n",
            "encoder (Functional)         (None, 32)                8482240   \n",
            "_________________________________________________________________\n",
            "decoder (Functional)         (None, 512, 64, 1)        4437505   \n",
            "=================================================================\n",
            "Total params: 12,919,745\n",
            "Trainable params: 12,918,913\n",
            "Non-trainable params: 832\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MetCvcrpWJ9g"
      },
      "source": [
        "2. Train VAE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIykrk9Dz54n"
      },
      "source": [
        "## Train the VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4XDb66wU0qt",
        "outputId": "c07d592f-3fd7-4feb-dcc5-b74f8df605ac"
      },
      "source": [
        "import re\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "LEARNING_RATE = 0.0001\n",
        "BATCH_SIZE = 50\n",
        "EPOCHS = 500\n",
        "LATENT_SPACE_DIM= 8\n",
        "\n",
        "SPECTROGRAMS_PATH = \"/content/drive/MyDrive/Music/VAE/spectrogram\"\n",
        "\n",
        "def load_fsdd(spectrograms_path):\n",
        "    dataset = {}\n",
        "    for root, _, file_names in os.walk(spectrograms_path):\n",
        "        for file_name in file_names:\n",
        "\n",
        "            if True: # re.match(regex, file_name):\n",
        "                file_path = os.path.join(root, file_name)\n",
        "                spectrogram = np.load(file_path) # (n_bins, n_frames, 1) \n",
        "                # print(spectrogram.shape)\n",
        "                dataset[file_name] = spectrogram[..., np.newaxis]\n",
        "    return dataset\n",
        "\n",
        "def train(x_train, learning_rate, batch_size, epochs):\n",
        "    autoencoder = VAE(\n",
        "        input_shape=(256, 64, 1),\n",
        "        conv_filters=(32, 16, 16, 8), # 16, 8, 8, 4 -> \n",
        "        conv_kernels=(3, 3, 3, 3),\n",
        "        conv_strides=(1, 2, 2, 1),\n",
        "        latent_space_dim=LATENT_SPACE_DIM\n",
        "    )\n",
        "    # autoencoder.summary()\n",
        "    print(x_train.shape)\n",
        "    autoencoder.compile(learning_rate)\n",
        "    autoencoder.train(x_train, batch_size, epochs)\n",
        "    return autoencoder\n",
        "\n",
        "\n",
        "dataset = load_fsdd(SPECTROGRAMS_PATH)\n",
        "\n",
        "autoencoder = train(np.array(list(dataset.values())), LEARNING_RATE, BATCH_SIZE, EPOCHS)\n",
        "model_suffix = \"-\" + str(LATENT_SPACE_DIM) + \"-\" + str(BATCH_SIZE) + \"-\" + str(EPOCHS)\n",
        "autoencoder.save(\"/content/drive/MyDrive/Music/VAE/model\" + model_suffix)\n",
        "print(\"Model Saved!!\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(960, 256, 64, 1)\n",
            "Train on 960 samples\n",
            "Epoch 1/500\n",
            "960/960 [==============================] - 18s 19ms/sample - loss: 197296.8241 - _calculate_reconstruction_loss: 0.1972 - _calculate_kl_loss: 116.7679\n",
            "Epoch 2/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 162356.5990 - _calculate_reconstruction_loss: 0.1593 - _calculate_kl_loss: 3100.5803\n",
            "Epoch 3/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 147949.5244 - _calculate_reconstruction_loss: 0.1472 - _calculate_kl_loss: 778.9922\n",
            "Epoch 4/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 131775.8138 - _calculate_reconstruction_loss: 0.1315 - _calculate_kl_loss: 226.7590\n",
            "Epoch 5/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 108638.0469 - _calculate_reconstruction_loss: 0.1085 - _calculate_kl_loss: 145.9994\n",
            "Epoch 6/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 92104.6510 - _calculate_reconstruction_loss: 0.0920 - _calculate_kl_loss: 144.5107\n",
            "Epoch 7/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 82264.9655 - _calculate_reconstruction_loss: 0.0821 - _calculate_kl_loss: 158.5204\n",
            "Epoch 8/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 74963.8156 - _calculate_reconstruction_loss: 0.0748 - _calculate_kl_loss: 166.8932\n",
            "Epoch 9/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 69090.6305 - _calculate_reconstruction_loss: 0.0689 - _calculate_kl_loss: 164.3963\n",
            "Epoch 10/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 64041.2143 - _calculate_reconstruction_loss: 0.0639 - _calculate_kl_loss: 163.4405\n",
            "Epoch 11/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 59872.3232 - _calculate_reconstruction_loss: 0.0597 - _calculate_kl_loss: 164.9436\n",
            "Epoch 12/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 56026.8951 - _calculate_reconstruction_loss: 0.0559 - _calculate_kl_loss: 160.0577\n",
            "Epoch 13/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 53004.3704 - _calculate_reconstruction_loss: 0.0528 - _calculate_kl_loss: 157.9255\n",
            "Epoch 14/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 50519.7974 - _calculate_reconstruction_loss: 0.0504 - _calculate_kl_loss: 156.9158\n",
            "Epoch 15/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 48038.9889 - _calculate_reconstruction_loss: 0.0479 - _calculate_kl_loss: 157.8755\n",
            "Epoch 16/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 45836.2802 - _calculate_reconstruction_loss: 0.0457 - _calculate_kl_loss: 158.7365\n",
            "Epoch 17/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 43794.7192 - _calculate_reconstruction_loss: 0.0436 - _calculate_kl_loss: 156.6964\n",
            "Epoch 18/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 42326.3680 - _calculate_reconstruction_loss: 0.0422 - _calculate_kl_loss: 159.0754\n",
            "Epoch 19/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 41173.7599 - _calculate_reconstruction_loss: 0.0410 - _calculate_kl_loss: 157.2566\n",
            "Epoch 20/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 39577.6605 - _calculate_reconstruction_loss: 0.0394 - _calculate_kl_loss: 158.8467\n",
            "Epoch 21/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 38566.2860 - _calculate_reconstruction_loss: 0.0384 - _calculate_kl_loss: 160.9539\n",
            "Epoch 22/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 37510.8713 - _calculate_reconstruction_loss: 0.0374 - _calculate_kl_loss: 159.0221\n",
            "Epoch 23/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 36098.5146 - _calculate_reconstruction_loss: 0.0359 - _calculate_kl_loss: 160.3094\n",
            "Epoch 24/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 35753.1325 - _calculate_reconstruction_loss: 0.0356 - _calculate_kl_loss: 161.3588\n",
            "Epoch 25/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 34524.3432 - _calculate_reconstruction_loss: 0.0344 - _calculate_kl_loss: 159.4618\n",
            "Epoch 26/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 33809.0356 - _calculate_reconstruction_loss: 0.0336 - _calculate_kl_loss: 162.3986\n",
            "Epoch 27/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 32811.5569 - _calculate_reconstruction_loss: 0.0327 - _calculate_kl_loss: 160.6179\n",
            "Epoch 28/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 32568.7142 - _calculate_reconstruction_loss: 0.0324 - _calculate_kl_loss: 166.0904\n",
            "Epoch 29/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 31860.5909 - _calculate_reconstruction_loss: 0.0317 - _calculate_kl_loss: 166.3831\n",
            "Epoch 30/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 30823.2499 - _calculate_reconstruction_loss: 0.0307 - _calculate_kl_loss: 164.4893\n",
            "Epoch 31/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 30536.9592 - _calculate_reconstruction_loss: 0.0304 - _calculate_kl_loss: 165.0470\n",
            "Epoch 32/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 29780.2193 - _calculate_reconstruction_loss: 0.0296 - _calculate_kl_loss: 171.7301\n",
            "Epoch 33/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 28898.2752 - _calculate_reconstruction_loss: 0.0287 - _calculate_kl_loss: 168.7344\n",
            "Epoch 34/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 28522.1193 - _calculate_reconstruction_loss: 0.0284 - _calculate_kl_loss: 169.6147\n",
            "Epoch 35/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 27558.1869 - _calculate_reconstruction_loss: 0.0274 - _calculate_kl_loss: 169.8369\n",
            "Epoch 36/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 27449.3877 - _calculate_reconstruction_loss: 0.0273 - _calculate_kl_loss: 170.0715\n",
            "Epoch 37/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 26184.4333 - _calculate_reconstruction_loss: 0.0260 - _calculate_kl_loss: 173.4107\n",
            "Epoch 38/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 26102.9893 - _calculate_reconstruction_loss: 0.0259 - _calculate_kl_loss: 172.7971\n",
            "Epoch 39/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 26025.6596 - _calculate_reconstruction_loss: 0.0259 - _calculate_kl_loss: 175.1401\n",
            "Epoch 40/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 24793.5007 - _calculate_reconstruction_loss: 0.0246 - _calculate_kl_loss: 175.8844\n",
            "Epoch 41/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 24360.8959 - _calculate_reconstruction_loss: 0.0242 - _calculate_kl_loss: 177.1959\n",
            "Epoch 42/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 23968.4860 - _calculate_reconstruction_loss: 0.0238 - _calculate_kl_loss: 183.7743\n",
            "Epoch 43/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 23127.1551 - _calculate_reconstruction_loss: 0.0229 - _calculate_kl_loss: 189.7163\n",
            "Epoch 44/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 22693.6931 - _calculate_reconstruction_loss: 0.0225 - _calculate_kl_loss: 193.9688\n",
            "Epoch 45/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 21873.4767 - _calculate_reconstruction_loss: 0.0217 - _calculate_kl_loss: 199.9184\n",
            "Epoch 46/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 21585.8327 - _calculate_reconstruction_loss: 0.0214 - _calculate_kl_loss: 202.2701\n",
            "Epoch 47/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 20924.6825 - _calculate_reconstruction_loss: 0.0207 - _calculate_kl_loss: 206.1070\n",
            "Epoch 48/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 20519.1559 - _calculate_reconstruction_loss: 0.0203 - _calculate_kl_loss: 207.5755\n",
            "Epoch 49/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 20572.9315 - _calculate_reconstruction_loss: 0.0204 - _calculate_kl_loss: 210.5171\n",
            "Epoch 50/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 19896.6709 - _calculate_reconstruction_loss: 0.0197 - _calculate_kl_loss: 210.6663\n",
            "Epoch 51/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 19123.5849 - _calculate_reconstruction_loss: 0.0189 - _calculate_kl_loss: 207.5325\n",
            "Epoch 52/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 18827.8325 - _calculate_reconstruction_loss: 0.0186 - _calculate_kl_loss: 205.1118\n",
            "Epoch 53/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 18509.3070 - _calculate_reconstruction_loss: 0.0183 - _calculate_kl_loss: 203.2053\n",
            "Epoch 54/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 18181.5551 - _calculate_reconstruction_loss: 0.0180 - _calculate_kl_loss: 203.9990\n",
            "Epoch 55/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 18172.7797 - _calculate_reconstruction_loss: 0.0180 - _calculate_kl_loss: 203.0257\n",
            "Epoch 56/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 18035.0697 - _calculate_reconstruction_loss: 0.0178 - _calculate_kl_loss: 205.4660\n",
            "Epoch 57/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 17134.4350 - _calculate_reconstruction_loss: 0.0169 - _calculate_kl_loss: 198.8400\n",
            "Epoch 58/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 16715.9199 - _calculate_reconstruction_loss: 0.0165 - _calculate_kl_loss: 195.7737\n",
            "Epoch 59/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 17042.6726 - _calculate_reconstruction_loss: 0.0168 - _calculate_kl_loss: 199.0699\n",
            "Epoch 60/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 17106.0749 - _calculate_reconstruction_loss: 0.0169 - _calculate_kl_loss: 198.0158\n",
            "Epoch 61/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 15850.5131 - _calculate_reconstruction_loss: 0.0157 - _calculate_kl_loss: 195.4922\n",
            "Epoch 62/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 15916.5192 - _calculate_reconstruction_loss: 0.0157 - _calculate_kl_loss: 194.8071\n",
            "Epoch 63/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 15472.2468 - _calculate_reconstruction_loss: 0.0153 - _calculate_kl_loss: 192.9609\n",
            "Epoch 64/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 15522.7562 - _calculate_reconstruction_loss: 0.0153 - _calculate_kl_loss: 192.5335\n",
            "Epoch 65/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 15003.1610 - _calculate_reconstruction_loss: 0.0148 - _calculate_kl_loss: 190.8789\n",
            "Epoch 66/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 14891.5142 - _calculate_reconstruction_loss: 0.0147 - _calculate_kl_loss: 190.9494\n",
            "Epoch 67/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 14759.8096 - _calculate_reconstruction_loss: 0.0146 - _calculate_kl_loss: 188.9599\n",
            "Epoch 68/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 14505.4073 - _calculate_reconstruction_loss: 0.0143 - _calculate_kl_loss: 183.5236\n",
            "Epoch 69/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 14522.0290 - _calculate_reconstruction_loss: 0.0143 - _calculate_kl_loss: 183.6653\n",
            "Epoch 70/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 14190.4790 - _calculate_reconstruction_loss: 0.0140 - _calculate_kl_loss: 180.9168\n",
            "Epoch 71/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 14978.6140 - _calculate_reconstruction_loss: 0.0148 - _calculate_kl_loss: 195.6574\n",
            "Epoch 72/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 14244.2756 - _calculate_reconstruction_loss: 0.0140 - _calculate_kl_loss: 194.4071\n",
            "Epoch 73/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 13777.6927 - _calculate_reconstruction_loss: 0.0136 - _calculate_kl_loss: 184.5293\n",
            "Epoch 74/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 13467.6599 - _calculate_reconstruction_loss: 0.0133 - _calculate_kl_loss: 181.1062\n",
            "Epoch 75/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 13022.8341 - _calculate_reconstruction_loss: 0.0128 - _calculate_kl_loss: 174.6091\n",
            "Epoch 76/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 12959.8438 - _calculate_reconstruction_loss: 0.0128 - _calculate_kl_loss: 175.0741\n",
            "Epoch 77/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 12860.6759 - _calculate_reconstruction_loss: 0.0127 - _calculate_kl_loss: 173.1635\n",
            "Epoch 78/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 12808.6168 - _calculate_reconstruction_loss: 0.0126 - _calculate_kl_loss: 171.1225\n",
            "Epoch 79/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 12442.5862 - _calculate_reconstruction_loss: 0.0123 - _calculate_kl_loss: 169.0913\n",
            "Epoch 80/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 12227.2561 - _calculate_reconstruction_loss: 0.0121 - _calculate_kl_loss: 171.5696\n",
            "Epoch 81/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 12496.9698 - _calculate_reconstruction_loss: 0.0123 - _calculate_kl_loss: 166.7798\n",
            "Epoch 82/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 12315.8805 - _calculate_reconstruction_loss: 0.0122 - _calculate_kl_loss: 162.5863\n",
            "Epoch 83/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 12326.6466 - _calculate_reconstruction_loss: 0.0122 - _calculate_kl_loss: 156.1076\n",
            "Epoch 84/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 12126.0644 - _calculate_reconstruction_loss: 0.0120 - _calculate_kl_loss: 156.1645\n",
            "Epoch 85/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 11808.3446 - _calculate_reconstruction_loss: 0.0116 - _calculate_kl_loss: 158.4671\n",
            "Epoch 86/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 11733.8622 - _calculate_reconstruction_loss: 0.0116 - _calculate_kl_loss: 154.7891\n",
            "Epoch 87/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 11423.1617 - _calculate_reconstruction_loss: 0.0113 - _calculate_kl_loss: 152.7479\n",
            "Epoch 88/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 11429.6058 - _calculate_reconstruction_loss: 0.0113 - _calculate_kl_loss: 153.1380\n",
            "Epoch 89/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 11273.3451 - _calculate_reconstruction_loss: 0.0111 - _calculate_kl_loss: 150.5679\n",
            "Epoch 90/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 11227.8379 - _calculate_reconstruction_loss: 0.0111 - _calculate_kl_loss: 148.1814\n",
            "Epoch 91/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 10935.6766 - _calculate_reconstruction_loss: 0.0108 - _calculate_kl_loss: 148.6328\n",
            "Epoch 92/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 10916.4971 - _calculate_reconstruction_loss: 0.0108 - _calculate_kl_loss: 146.1670\n",
            "Epoch 93/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 10760.7660 - _calculate_reconstruction_loss: 0.0106 - _calculate_kl_loss: 141.5755\n",
            "Epoch 94/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 10641.7479 - _calculate_reconstruction_loss: 0.0105 - _calculate_kl_loss: 139.7737\n",
            "Epoch 95/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 10671.1429 - _calculate_reconstruction_loss: 0.0105 - _calculate_kl_loss: 138.1548\n",
            "Epoch 96/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 10637.1646 - _calculate_reconstruction_loss: 0.0105 - _calculate_kl_loss: 137.4089\n",
            "Epoch 97/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 10532.2363 - _calculate_reconstruction_loss: 0.0104 - _calculate_kl_loss: 139.8318\n",
            "Epoch 98/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 10291.0827 - _calculate_reconstruction_loss: 0.0102 - _calculate_kl_loss: 140.6325\n",
            "Epoch 99/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 10190.2526 - _calculate_reconstruction_loss: 0.0101 - _calculate_kl_loss: 138.6397\n",
            "Epoch 100/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 10157.8599 - _calculate_reconstruction_loss: 0.0100 - _calculate_kl_loss: 141.2991\n",
            "Epoch 101/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 10109.1404 - _calculate_reconstruction_loss: 0.0100 - _calculate_kl_loss: 143.6985\n",
            "Epoch 102/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 10065.2296 - _calculate_reconstruction_loss: 0.0099 - _calculate_kl_loss: 145.8520\n",
            "Epoch 103/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 9749.4111 - _calculate_reconstruction_loss: 0.0096 - _calculate_kl_loss: 142.2095\n",
            "Epoch 104/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 10005.1697 - _calculate_reconstruction_loss: 0.0099 - _calculate_kl_loss: 143.7910\n",
            "Epoch 105/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 9855.5515 - _calculate_reconstruction_loss: 0.0097 - _calculate_kl_loss: 143.6602\n",
            "Epoch 106/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 9616.6046 - _calculate_reconstruction_loss: 0.0095 - _calculate_kl_loss: 139.1387\n",
            "Epoch 107/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 9548.3171 - _calculate_reconstruction_loss: 0.0094 - _calculate_kl_loss: 140.1662\n",
            "Epoch 108/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 9382.6505 - _calculate_reconstruction_loss: 0.0092 - _calculate_kl_loss: 141.6259\n",
            "Epoch 109/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 9309.2862 - _calculate_reconstruction_loss: 0.0092 - _calculate_kl_loss: 136.0513\n",
            "Epoch 110/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 9205.7548 - _calculate_reconstruction_loss: 0.0091 - _calculate_kl_loss: 134.5796\n",
            "Epoch 111/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 9186.0259 - _calculate_reconstruction_loss: 0.0090 - _calculate_kl_loss: 138.6136\n",
            "Epoch 112/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 9054.0300 - _calculate_reconstruction_loss: 0.0089 - _calculate_kl_loss: 133.7418\n",
            "Epoch 113/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 8980.8852 - _calculate_reconstruction_loss: 0.0088 - _calculate_kl_loss: 132.7863\n",
            "Epoch 114/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 8985.3366 - _calculate_reconstruction_loss: 0.0089 - _calculate_kl_loss: 132.9131\n",
            "Epoch 115/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 8690.6798 - _calculate_reconstruction_loss: 0.0086 - _calculate_kl_loss: 129.2398\n",
            "Epoch 116/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 9004.0365 - _calculate_reconstruction_loss: 0.0089 - _calculate_kl_loss: 132.8959\n",
            "Epoch 117/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 8950.5899 - _calculate_reconstruction_loss: 0.0088 - _calculate_kl_loss: 131.7737\n",
            "Epoch 118/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 8625.7516 - _calculate_reconstruction_loss: 0.0085 - _calculate_kl_loss: 129.6903\n",
            "Epoch 119/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 8891.2527 - _calculate_reconstruction_loss: 0.0088 - _calculate_kl_loss: 134.2808\n",
            "Epoch 120/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 8860.8894 - _calculate_reconstruction_loss: 0.0087 - _calculate_kl_loss: 138.3550\n",
            "Epoch 121/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 8348.4578 - _calculate_reconstruction_loss: 0.0082 - _calculate_kl_loss: 137.8844\n",
            "Epoch 122/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 8252.9997 - _calculate_reconstruction_loss: 0.0081 - _calculate_kl_loss: 133.5885\n",
            "Epoch 123/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 8222.2881 - _calculate_reconstruction_loss: 0.0081 - _calculate_kl_loss: 129.5753\n",
            "Epoch 124/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 8416.8541 - _calculate_reconstruction_loss: 0.0083 - _calculate_kl_loss: 130.1917\n",
            "Epoch 125/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 8461.3639 - _calculate_reconstruction_loss: 0.0083 - _calculate_kl_loss: 130.6801\n",
            "Epoch 126/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 8144.0594 - _calculate_reconstruction_loss: 0.0080 - _calculate_kl_loss: 132.6439\n",
            "Epoch 127/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 7948.0999 - _calculate_reconstruction_loss: 0.0078 - _calculate_kl_loss: 126.7555\n",
            "Epoch 128/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 8130.2067 - _calculate_reconstruction_loss: 0.0080 - _calculate_kl_loss: 126.0596\n",
            "Epoch 129/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 7863.6377 - _calculate_reconstruction_loss: 0.0077 - _calculate_kl_loss: 129.6295\n",
            "Epoch 130/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 7953.6150 - _calculate_reconstruction_loss: 0.0078 - _calculate_kl_loss: 128.9703\n",
            "Epoch 131/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 7908.8075 - _calculate_reconstruction_loss: 0.0078 - _calculate_kl_loss: 127.4354\n",
            "Epoch 132/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 7687.9759 - _calculate_reconstruction_loss: 0.0076 - _calculate_kl_loss: 125.6631\n",
            "Epoch 133/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 8625.7229 - _calculate_reconstruction_loss: 0.0085 - _calculate_kl_loss: 134.6967\n",
            "Epoch 134/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 7750.2437 - _calculate_reconstruction_loss: 0.0076 - _calculate_kl_loss: 136.8496\n",
            "Epoch 135/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 7483.8855 - _calculate_reconstruction_loss: 0.0074 - _calculate_kl_loss: 131.9385\n",
            "Epoch 136/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 7498.0247 - _calculate_reconstruction_loss: 0.0074 - _calculate_kl_loss: 129.4487\n",
            "Epoch 137/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 7423.6801 - _calculate_reconstruction_loss: 0.0073 - _calculate_kl_loss: 130.3067\n",
            "Epoch 138/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 7423.4323 - _calculate_reconstruction_loss: 0.0073 - _calculate_kl_loss: 132.9149\n",
            "Epoch 139/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 7261.5338 - _calculate_reconstruction_loss: 0.0071 - _calculate_kl_loss: 130.0599\n",
            "Epoch 140/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 7337.6844 - _calculate_reconstruction_loss: 0.0072 - _calculate_kl_loss: 126.6891\n",
            "Epoch 141/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 7247.6587 - _calculate_reconstruction_loss: 0.0071 - _calculate_kl_loss: 125.9286\n",
            "Epoch 142/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 7487.1537 - _calculate_reconstruction_loss: 0.0074 - _calculate_kl_loss: 124.7552\n",
            "Epoch 143/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 11025.4088 - _calculate_reconstruction_loss: 0.0109 - _calculate_kl_loss: 171.4138\n",
            "Epoch 144/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 8326.7528 - _calculate_reconstruction_loss: 0.0081 - _calculate_kl_loss: 180.3826\n",
            "Epoch 145/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 7600.5842 - _calculate_reconstruction_loss: 0.0074 - _calculate_kl_loss: 165.8851\n",
            "Epoch 146/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 7330.5792 - _calculate_reconstruction_loss: 0.0072 - _calculate_kl_loss: 156.9769\n",
            "Epoch 147/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 7132.0923 - _calculate_reconstruction_loss: 0.0070 - _calculate_kl_loss: 150.0994\n",
            "Epoch 148/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 7248.2887 - _calculate_reconstruction_loss: 0.0071 - _calculate_kl_loss: 145.2157\n",
            "Epoch 149/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 7079.2484 - _calculate_reconstruction_loss: 0.0069 - _calculate_kl_loss: 140.6680\n",
            "Epoch 150/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 7182.7508 - _calculate_reconstruction_loss: 0.0070 - _calculate_kl_loss: 137.2612\n",
            "Epoch 151/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 7035.6440 - _calculate_reconstruction_loss: 0.0069 - _calculate_kl_loss: 137.6468\n",
            "Epoch 152/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6940.3853 - _calculate_reconstruction_loss: 0.0068 - _calculate_kl_loss: 134.6168\n",
            "Epoch 153/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 7025.6634 - _calculate_reconstruction_loss: 0.0069 - _calculate_kl_loss: 131.2456\n",
            "Epoch 154/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6893.0605 - _calculate_reconstruction_loss: 0.0068 - _calculate_kl_loss: 130.4424\n",
            "Epoch 155/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6982.1601 - _calculate_reconstruction_loss: 0.0069 - _calculate_kl_loss: 130.9533\n",
            "Epoch 156/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6830.3313 - _calculate_reconstruction_loss: 0.0067 - _calculate_kl_loss: 129.4699\n",
            "Epoch 157/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6825.8142 - _calculate_reconstruction_loss: 0.0067 - _calculate_kl_loss: 125.8059\n",
            "Epoch 158/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6852.5106 - _calculate_reconstruction_loss: 0.0067 - _calculate_kl_loss: 119.6918\n",
            "Epoch 159/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6612.4985 - _calculate_reconstruction_loss: 0.0065 - _calculate_kl_loss: 122.3226\n",
            "Epoch 160/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6736.5792 - _calculate_reconstruction_loss: 0.0066 - _calculate_kl_loss: 124.3090\n",
            "Epoch 161/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6588.4194 - _calculate_reconstruction_loss: 0.0065 - _calculate_kl_loss: 124.4666\n",
            "Epoch 162/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6846.4677 - _calculate_reconstruction_loss: 0.0067 - _calculate_kl_loss: 127.2360\n",
            "Epoch 163/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 8041.7698 - _calculate_reconstruction_loss: 0.0079 - _calculate_kl_loss: 149.7973\n",
            "Epoch 164/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 7021.6662 - _calculate_reconstruction_loss: 0.0069 - _calculate_kl_loss: 149.8291\n",
            "Epoch 165/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6904.7749 - _calculate_reconstruction_loss: 0.0068 - _calculate_kl_loss: 143.3166\n",
            "Epoch 166/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6773.4225 - _calculate_reconstruction_loss: 0.0066 - _calculate_kl_loss: 138.1960\n",
            "Epoch 167/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6745.5674 - _calculate_reconstruction_loss: 0.0066 - _calculate_kl_loss: 134.2216\n",
            "Epoch 168/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6476.2458 - _calculate_reconstruction_loss: 0.0063 - _calculate_kl_loss: 129.9222\n",
            "Epoch 169/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6512.0857 - _calculate_reconstruction_loss: 0.0064 - _calculate_kl_loss: 131.2255\n",
            "Epoch 170/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6649.9239 - _calculate_reconstruction_loss: 0.0065 - _calculate_kl_loss: 138.3204\n",
            "Epoch 171/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6484.3177 - _calculate_reconstruction_loss: 0.0063 - _calculate_kl_loss: 134.5367\n",
            "Epoch 172/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6377.9066 - _calculate_reconstruction_loss: 0.0062 - _calculate_kl_loss: 131.2913\n",
            "Epoch 173/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6463.4768 - _calculate_reconstruction_loss: 0.0063 - _calculate_kl_loss: 125.8188\n",
            "Epoch 174/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6715.8235 - _calculate_reconstruction_loss: 0.0066 - _calculate_kl_loss: 125.4760\n",
            "Epoch 175/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 10321.2124 - _calculate_reconstruction_loss: 0.0102 - _calculate_kl_loss: 161.3597\n",
            "Epoch 176/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 7890.7994 - _calculate_reconstruction_loss: 0.0077 - _calculate_kl_loss: 175.0082\n",
            "Epoch 177/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 7069.6866 - _calculate_reconstruction_loss: 0.0069 - _calculate_kl_loss: 168.8712\n",
            "Epoch 178/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6729.1364 - _calculate_reconstruction_loss: 0.0066 - _calculate_kl_loss: 165.6463\n",
            "Epoch 179/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6583.1923 - _calculate_reconstruction_loss: 0.0064 - _calculate_kl_loss: 159.6669\n",
            "Epoch 180/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6539.3275 - _calculate_reconstruction_loss: 0.0064 - _calculate_kl_loss: 156.2107\n",
            "Epoch 181/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6393.3378 - _calculate_reconstruction_loss: 0.0062 - _calculate_kl_loss: 151.5508\n",
            "Epoch 182/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6477.3782 - _calculate_reconstruction_loss: 0.0063 - _calculate_kl_loss: 148.5699\n",
            "Epoch 183/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6396.8622 - _calculate_reconstruction_loss: 0.0062 - _calculate_kl_loss: 148.1532\n",
            "Epoch 184/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6474.1573 - _calculate_reconstruction_loss: 0.0063 - _calculate_kl_loss: 148.2026\n",
            "Epoch 185/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6631.2690 - _calculate_reconstruction_loss: 0.0065 - _calculate_kl_loss: 148.7071\n",
            "Epoch 186/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6419.5797 - _calculate_reconstruction_loss: 0.0063 - _calculate_kl_loss: 144.9387\n",
            "Epoch 187/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6215.8929 - _calculate_reconstruction_loss: 0.0061 - _calculate_kl_loss: 141.1333\n",
            "Epoch 188/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6136.1760 - _calculate_reconstruction_loss: 0.0060 - _calculate_kl_loss: 141.2749\n",
            "Epoch 189/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6171.5583 - _calculate_reconstruction_loss: 0.0060 - _calculate_kl_loss: 139.0247\n",
            "Epoch 190/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6038.3992 - _calculate_reconstruction_loss: 0.0059 - _calculate_kl_loss: 136.4874\n",
            "Epoch 191/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6298.8295 - _calculate_reconstruction_loss: 0.0062 - _calculate_kl_loss: 133.1587\n",
            "Epoch 192/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6221.8860 - _calculate_reconstruction_loss: 0.0061 - _calculate_kl_loss: 133.2735\n",
            "Epoch 193/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6174.7455 - _calculate_reconstruction_loss: 0.0060 - _calculate_kl_loss: 131.1193\n",
            "Epoch 194/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6113.0041 - _calculate_reconstruction_loss: 0.0060 - _calculate_kl_loss: 126.4559\n",
            "Epoch 195/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6160.4416 - _calculate_reconstruction_loss: 0.0060 - _calculate_kl_loss: 129.4531\n",
            "Epoch 196/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6019.8679 - _calculate_reconstruction_loss: 0.0059 - _calculate_kl_loss: 129.7881\n",
            "Epoch 197/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6336.4430 - _calculate_reconstruction_loss: 0.0062 - _calculate_kl_loss: 130.2733\n",
            "Epoch 198/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6075.7777 - _calculate_reconstruction_loss: 0.0059 - _calculate_kl_loss: 129.7109\n",
            "Epoch 199/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6051.7252 - _calculate_reconstruction_loss: 0.0059 - _calculate_kl_loss: 126.2855\n",
            "Epoch 200/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6011.2501 - _calculate_reconstruction_loss: 0.0059 - _calculate_kl_loss: 127.0485\n",
            "Epoch 201/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6184.6451 - _calculate_reconstruction_loss: 0.0060 - _calculate_kl_loss: 136.5878\n",
            "Epoch 202/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6286.1985 - _calculate_reconstruction_loss: 0.0062 - _calculate_kl_loss: 135.4813\n",
            "Epoch 203/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6056.9452 - _calculate_reconstruction_loss: 0.0059 - _calculate_kl_loss: 136.9041\n",
            "Epoch 204/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6204.5782 - _calculate_reconstruction_loss: 0.0061 - _calculate_kl_loss: 140.3004\n",
            "Epoch 205/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6234.5234 - _calculate_reconstruction_loss: 0.0061 - _calculate_kl_loss: 133.4062\n",
            "Epoch 206/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5841.8150 - _calculate_reconstruction_loss: 0.0057 - _calculate_kl_loss: 131.6034\n",
            "Epoch 207/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5866.5474 - _calculate_reconstruction_loss: 0.0057 - _calculate_kl_loss: 128.8955\n",
            "Epoch 208/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5815.3226 - _calculate_reconstruction_loss: 0.0057 - _calculate_kl_loss: 130.1970\n",
            "Epoch 209/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5759.8845 - _calculate_reconstruction_loss: 0.0056 - _calculate_kl_loss: 126.2149\n",
            "Epoch 210/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5719.1709 - _calculate_reconstruction_loss: 0.0056 - _calculate_kl_loss: 124.8144\n",
            "Epoch 211/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5980.9100 - _calculate_reconstruction_loss: 0.0059 - _calculate_kl_loss: 124.5415\n",
            "Epoch 212/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5866.6310 - _calculate_reconstruction_loss: 0.0057 - _calculate_kl_loss: 122.7208\n",
            "Epoch 213/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6126.9677 - _calculate_reconstruction_loss: 0.0060 - _calculate_kl_loss: 120.2868\n",
            "Epoch 214/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5756.9512 - _calculate_reconstruction_loss: 0.0056 - _calculate_kl_loss: 121.2622\n",
            "Epoch 215/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5636.2028 - _calculate_reconstruction_loss: 0.0055 - _calculate_kl_loss: 120.2835\n",
            "Epoch 216/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6166.8343 - _calculate_reconstruction_loss: 0.0060 - _calculate_kl_loss: 126.4052\n",
            "Epoch 217/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5835.1207 - _calculate_reconstruction_loss: 0.0057 - _calculate_kl_loss: 123.2226\n",
            "Epoch 218/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5902.0073 - _calculate_reconstruction_loss: 0.0058 - _calculate_kl_loss: 120.4649\n",
            "Epoch 219/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6867.5991 - _calculate_reconstruction_loss: 0.0067 - _calculate_kl_loss: 129.0650\n",
            "Epoch 220/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6201.8985 - _calculate_reconstruction_loss: 0.0061 - _calculate_kl_loss: 127.4563\n",
            "Epoch 221/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 7893.3804 - _calculate_reconstruction_loss: 0.0077 - _calculate_kl_loss: 164.8101\n",
            "Epoch 222/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6534.1382 - _calculate_reconstruction_loss: 0.0064 - _calculate_kl_loss: 167.4932\n",
            "Epoch 223/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6093.3169 - _calculate_reconstruction_loss: 0.0059 - _calculate_kl_loss: 159.1093\n",
            "Epoch 224/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5922.9023 - _calculate_reconstruction_loss: 0.0058 - _calculate_kl_loss: 154.2747\n",
            "Epoch 225/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5832.9407 - _calculate_reconstruction_loss: 0.0057 - _calculate_kl_loss: 147.7812\n",
            "Epoch 226/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6019.0286 - _calculate_reconstruction_loss: 0.0059 - _calculate_kl_loss: 140.0926\n",
            "Epoch 227/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5674.0409 - _calculate_reconstruction_loss: 0.0055 - _calculate_kl_loss: 139.1799\n",
            "Epoch 228/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5721.3370 - _calculate_reconstruction_loss: 0.0056 - _calculate_kl_loss: 136.1398\n",
            "Epoch 229/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5771.5165 - _calculate_reconstruction_loss: 0.0056 - _calculate_kl_loss: 131.1317\n",
            "Epoch 230/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5616.6015 - _calculate_reconstruction_loss: 0.0055 - _calculate_kl_loss: 128.5966\n",
            "Epoch 231/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5520.2917 - _calculate_reconstruction_loss: 0.0054 - _calculate_kl_loss: 125.6367\n",
            "Epoch 232/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5542.5694 - _calculate_reconstruction_loss: 0.0054 - _calculate_kl_loss: 126.4197\n",
            "Epoch 233/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5776.4001 - _calculate_reconstruction_loss: 0.0057 - _calculate_kl_loss: 123.0166\n",
            "Epoch 234/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5694.6412 - _calculate_reconstruction_loss: 0.0056 - _calculate_kl_loss: 122.7225\n",
            "Epoch 235/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6038.4223 - _calculate_reconstruction_loss: 0.0059 - _calculate_kl_loss: 119.5801\n",
            "Epoch 236/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5671.8276 - _calculate_reconstruction_loss: 0.0055 - _calculate_kl_loss: 122.9226\n",
            "Epoch 237/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5651.2778 - _calculate_reconstruction_loss: 0.0055 - _calculate_kl_loss: 122.8174\n",
            "Epoch 238/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5583.5510 - _calculate_reconstruction_loss: 0.0055 - _calculate_kl_loss: 122.7044\n",
            "Epoch 239/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5491.5189 - _calculate_reconstruction_loss: 0.0054 - _calculate_kl_loss: 121.8339\n",
            "Epoch 240/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5653.7639 - _calculate_reconstruction_loss: 0.0055 - _calculate_kl_loss: 119.5475\n",
            "Epoch 241/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 7656.2610 - _calculate_reconstruction_loss: 0.0075 - _calculate_kl_loss: 141.3376\n",
            "Epoch 242/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6036.6530 - _calculate_reconstruction_loss: 0.0059 - _calculate_kl_loss: 149.7023\n",
            "Epoch 243/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5663.8635 - _calculate_reconstruction_loss: 0.0055 - _calculate_kl_loss: 148.4852\n",
            "Epoch 244/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5615.1649 - _calculate_reconstruction_loss: 0.0055 - _calculate_kl_loss: 145.2331\n",
            "Epoch 245/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5645.3061 - _calculate_reconstruction_loss: 0.0055 - _calculate_kl_loss: 139.9447\n",
            "Epoch 246/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5483.1141 - _calculate_reconstruction_loss: 0.0053 - _calculate_kl_loss: 135.3563\n",
            "Epoch 247/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5518.4984 - _calculate_reconstruction_loss: 0.0054 - _calculate_kl_loss: 133.3089\n",
            "Epoch 248/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5465.5318 - _calculate_reconstruction_loss: 0.0053 - _calculate_kl_loss: 130.9687\n",
            "Epoch 249/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5444.2309 - _calculate_reconstruction_loss: 0.0053 - _calculate_kl_loss: 128.6954\n",
            "Epoch 250/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5563.2445 - _calculate_reconstruction_loss: 0.0054 - _calculate_kl_loss: 126.8634\n",
            "Epoch 251/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5404.9366 - _calculate_reconstruction_loss: 0.0053 - _calculate_kl_loss: 126.3955\n",
            "Epoch 252/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5357.7215 - _calculate_reconstruction_loss: 0.0052 - _calculate_kl_loss: 127.6139\n",
            "Epoch 253/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5338.2011 - _calculate_reconstruction_loss: 0.0052 - _calculate_kl_loss: 126.2248\n",
            "Epoch 254/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5268.5069 - _calculate_reconstruction_loss: 0.0051 - _calculate_kl_loss: 125.3090\n",
            "Epoch 255/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5341.9311 - _calculate_reconstruction_loss: 0.0052 - _calculate_kl_loss: 122.5062\n",
            "Epoch 256/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5395.0786 - _calculate_reconstruction_loss: 0.0053 - _calculate_kl_loss: 125.6136\n",
            "Epoch 257/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5254.2394 - _calculate_reconstruction_loss: 0.0051 - _calculate_kl_loss: 125.8109\n",
            "Epoch 258/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5328.4538 - _calculate_reconstruction_loss: 0.0052 - _calculate_kl_loss: 121.7123\n",
            "Epoch 259/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5283.4502 - _calculate_reconstruction_loss: 0.0052 - _calculate_kl_loss: 118.3006\n",
            "Epoch 260/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5289.2731 - _calculate_reconstruction_loss: 0.0052 - _calculate_kl_loss: 122.6590\n",
            "Epoch 261/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5210.1853 - _calculate_reconstruction_loss: 0.0051 - _calculate_kl_loss: 118.5398\n",
            "Epoch 262/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5312.0617 - _calculate_reconstruction_loss: 0.0052 - _calculate_kl_loss: 117.9504\n",
            "Epoch 263/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5329.4669 - _calculate_reconstruction_loss: 0.0052 - _calculate_kl_loss: 116.5055\n",
            "Epoch 264/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5253.0611 - _calculate_reconstruction_loss: 0.0051 - _calculate_kl_loss: 115.0267\n",
            "Epoch 265/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5242.0448 - _calculate_reconstruction_loss: 0.0051 - _calculate_kl_loss: 112.0980\n",
            "Epoch 266/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5234.6481 - _calculate_reconstruction_loss: 0.0051 - _calculate_kl_loss: 112.3564\n",
            "Epoch 267/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5199.4946 - _calculate_reconstruction_loss: 0.0051 - _calculate_kl_loss: 111.5115\n",
            "Epoch 268/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5232.5797 - _calculate_reconstruction_loss: 0.0051 - _calculate_kl_loss: 113.0156\n",
            "Epoch 269/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5279.7085 - _calculate_reconstruction_loss: 0.0052 - _calculate_kl_loss: 111.4468\n",
            "Epoch 270/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5155.9911 - _calculate_reconstruction_loss: 0.0050 - _calculate_kl_loss: 112.8062\n",
            "Epoch 271/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5082.4522 - _calculate_reconstruction_loss: 0.0050 - _calculate_kl_loss: 111.0089\n",
            "Epoch 272/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5238.2870 - _calculate_reconstruction_loss: 0.0051 - _calculate_kl_loss: 110.3260\n",
            "Epoch 273/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6579.6864 - _calculate_reconstruction_loss: 0.0064 - _calculate_kl_loss: 132.1250\n",
            "Epoch 274/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5758.1982 - _calculate_reconstruction_loss: 0.0056 - _calculate_kl_loss: 131.1924\n",
            "Epoch 275/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5464.0931 - _calculate_reconstruction_loss: 0.0053 - _calculate_kl_loss: 127.1688\n",
            "Epoch 276/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5358.1492 - _calculate_reconstruction_loss: 0.0052 - _calculate_kl_loss: 124.0243\n",
            "Epoch 277/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5143.6066 - _calculate_reconstruction_loss: 0.0050 - _calculate_kl_loss: 121.8598\n",
            "Epoch 278/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5204.7036 - _calculate_reconstruction_loss: 0.0051 - _calculate_kl_loss: 118.6848\n",
            "Epoch 279/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5312.1914 - _calculate_reconstruction_loss: 0.0052 - _calculate_kl_loss: 112.4924\n",
            "Epoch 280/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5183.7947 - _calculate_reconstruction_loss: 0.0051 - _calculate_kl_loss: 109.2408\n",
            "Epoch 281/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5068.6849 - _calculate_reconstruction_loss: 0.0050 - _calculate_kl_loss: 110.7189\n",
            "Epoch 282/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5178.1352 - _calculate_reconstruction_loss: 0.0051 - _calculate_kl_loss: 110.0784\n",
            "Epoch 283/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5073.6709 - _calculate_reconstruction_loss: 0.0050 - _calculate_kl_loss: 109.0500\n",
            "Epoch 284/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5132.9769 - _calculate_reconstruction_loss: 0.0050 - _calculate_kl_loss: 108.1278\n",
            "Epoch 285/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5139.4585 - _calculate_reconstruction_loss: 0.0050 - _calculate_kl_loss: 106.7026\n",
            "Epoch 286/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5135.2679 - _calculate_reconstruction_loss: 0.0050 - _calculate_kl_loss: 111.4132\n",
            "Epoch 287/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5082.3724 - _calculate_reconstruction_loss: 0.0050 - _calculate_kl_loss: 108.6647\n",
            "Epoch 288/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5106.3478 - _calculate_reconstruction_loss: 0.0050 - _calculate_kl_loss: 108.2885\n",
            "Epoch 289/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5149.7120 - _calculate_reconstruction_loss: 0.0050 - _calculate_kl_loss: 109.7726\n",
            "Epoch 290/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5070.9311 - _calculate_reconstruction_loss: 0.0050 - _calculate_kl_loss: 108.2257\n",
            "Epoch 291/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5159.5358 - _calculate_reconstruction_loss: 0.0051 - _calculate_kl_loss: 105.7698\n",
            "Epoch 292/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4991.5339 - _calculate_reconstruction_loss: 0.0049 - _calculate_kl_loss: 105.7234\n",
            "Epoch 293/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5042.8317 - _calculate_reconstruction_loss: 0.0049 - _calculate_kl_loss: 103.9850\n",
            "Epoch 294/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4997.8219 - _calculate_reconstruction_loss: 0.0049 - _calculate_kl_loss: 104.8135\n",
            "Epoch 295/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4944.1951 - _calculate_reconstruction_loss: 0.0048 - _calculate_kl_loss: 105.1654\n",
            "Epoch 296/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5017.8479 - _calculate_reconstruction_loss: 0.0049 - _calculate_kl_loss: 103.8236\n",
            "Epoch 297/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4999.6508 - _calculate_reconstruction_loss: 0.0049 - _calculate_kl_loss: 101.6171\n",
            "Epoch 298/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5249.3860 - _calculate_reconstruction_loss: 0.0051 - _calculate_kl_loss: 103.6598\n",
            "Epoch 299/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5131.9711 - _calculate_reconstruction_loss: 0.0050 - _calculate_kl_loss: 99.4030\n",
            "Epoch 300/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5002.9658 - _calculate_reconstruction_loss: 0.0049 - _calculate_kl_loss: 101.7603\n",
            "Epoch 301/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5021.0009 - _calculate_reconstruction_loss: 0.0049 - _calculate_kl_loss: 102.4873\n",
            "Epoch 302/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5077.9365 - _calculate_reconstruction_loss: 0.0050 - _calculate_kl_loss: 101.9683\n",
            "Epoch 303/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4915.0222 - _calculate_reconstruction_loss: 0.0048 - _calculate_kl_loss: 101.1361\n",
            "Epoch 304/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4945.0611 - _calculate_reconstruction_loss: 0.0048 - _calculate_kl_loss: 98.7482\n",
            "Epoch 305/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4958.5232 - _calculate_reconstruction_loss: 0.0049 - _calculate_kl_loss: 97.3520\n",
            "Epoch 306/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4995.9685 - _calculate_reconstruction_loss: 0.0049 - _calculate_kl_loss: 99.2102\n",
            "Epoch 307/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4940.7929 - _calculate_reconstruction_loss: 0.0048 - _calculate_kl_loss: 100.1471\n",
            "Epoch 308/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4929.4845 - _calculate_reconstruction_loss: 0.0048 - _calculate_kl_loss: 98.6864\n",
            "Epoch 309/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5013.8149 - _calculate_reconstruction_loss: 0.0049 - _calculate_kl_loss: 97.6369\n",
            "Epoch 310/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4922.6417 - _calculate_reconstruction_loss: 0.0048 - _calculate_kl_loss: 98.2010\n",
            "Epoch 311/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4928.9868 - _calculate_reconstruction_loss: 0.0048 - _calculate_kl_loss: 98.9439\n",
            "Epoch 312/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4865.6498 - _calculate_reconstruction_loss: 0.0048 - _calculate_kl_loss: 100.5988\n",
            "Epoch 313/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4921.6337 - _calculate_reconstruction_loss: 0.0048 - _calculate_kl_loss: 98.4723\n",
            "Epoch 314/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4951.6388 - _calculate_reconstruction_loss: 0.0049 - _calculate_kl_loss: 96.4342\n",
            "Epoch 315/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5046.1996 - _calculate_reconstruction_loss: 0.0049 - _calculate_kl_loss: 98.0561\n",
            "Epoch 316/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5423.0437 - _calculate_reconstruction_loss: 0.0053 - _calculate_kl_loss: 99.4108\n",
            "Epoch 317/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4975.4684 - _calculate_reconstruction_loss: 0.0049 - _calculate_kl_loss: 103.5195\n",
            "Epoch 318/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4902.3909 - _calculate_reconstruction_loss: 0.0048 - _calculate_kl_loss: 105.4451\n",
            "Epoch 319/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4930.9379 - _calculate_reconstruction_loss: 0.0048 - _calculate_kl_loss: 104.5865\n",
            "Epoch 320/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4870.0604 - _calculate_reconstruction_loss: 0.0048 - _calculate_kl_loss: 103.2463\n",
            "Epoch 321/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4754.8537 - _calculate_reconstruction_loss: 0.0047 - _calculate_kl_loss: 101.7693\n",
            "Epoch 322/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4987.7063 - _calculate_reconstruction_loss: 0.0049 - _calculate_kl_loss: 99.8359\n",
            "Epoch 323/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4802.4869 - _calculate_reconstruction_loss: 0.0047 - _calculate_kl_loss: 99.5891\n",
            "Epoch 324/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5073.8973 - _calculate_reconstruction_loss: 0.0050 - _calculate_kl_loss: 99.0803\n",
            "Epoch 325/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5506.6291 - _calculate_reconstruction_loss: 0.0054 - _calculate_kl_loss: 113.5620\n",
            "Epoch 326/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5079.5566 - _calculate_reconstruction_loss: 0.0050 - _calculate_kl_loss: 111.1952\n",
            "Epoch 327/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5014.2899 - _calculate_reconstruction_loss: 0.0049 - _calculate_kl_loss: 108.4414\n",
            "Epoch 328/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4861.0886 - _calculate_reconstruction_loss: 0.0048 - _calculate_kl_loss: 103.7333\n",
            "Epoch 329/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5048.0521 - _calculate_reconstruction_loss: 0.0049 - _calculate_kl_loss: 101.0286\n",
            "Epoch 330/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 8467.8326 - _calculate_reconstruction_loss: 0.0083 - _calculate_kl_loss: 158.9634\n",
            "Epoch 331/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6450.9103 - _calculate_reconstruction_loss: 0.0063 - _calculate_kl_loss: 171.8685\n",
            "Epoch 332/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5488.8835 - _calculate_reconstruction_loss: 0.0053 - _calculate_kl_loss: 156.6185\n",
            "Epoch 333/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5219.1678 - _calculate_reconstruction_loss: 0.0051 - _calculate_kl_loss: 148.0954\n",
            "Epoch 334/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5196.2971 - _calculate_reconstruction_loss: 0.0051 - _calculate_kl_loss: 142.9050\n",
            "Epoch 335/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5174.8675 - _calculate_reconstruction_loss: 0.0050 - _calculate_kl_loss: 139.2472\n",
            "Epoch 336/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4963.0164 - _calculate_reconstruction_loss: 0.0048 - _calculate_kl_loss: 138.0455\n",
            "Epoch 337/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5115.7101 - _calculate_reconstruction_loss: 0.0050 - _calculate_kl_loss: 131.7649\n",
            "Epoch 338/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4868.7614 - _calculate_reconstruction_loss: 0.0047 - _calculate_kl_loss: 129.1121\n",
            "Epoch 339/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4917.8432 - _calculate_reconstruction_loss: 0.0048 - _calculate_kl_loss: 128.1967\n",
            "Epoch 340/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4833.6249 - _calculate_reconstruction_loss: 0.0047 - _calculate_kl_loss: 128.1576\n",
            "Epoch 341/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4831.4807 - _calculate_reconstruction_loss: 0.0047 - _calculate_kl_loss: 125.4808\n",
            "Epoch 342/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4792.5669 - _calculate_reconstruction_loss: 0.0047 - _calculate_kl_loss: 122.3425\n",
            "Epoch 343/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4882.0150 - _calculate_reconstruction_loss: 0.0048 - _calculate_kl_loss: 120.4072\n",
            "Epoch 344/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4807.6918 - _calculate_reconstruction_loss: 0.0047 - _calculate_kl_loss: 121.7674\n",
            "Epoch 345/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4928.1335 - _calculate_reconstruction_loss: 0.0048 - _calculate_kl_loss: 118.7099\n",
            "Epoch 346/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4973.4183 - _calculate_reconstruction_loss: 0.0049 - _calculate_kl_loss: 116.2785\n",
            "Epoch 347/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4838.2985 - _calculate_reconstruction_loss: 0.0047 - _calculate_kl_loss: 110.4455\n",
            "Epoch 348/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4865.3622 - _calculate_reconstruction_loss: 0.0048 - _calculate_kl_loss: 109.7836\n",
            "Epoch 349/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4772.0550 - _calculate_reconstruction_loss: 0.0047 - _calculate_kl_loss: 115.4880\n",
            "Epoch 350/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4830.7784 - _calculate_reconstruction_loss: 0.0047 - _calculate_kl_loss: 115.1490\n",
            "Epoch 351/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4917.3870 - _calculate_reconstruction_loss: 0.0048 - _calculate_kl_loss: 111.1302\n",
            "Epoch 352/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4866.6573 - _calculate_reconstruction_loss: 0.0048 - _calculate_kl_loss: 108.8363\n",
            "Epoch 353/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4751.6703 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 111.7648\n",
            "Epoch 354/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4745.2061 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 110.5887\n",
            "Epoch 355/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4743.0599 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 109.2936\n",
            "Epoch 356/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4812.5986 - _calculate_reconstruction_loss: 0.0047 - _calculate_kl_loss: 108.5827\n",
            "Epoch 357/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4823.2812 - _calculate_reconstruction_loss: 0.0047 - _calculate_kl_loss: 107.9634\n",
            "Epoch 358/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4705.6261 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 105.7596\n",
            "Epoch 359/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4614.6401 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 107.7114\n",
            "Epoch 360/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4727.1809 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 106.1262\n",
            "Epoch 361/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4673.0738 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 105.3115\n",
            "Epoch 362/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4739.7909 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 102.7694\n",
            "Epoch 363/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4654.9276 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 102.6723\n",
            "Epoch 364/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4685.7731 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 101.3594\n",
            "Epoch 365/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4794.1859 - _calculate_reconstruction_loss: 0.0047 - _calculate_kl_loss: 100.7546\n",
            "Epoch 366/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4605.5664 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 99.8727\n",
            "Epoch 367/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4634.6200 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 101.7985\n",
            "Epoch 368/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4644.8636 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 100.7782\n",
            "Epoch 369/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4685.7225 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 101.3341\n",
            "Epoch 370/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4678.9050 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 101.7046\n",
            "Epoch 371/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4607.4311 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 99.1954\n",
            "Epoch 372/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4656.6368 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 99.2316\n",
            "Epoch 373/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4668.8818 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 100.0748\n",
            "Epoch 374/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4554.7878 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 97.1945\n",
            "Epoch 375/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4627.9382 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 94.1158\n",
            "Epoch 376/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4624.3588 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 94.0679\n",
            "Epoch 377/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4612.1895 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 93.9322\n",
            "Epoch 378/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4615.6603 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 95.9306\n",
            "Epoch 379/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4522.0301 - _calculate_reconstruction_loss: 0.0044 - _calculate_kl_loss: 96.3295\n",
            "Epoch 380/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4613.9862 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 96.0653\n",
            "Epoch 381/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5483.1924 - _calculate_reconstruction_loss: 0.0054 - _calculate_kl_loss: 109.4239\n",
            "Epoch 382/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5008.5735 - _calculate_reconstruction_loss: 0.0049 - _calculate_kl_loss: 109.1312\n",
            "Epoch 383/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4711.8570 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 109.2561\n",
            "Epoch 384/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4711.0280 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 108.1524\n",
            "Epoch 385/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4679.2098 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 108.1568\n",
            "Epoch 386/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4828.7696 - _calculate_reconstruction_loss: 0.0047 - _calculate_kl_loss: 110.4925\n",
            "Epoch 387/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4675.5049 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 108.0140\n",
            "Epoch 388/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4583.2859 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 106.6569\n",
            "Epoch 389/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4615.6309 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 104.5598\n",
            "Epoch 390/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4592.5627 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 104.0437\n",
            "Epoch 391/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4542.3927 - _calculate_reconstruction_loss: 0.0044 - _calculate_kl_loss: 99.9106\n",
            "Epoch 392/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4493.5886 - _calculate_reconstruction_loss: 0.0044 - _calculate_kl_loss: 99.2653\n",
            "Epoch 393/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4536.7064 - _calculate_reconstruction_loss: 0.0044 - _calculate_kl_loss: 98.8699\n",
            "Epoch 394/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4560.3954 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 98.8340\n",
            "Epoch 395/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4564.6172 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 97.4105\n",
            "Epoch 396/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4517.9085 - _calculate_reconstruction_loss: 0.0044 - _calculate_kl_loss: 95.6898\n",
            "Epoch 397/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4583.0676 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 94.5284\n",
            "Epoch 398/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4470.5954 - _calculate_reconstruction_loss: 0.0044 - _calculate_kl_loss: 95.2545\n",
            "Epoch 399/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4488.3796 - _calculate_reconstruction_loss: 0.0044 - _calculate_kl_loss: 93.3471\n",
            "Epoch 400/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4592.0261 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 93.5168\n",
            "Epoch 401/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4545.4230 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 93.6866\n",
            "Epoch 402/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4738.0753 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 92.7701\n",
            "Epoch 403/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4548.8055 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 91.5356\n",
            "Epoch 404/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4566.4266 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 91.7019\n",
            "Epoch 405/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4538.8859 - _calculate_reconstruction_loss: 0.0044 - _calculate_kl_loss: 93.2833\n",
            "Epoch 406/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4515.6113 - _calculate_reconstruction_loss: 0.0044 - _calculate_kl_loss: 94.8711\n",
            "Epoch 407/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4497.8575 - _calculate_reconstruction_loss: 0.0044 - _calculate_kl_loss: 95.8653\n",
            "Epoch 408/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4567.2639 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 93.7395\n",
            "Epoch 409/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4477.0148 - _calculate_reconstruction_loss: 0.0044 - _calculate_kl_loss: 92.2490\n",
            "Epoch 410/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4506.2820 - _calculate_reconstruction_loss: 0.0044 - _calculate_kl_loss: 92.3294\n",
            "Epoch 411/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4468.8716 - _calculate_reconstruction_loss: 0.0044 - _calculate_kl_loss: 92.0251\n",
            "Epoch 412/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4651.6067 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 90.0863\n",
            "Epoch 413/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4594.6061 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 91.2116\n",
            "Epoch 414/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4508.6848 - _calculate_reconstruction_loss: 0.0044 - _calculate_kl_loss: 95.9240\n",
            "Epoch 415/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4533.2199 - _calculate_reconstruction_loss: 0.0044 - _calculate_kl_loss: 94.3783\n",
            "Epoch 416/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4541.5268 - _calculate_reconstruction_loss: 0.0044 - _calculate_kl_loss: 92.5074\n",
            "Epoch 417/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4505.2096 - _calculate_reconstruction_loss: 0.0044 - _calculate_kl_loss: 90.6498\n",
            "Epoch 418/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4480.9945 - _calculate_reconstruction_loss: 0.0044 - _calculate_kl_loss: 90.0479\n",
            "Epoch 419/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4514.0658 - _calculate_reconstruction_loss: 0.0044 - _calculate_kl_loss: 92.2249\n",
            "Epoch 420/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4495.5649 - _calculate_reconstruction_loss: 0.0044 - _calculate_kl_loss: 91.3974\n",
            "Epoch 421/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4482.2228 - _calculate_reconstruction_loss: 0.0044 - _calculate_kl_loss: 88.1532\n",
            "Epoch 422/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4510.3594 - _calculate_reconstruction_loss: 0.0044 - _calculate_kl_loss: 88.6169\n",
            "Epoch 423/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4594.3764 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 87.8274\n",
            "Epoch 424/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4415.2383 - _calculate_reconstruction_loss: 0.0043 - _calculate_kl_loss: 87.7236\n",
            "Epoch 425/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4503.6858 - _calculate_reconstruction_loss: 0.0044 - _calculate_kl_loss: 88.7998\n",
            "Epoch 426/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4582.9192 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 92.8885\n",
            "Epoch 427/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4426.8774 - _calculate_reconstruction_loss: 0.0043 - _calculate_kl_loss: 92.2597\n",
            "Epoch 428/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4453.4348 - _calculate_reconstruction_loss: 0.0044 - _calculate_kl_loss: 90.9781\n",
            "Epoch 429/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4560.9155 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 88.7476\n",
            "Epoch 430/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4444.3460 - _calculate_reconstruction_loss: 0.0044 - _calculate_kl_loss: 86.8464\n",
            "Epoch 431/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4368.0720 - _calculate_reconstruction_loss: 0.0043 - _calculate_kl_loss: 87.0333\n",
            "Epoch 432/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4384.3080 - _calculate_reconstruction_loss: 0.0043 - _calculate_kl_loss: 87.3725\n",
            "Epoch 433/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4382.7302 - _calculate_reconstruction_loss: 0.0043 - _calculate_kl_loss: 88.0126\n",
            "Epoch 434/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4364.2688 - _calculate_reconstruction_loss: 0.0043 - _calculate_kl_loss: 87.9062\n",
            "Epoch 435/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4464.3557 - _calculate_reconstruction_loss: 0.0044 - _calculate_kl_loss: 87.5741\n",
            "Epoch 436/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4436.0205 - _calculate_reconstruction_loss: 0.0043 - _calculate_kl_loss: 90.3555\n",
            "Epoch 437/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4375.4213 - _calculate_reconstruction_loss: 0.0043 - _calculate_kl_loss: 90.0003\n",
            "Epoch 438/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4474.0841 - _calculate_reconstruction_loss: 0.0044 - _calculate_kl_loss: 88.9757\n",
            "Epoch 439/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4426.3168 - _calculate_reconstruction_loss: 0.0043 - _calculate_kl_loss: 89.5536\n",
            "Epoch 440/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4417.6233 - _calculate_reconstruction_loss: 0.0043 - _calculate_kl_loss: 88.0494\n",
            "Epoch 441/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4398.8094 - _calculate_reconstruction_loss: 0.0043 - _calculate_kl_loss: 88.4534\n",
            "Epoch 442/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4395.4812 - _calculate_reconstruction_loss: 0.0043 - _calculate_kl_loss: 88.5771\n",
            "Epoch 443/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4375.5296 - _calculate_reconstruction_loss: 0.0043 - _calculate_kl_loss: 86.5233\n",
            "Epoch 444/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4388.1659 - _calculate_reconstruction_loss: 0.0043 - _calculate_kl_loss: 85.4744\n",
            "Epoch 445/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4423.6384 - _calculate_reconstruction_loss: 0.0043 - _calculate_kl_loss: 84.4691\n",
            "Epoch 446/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4362.5839 - _calculate_reconstruction_loss: 0.0043 - _calculate_kl_loss: 85.0105\n",
            "Epoch 447/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4392.2227 - _calculate_reconstruction_loss: 0.0043 - _calculate_kl_loss: 83.9859\n",
            "Epoch 448/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4373.4335 - _calculate_reconstruction_loss: 0.0043 - _calculate_kl_loss: 86.0012\n",
            "Epoch 449/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4311.5290 - _calculate_reconstruction_loss: 0.0042 - _calculate_kl_loss: 85.6556\n",
            "Epoch 450/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4415.9933 - _calculate_reconstruction_loss: 0.0043 - _calculate_kl_loss: 83.4439\n",
            "Epoch 451/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4419.3919 - _calculate_reconstruction_loss: 0.0043 - _calculate_kl_loss: 84.5785\n",
            "Epoch 452/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4392.2569 - _calculate_reconstruction_loss: 0.0043 - _calculate_kl_loss: 85.9476\n",
            "Epoch 453/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4444.8581 - _calculate_reconstruction_loss: 0.0044 - _calculate_kl_loss: 85.9672\n",
            "Epoch 454/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4408.3862 - _calculate_reconstruction_loss: 0.0043 - _calculate_kl_loss: 85.7487\n",
            "Epoch 455/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4424.9091 - _calculate_reconstruction_loss: 0.0043 - _calculate_kl_loss: 86.3645\n",
            "Epoch 456/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4423.5663 - _calculate_reconstruction_loss: 0.0043 - _calculate_kl_loss: 86.2571\n",
            "Epoch 457/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4376.7387 - _calculate_reconstruction_loss: 0.0043 - _calculate_kl_loss: 86.4697\n",
            "Epoch 458/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4484.0451 - _calculate_reconstruction_loss: 0.0044 - _calculate_kl_loss: 84.6188\n",
            "Epoch 459/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4370.3951 - _calculate_reconstruction_loss: 0.0043 - _calculate_kl_loss: 86.6517\n",
            "Epoch 460/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4351.6625 - _calculate_reconstruction_loss: 0.0043 - _calculate_kl_loss: 85.8667\n",
            "Epoch 461/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4448.8103 - _calculate_reconstruction_loss: 0.0044 - _calculate_kl_loss: 85.1083\n",
            "Epoch 462/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5067.1119 - _calculate_reconstruction_loss: 0.0050 - _calculate_kl_loss: 88.1041\n",
            "Epoch 463/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4701.9530 - _calculate_reconstruction_loss: 0.0046 - _calculate_kl_loss: 92.5520\n",
            "Epoch 464/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4591.7709 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 93.0559\n",
            "Epoch 465/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4478.1665 - _calculate_reconstruction_loss: 0.0044 - _calculate_kl_loss: 91.1208\n",
            "Epoch 466/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4374.4651 - _calculate_reconstruction_loss: 0.0043 - _calculate_kl_loss: 89.7742\n",
            "Epoch 467/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4423.6943 - _calculate_reconstruction_loss: 0.0043 - _calculate_kl_loss: 87.2850\n",
            "Epoch 468/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4306.1828 - _calculate_reconstruction_loss: 0.0042 - _calculate_kl_loss: 84.9498\n",
            "Epoch 469/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4340.4169 - _calculate_reconstruction_loss: 0.0043 - _calculate_kl_loss: 87.6917\n",
            "Epoch 470/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4351.8854 - _calculate_reconstruction_loss: 0.0043 - _calculate_kl_loss: 86.3737\n",
            "Epoch 471/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4329.3525 - _calculate_reconstruction_loss: 0.0042 - _calculate_kl_loss: 85.6681\n",
            "Epoch 472/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4287.6595 - _calculate_reconstruction_loss: 0.0042 - _calculate_kl_loss: 85.0046\n",
            "Epoch 473/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4318.6347 - _calculate_reconstruction_loss: 0.0042 - _calculate_kl_loss: 84.8718\n",
            "Epoch 474/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4317.2616 - _calculate_reconstruction_loss: 0.0042 - _calculate_kl_loss: 85.8381\n",
            "Epoch 475/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4345.6448 - _calculate_reconstruction_loss: 0.0043 - _calculate_kl_loss: 84.3931\n",
            "Epoch 476/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4326.3497 - _calculate_reconstruction_loss: 0.0042 - _calculate_kl_loss: 83.0425\n",
            "Epoch 477/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4598.8614 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 85.3984\n",
            "Epoch 478/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 8687.4850 - _calculate_reconstruction_loss: 0.0085 - _calculate_kl_loss: 185.6492\n",
            "Epoch 479/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 7423.8125 - _calculate_reconstruction_loss: 0.0072 - _calculate_kl_loss: 249.5531\n",
            "Epoch 480/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 6415.0063 - _calculate_reconstruction_loss: 0.0062 - _calculate_kl_loss: 230.6768\n",
            "Epoch 481/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5837.8679 - _calculate_reconstruction_loss: 0.0056 - _calculate_kl_loss: 212.0891\n",
            "Epoch 482/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5602.1039 - _calculate_reconstruction_loss: 0.0054 - _calculate_kl_loss: 197.5367\n",
            "Epoch 483/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5359.9930 - _calculate_reconstruction_loss: 0.0052 - _calculate_kl_loss: 185.1575\n",
            "Epoch 484/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5264.2510 - _calculate_reconstruction_loss: 0.0051 - _calculate_kl_loss: 176.2770\n",
            "Epoch 485/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5156.6068 - _calculate_reconstruction_loss: 0.0050 - _calculate_kl_loss: 170.1284\n",
            "Epoch 486/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4997.7567 - _calculate_reconstruction_loss: 0.0048 - _calculate_kl_loss: 161.3781\n",
            "Epoch 487/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4825.2239 - _calculate_reconstruction_loss: 0.0047 - _calculate_kl_loss: 158.3930\n",
            "Epoch 488/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5086.3798 - _calculate_reconstruction_loss: 0.0049 - _calculate_kl_loss: 153.5820\n",
            "Epoch 489/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4867.1911 - _calculate_reconstruction_loss: 0.0047 - _calculate_kl_loss: 150.5608\n",
            "Epoch 490/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4890.0514 - _calculate_reconstruction_loss: 0.0047 - _calculate_kl_loss: 146.1537\n",
            "Epoch 491/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4947.5535 - _calculate_reconstruction_loss: 0.0048 - _calculate_kl_loss: 141.6230\n",
            "Epoch 492/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4882.1266 - _calculate_reconstruction_loss: 0.0047 - _calculate_kl_loss: 138.9057\n",
            "Epoch 493/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4798.3834 - _calculate_reconstruction_loss: 0.0047 - _calculate_kl_loss: 135.3315\n",
            "Epoch 494/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4801.0800 - _calculate_reconstruction_loss: 0.0047 - _calculate_kl_loss: 132.8287\n",
            "Epoch 495/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4852.2114 - _calculate_reconstruction_loss: 0.0047 - _calculate_kl_loss: 130.5580\n",
            "Epoch 496/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5026.4365 - _calculate_reconstruction_loss: 0.0049 - _calculate_kl_loss: 133.0965\n",
            "Epoch 497/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4674.0041 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 129.3815\n",
            "Epoch 498/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4667.6109 - _calculate_reconstruction_loss: 0.0045 - _calculate_kl_loss: 124.8640\n",
            "Epoch 499/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 5378.4342 - _calculate_reconstruction_loss: 0.0052 - _calculate_kl_loss: 142.3540\n",
            "Epoch 500/500\n",
            "960/960 [==============================] - 2s 2ms/sample - loss: 4901.6346 - _calculate_reconstruction_loss: 0.0048 - _calculate_kl_loss: 149.6600\n",
            "[(256, 64, 1), (32, 16, 16, 8), (3, 3, 3, 3), (1, 2, 2, 1), 8]\n",
            "Model Saved!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2IhMH3guEs_",
        "outputId": "c3b91df8-61f2-4dac-92f3-1cde8845bcfc"
      },
      "source": [
        "# # https://github.com/musikalkemist/generating-sound-with-neural-networks/blob/49d7db32c43d1a04c596cbbb282a9521be1e7fc8/11%20Implementing%20VAE/code/analysis.py\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa\n",
        "import librosa.display\n",
        "\n",
        "LEARNING_RATE = 0.0001\n",
        "BATCH_SIZE = 50\n",
        "EPOCHS = 500\n",
        "LATENT_SPACE_DIM= 8 \n",
        "\n",
        "# Same method as above\n",
        "def load_fsdd(spectrograms_path):\n",
        "    dataset = {}\n",
        "    for root, _, file_names in os.walk(spectrograms_path):\n",
        "        for file_name in file_names:\n",
        "\n",
        "            if True: # re.match(regex, file_name):\n",
        "                file_path = os.path.join(root, file_name)\n",
        "                spectrogram = np.load(file_path) # (n_bins, n_frames, 1) \n",
        "                dataset[file_name] = spectrogram[..., np.newaxis]\n",
        "    return dataset\n",
        "SPECTROGRAMS_PATH = \"/content/drive/MyDrive/Music/VAE/spectrogram\"\n",
        "\n",
        "LATENT_REPRESENTATIONS_PATH = '/content/drive/MyDrive/Music/VAE/model-' + str(LATENT_SPACE_DIM) + '-' + str(BATCH_SIZE) + '-' + str(EPOCHS) + '/'\n",
        "MODEL_PATH = '/content/drive/MyDrive/Music/VAE/model-8-50-100'\n",
        "\n",
        "def select_random_images(dataset, num_images=10):\n",
        "    sample_keys = np.random.choice(list(dataset.keys()), num_images)\n",
        "    sample_ds = { key: dataset[key] for key in sample_keys }\n",
        "\n",
        "    return sample_ds\n",
        "\n",
        "\n",
        "def plot_reconstructed_images(images, reconstructed_images):\n",
        "    num_images = len(images)\n",
        "    for i, (image, reconstructed_image) in enumerate(zip(images, reconstructed_images)):\n",
        "\n",
        "        fig, ax = plt.subplots()\n",
        "        image = image.squeeze()\n",
        "        img = librosa.display.specshow(image, y_axis='log', x_axis='time', ax=ax)\n",
        "        fig.colorbar(img, ax=ax, format=\"%+2.0f dB\")\n",
        "\n",
        "        fig, ax = plt.subplots()\n",
        "        reconstructed_image = reconstructed_image.squeeze()\n",
        "        recon_img = librosa.display.specshow(reconstructed_image, y_axis='log', x_axis='time', ax=ax)\n",
        "        fig.colorbar(recon_img, ax=ax, format=\"%+2.0f dB\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_images_encoded_in_latent_space(latent_representations, sample_labels):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.scatter(latent_representations[:, 0],\n",
        "                latent_representations[:, 1],\n",
        "                cmap=\"rainbow\",\n",
        "                c=sample_labels,\n",
        "                alpha=0.5,\n",
        "                s=2)\n",
        "    plt.colorbar()\n",
        "    plt.show()\n",
        "\n",
        "def download_vectors(autoencoder, sample_ds, download_path):\n",
        "    images = np.array(list(sample_ds.values()))\n",
        "    filenames = sample_ds.keys()\n",
        "    latent_representations = autoencoder.encoder.predict(images)\n",
        "\n",
        "    with open(download_path + 'embeddings.tsv', 'w', newline='') as f_output:\n",
        "        tsv_output = csv.writer(f_output, delimiter='\\t')\n",
        "        tsv_output.writerows(latent_representations)\n",
        "    # Write corresdonding filenames\n",
        "    with open(download_path + 'embedding-filenames.tsv', 'a') as f_output:\n",
        "        f_output.seek(0)\n",
        "        f_output.truncate()\n",
        "        for data in filenames:\n",
        "            f_output.write(data)\n",
        "            f_output.write('\\n')\n",
        "    return latent_representations, filenames\n",
        "\n",
        "\n",
        "autoencoder = VAE.load(MODEL_PATH)\n",
        "dataset = load_fsdd(SPECTROGRAMS_PATH)\n",
        "\n",
        "# num_sample_images_to_show = 30\n",
        "\n",
        "# sample_ds = select_random_images(dataset, num_sample_images_to_show)\n",
        "# reconstructed_images, _ = autoencoder.reconstruct(np.array(list(dataset.values())))\n",
        "download_vectors(autoencoder, dataset, LATENT_REPRESENTATIONS_PATH)\n",
        "\n",
        "# plot_reconstructed_images(sample_images, reconstructed_images)\n",
        "\n",
        "# num_images = 6000\n",
        "# sample_images, sample_labels = select_images(x_test, y_test, num_images)\n",
        "# _, latent_representations = autoencoder.reconstruct(sample_images)\n",
        "# plot_images_encoded_in_latent_space(latent_representations, sample_labels)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[-1.3283415e+00,  4.5208755e+00, -1.2487184e-01, ...,\n",
              "          6.4911723e+00, -3.1294203e+00, -5.7066922e+00],\n",
              "        [-4.6504583e+00, -3.1070719e+00,  6.1827745e+00, ...,\n",
              "          8.0801172e+00,  3.2701304e+00, -9.6376610e+00],\n",
              "        [-5.3734121e+00,  2.6573277e+00,  5.0506210e+00, ...,\n",
              "          3.9828353e+00, -4.8554630e+00, -6.3484883e+00],\n",
              "        ...,\n",
              "        [-7.1195621e+00, -5.5236399e-01, -1.4479220e+00, ...,\n",
              "          1.0036805e+01, -7.0367503e-01, -9.2546530e+00],\n",
              "        [-7.7029009e+00, -4.0446115e+00,  2.3407176e+00, ...,\n",
              "          1.1809381e+01,  1.0936880e+00, -5.9428272e+00],\n",
              "        [-8.9572401e+00, -1.2602620e-03,  9.4465315e-01, ...,\n",
              "          7.5447712e+00, -3.9030082e+00, -7.4327726e+00]], dtype=float32),\n",
              " dict_keys(['00001-04 01A US Double Nrm.wav.npy', '00001-06 01A US Double Nrm.wav.npy', '00001-09 01A US Double Nrm.wav.npy', '00001-05 01A US Double Nrm.wav.npy', '00001-12 01A US Double Nrm.wav.npy', '00001-02 01A US Double Nrm.wav.npy', '00001-07 01A US Double Nrm.wav.npy', '00001-10 01A US Double Nrm.wav.npy', '00001-11 01A US Double Nrm.wav.npy', '00001-03 01A US Double Nrm.wav.npy', '00001-08 01A US Double Nrm.wav.npy', '00002-09 01B Essex A30.wav.npy', '00002-05 01B Essex A30.wav.npy', '00002-04 01B Essex A30.wav.npy', '00001-01 01A US Double Nrm.wav.npy', '00002-11 01B Essex A30.wav.npy', '00002-06 01B Essex A30.wav.npy', '00002-12 01B Essex A30.wav.npy', '00002-08 01B Essex A30.wav.npy', '00002-07 01B Essex A30.wav.npy', '00002-10 01B Essex A30.wav.npy', '00002-02 01B Essex A30.wav.npy', '00002-03 01B Essex A30.wav.npy', '00002-01 01B Essex A30.wav.npy', '00003-09 01C Brit Plexi Jump.wav.npy', '00003-06 01C Brit Plexi Jump.wav.npy', '00003-11 01C Brit Plexi Jump.wav.npy', '00003-10 01C Brit Plexi Jump.wav.npy', '00003-05 01C Brit Plexi Jump.wav.npy', '00003-12 01C Brit Plexi Jump.wav.npy', '00003-08 01C Brit Plexi Jump.wav.npy', '00003-07 01C Brit Plexi Jump.wav.npy', '00003-03 01C Brit Plexi Jump.wav.npy', '00003-02 01C Brit Plexi Jump.wav.npy', '00003-04 01C Brit Plexi Jump.wav.npy', '00004-04 01D Cali Rectifire.wav.npy', '00004-12 01D Cali Rectifire.wav.npy', '00004-07 01D Cali Rectifire.wav.npy', '00004-06 01D Cali Rectifire.wav.npy', '00004-11 01D Cali Rectifire.wav.npy', '00003-01 01C Brit Plexi Jump.wav.npy', '00004-03 01D Cali Rectifire.wav.npy', '00004-10 01D Cali Rectifire.wav.npy', '00004-02 01D Cali Rectifire.wav.npy', '00004-08 01D Cali Rectifire.wav.npy', '00004-05 01D Cali Rectifire.wav.npy', '00004-09 01D Cali Rectifire.wav.npy', '00005-12 02A US Deluxe Nrm.wav.npy', '00005-07 02A US Deluxe Nrm.wav.npy', '00005-06 02A US Deluxe Nrm.wav.npy', '00005-08 02A US Deluxe Nrm.wav.npy', '00005-11 02A US Deluxe Nrm.wav.npy', '00005-04 02A US Deluxe Nrm.wav.npy', '00004-01 01D Cali Rectifire.wav.npy', '00005-03 02A US Deluxe Nrm.wav.npy', '00005-01 02A US Deluxe Nrm.wav.npy', '00005-09 02A US Deluxe Nrm.wav.npy', '00005-05 02A US Deluxe Nrm.wav.npy', '00005-02 02A US Deluxe Nrm.wav.npy', '00005-10 02A US Deluxe Nrm.wav.npy', '00006-07 02B A30 Fawn Nrm.wav.npy', '00006-11 02B A30 Fawn Nrm.wav.npy', '00006-06 02B A30 Fawn Nrm.wav.npy', '00006-08 02B A30 Fawn Nrm.wav.npy', '00006-10 02B A30 Fawn Nrm.wav.npy', '00006-12 02B A30 Fawn Nrm.wav.npy', '00006-09 02B A30 Fawn Nrm.wav.npy', '00006-04 02B A30 Fawn Nrm.wav.npy', '00006-02 02B A30 Fawn Nrm.wav.npy', '00006-03 02B A30 Fawn Nrm.wav.npy', '00006-05 02B A30 Fawn Nrm.wav.npy', '00006-01 02B A30 Fawn Nrm.wav.npy', '00007-06 02C Revv Gen Purple.wav.npy', '00007-04 02C Revv Gen Purple.wav.npy', '00007-10 02C Revv Gen Purple.wav.npy', '00007-11 02C Revv Gen Purple.wav.npy', '00007-08 02C Revv Gen Purple.wav.npy', '00007-05 02C Revv Gen Purple.wav.npy', '00007-07 02C Revv Gen Purple.wav.npy', '00007-02 02C Revv Gen Purple.wav.npy', '00007-09 02C Revv Gen Purple.wav.npy', '00007-12 02C Revv Gen Purple.wav.npy', '00007-03 02C Revv Gen Purple.wav.npy', '00008-11 02D Revv Gen Red.wav.npy', '00007-01 02C Revv Gen Purple.wav.npy', '00008-10 02D Revv Gen Red.wav.npy', '00008-09 02D Revv Gen Red.wav.npy', '00008-05 02D Revv Gen Red.wav.npy', '00008-12 02D Revv Gen Red.wav.npy', '00008-08 02D Revv Gen Red.wav.npy', '00008-03 02D Revv Gen Red.wav.npy', '00008-07 02D Revv Gen Red.wav.npy', '00008-06 02D Revv Gen Red.wav.npy', '00008-02 02D Revv Gen Red.wav.npy', '00008-04 02D Revv Gen Red.wav.npy', '00008-01 02D Revv Gen Red.wav.npy', '00009-06 03A Archetype Clean.wav.npy', '00009-12 03A Archetype Clean.wav.npy', '00009-07 03A Archetype Clean.wav.npy', '00009-09 03A Archetype Clean.wav.npy', '00009-11 03A Archetype Clean.wav.npy', '00009-08 03A Archetype Clean.wav.npy', '00009-05 03A Archetype Clean.wav.npy', '00009-02 03A Archetype Clean.wav.npy', '00009-04 03A Archetype Clean.wav.npy', '00009-10 03A Archetype Clean.wav.npy', '00009-03 03A Archetype Clean.wav.npy', '00010-10 03B Matchstick Ch1.wav.npy', '00010-06 03B Matchstick Ch1.wav.npy', '00010-09 03B Matchstick Ch1.wav.npy', '00010-02 03B Matchstick Ch1.wav.npy', '00010-03 03B Matchstick Ch1.wav.npy', '00010-12 03B Matchstick Ch1.wav.npy', '00010-07 03B Matchstick Ch1.wav.npy', '00010-08 03B Matchstick Ch1.wav.npy', '00009-01 03A Archetype Clean.wav.npy', '00010-05 03B Matchstick Ch1.wav.npy', '00010-11 03B Matchstick Ch1.wav.npy', '00010-04 03B Matchstick Ch1.wav.npy', '00011-10 03C Brit 2204.wav.npy', '00011-09 03C Brit 2204.wav.npy', '00011-08 03C Brit 2204.wav.npy', '00011-04 03C Brit 2204.wav.npy', '00011-07 03C Brit 2204.wav.npy', '00011-11 03C Brit 2204.wav.npy', '00010-01 03B Matchstick Ch1.wav.npy', '00011-03 03C Brit 2204.wav.npy', '00011-06 03C Brit 2204.wav.npy', '00011-05 03C Brit 2204.wav.npy', '00011-02 03C Brit 2204.wav.npy', '00011-12 03C Brit 2204.wav.npy', '00012-03 03D Archetype Lead.wav.npy', '00012-12 03D Archetype Lead.wav.npy', '00012-08 03D Archetype Lead.wav.npy', '00011-01 03C Brit 2204.wav.npy', '00012-06 03D Archetype Lead.wav.npy', '00012-07 03D Archetype Lead.wav.npy', '00012-10 03D Archetype Lead.wav.npy', '00012-05 03D Archetype Lead.wav.npy', '00012-02 03D Archetype Lead.wav.npy', '00012-11 03D Archetype Lead.wav.npy', '00012-09 03D Archetype Lead.wav.npy', '00012-04 03D Archetype Lead.wav.npy', '00013-05 04A Jazz Rivet 120.wav.npy', '00013-06 04A Jazz Rivet 120.wav.npy', '00013-02 04A Jazz Rivet 120.wav.npy', '00013-09 04A Jazz Rivet 120.wav.npy', '00013-04 04A Jazz Rivet 120.wav.npy', '00013-08 04A Jazz Rivet 120.wav.npy', '00013-10 04A Jazz Rivet 120.wav.npy', '00012-01 03D Archetype Lead.wav.npy', '00013-11 04A Jazz Rivet 120.wav.npy', '00013-07 04A Jazz Rivet 120.wav.npy', '00013-03 04A Jazz Rivet 120.wav.npy', '00013-12 04A Jazz Rivet 120.wav.npy', '00014-09 04B Fullerton Brt.wav.npy', '00014-07 04B Fullerton Brt.wav.npy', '00013-01 04A Jazz Rivet 120.wav.npy', '00014-08 04B Fullerton Brt.wav.npy', '00014-06 04B Fullerton Brt.wav.npy', '00014-04 04B Fullerton Brt.wav.npy', '00014-10 04B Fullerton Brt.wav.npy', '00014-02 04B Fullerton Brt.wav.npy', '00014-12 04B Fullerton Brt.wav.npy', '00014-03 04B Fullerton Brt.wav.npy', '00014-01 04B Fullerton Brt.wav.npy', '00014-05 04B Fullerton Brt.wav.npy', '00014-11 04B Fullerton Brt.wav.npy', '00015-06 04C Brit J45 Brt.wav.npy', '00015-10 04C Brit J45 Brt.wav.npy', '00015-12 04C Brit J45 Brt.wav.npy', '00015-09 04C Brit J45 Brt.wav.npy', '00015-11 04C Brit J45 Brt.wav.npy', '00015-05 04C Brit J45 Brt.wav.npy', '00015-08 04C Brit J45 Brt.wav.npy', '00015-04 04C Brit J45 Brt.wav.npy', '00015-07 04C Brit J45 Brt.wav.npy', '00015-02 04C Brit J45 Brt.wav.npy', '00015-03 04C Brit J45 Brt.wav.npy', '00015-01 04C Brit J45 Brt.wav.npy', '00016-07 04D Solo Lead OD.wav.npy', '00016-11 04D Solo Lead OD.wav.npy', '00016-05 04D Solo Lead OD.wav.npy', '00016-10 04D Solo Lead OD.wav.npy', '00016-09 04D Solo Lead OD.wav.npy', '00016-02 04D Solo Lead OD.wav.npy', '00016-06 04D Solo Lead OD.wav.npy', '00016-08 04D Solo Lead OD.wav.npy', '00016-03 04D Solo Lead OD.wav.npy', '00016-04 04D Solo Lead OD.wav.npy', '00016-01 04D Solo Lead OD.wav.npy', '00016-12 04D Solo Lead OD.wav.npy', '00017-05 05A Placater Clean.wav.npy', '00017-11 05A Placater Clean.wav.npy', '00017-03 05A Placater Clean.wav.npy', '00017-07 05A Placater Clean.wav.npy', '00017-06 05A Placater Clean.wav.npy', '00017-12 05A Placater Clean.wav.npy', '00017-09 05A Placater Clean.wav.npy', '00017-08 05A Placater Clean.wav.npy', '00017-10 05A Placater Clean.wav.npy', '00017-02 05A Placater Clean.wav.npy', '00017-04 05A Placater Clean.wav.npy', '00018-04 05B Interstate Zed.wav.npy', '00018-10 05B Interstate Zed.wav.npy', '00018-02 05B Interstate Zed.wav.npy', '00018-08 05B Interstate Zed.wav.npy', '00018-03 05B Interstate Zed.wav.npy', '00018-05 05B Interstate Zed.wav.npy', '00017-01 05A Placater Clean.wav.npy', '00018-09 05B Interstate Zed.wav.npy', '00018-07 05B Interstate Zed.wav.npy', '00018-11 05B Interstate Zed.wav.npy', '00018-12 05B Interstate Zed.wav.npy', '00018-06 05B Interstate Zed.wav.npy', '00019-11 05C Placater Dirty.wav.npy', '00018-01 05B Interstate Zed.wav.npy', '00019-05 05C Placater Dirty.wav.npy', '00019-12 05C Placater Dirty.wav.npy', '00019-06 05C Placater Dirty.wav.npy', '00019-03 05C Placater Dirty.wav.npy', '00019-02 05C Placater Dirty.wav.npy', '00019-04 05C Placater Dirty.wav.npy', '00019-09 05C Placater Dirty.wav.npy', '00019-01 05C Placater Dirty.wav.npy', '00019-07 05C Placater Dirty.wav.npy', '00019-08 05C Placater Dirty.wav.npy', '00019-10 05C Placater Dirty.wav.npy', '00020-04 05D PV Panama.wav.npy', '00020-05 05D PV Panama.wav.npy', '00020-09 05D PV Panama.wav.npy', '00020-06 05D PV Panama.wav.npy', '00020-03 05D PV Panama.wav.npy', '00020-12 05D PV Panama.wav.npy', '00020-11 05D PV Panama.wav.npy', '00020-02 05D PV Panama.wav.npy', '00020-08 05D PV Panama.wav.npy', '00020-07 05D PV Panama.wav.npy', '00020-10 05D PV Panama.wav.npy', '00021-05 06A Cali Texas Ch 1.wav.npy', '00021-07 06A Cali Texas Ch 1.wav.npy', '00021-10 06A Cali Texas Ch 1.wav.npy', '00021-08 06A Cali Texas Ch 1.wav.npy', '00021-06 06A Cali Texas Ch 1.wav.npy', '00021-09 06A Cali Texas Ch 1.wav.npy', '00021-04 06A Cali Texas Ch 1.wav.npy', '00020-01 05D PV Panama.wav.npy', '00021-11 06A Cali Texas Ch 1.wav.npy', '00021-02 06A Cali Texas Ch 1.wav.npy', '00021-12 06A Cali Texas Ch 1.wav.npy', '00021-03 06A Cali Texas Ch 1.wav.npy', '00021-01 06A Cali Texas Ch 1.wav.npy', '00022-07 06B Essex A15.wav.npy', '00022-06 06B Essex A15.wav.npy', '00022-10 06B Essex A15.wav.npy', '00022-02 06B Essex A15.wav.npy', '00022-08 06B Essex A15.wav.npy', '00022-03 06B Essex A15.wav.npy', '00022-09 06B Essex A15.wav.npy', '00022-05 06B Essex A15.wav.npy', '00022-11 06B Essex A15.wav.npy', '00022-12 06B Essex A15.wav.npy', '00022-04 06B Essex A15.wav.npy', '00023-08 06C Derailed Ingrid.wav.npy', '00023-04 06C Derailed Ingrid.wav.npy', '00022-01 06B Essex A15.wav.npy', '00023-06 06C Derailed Ingrid.wav.npy', '00023-03 06C Derailed Ingrid.wav.npy', '00023-09 06C Derailed Ingrid.wav.npy', '00023-02 06C Derailed Ingrid.wav.npy', '00023-07 06C Derailed Ingrid.wav.npy', '00023-12 06C Derailed Ingrid.wav.npy', '00023-11 06C Derailed Ingrid.wav.npy', '00023-10 06C Derailed Ingrid.wav.npy', '00023-05 06C Derailed Ingrid.wav.npy', '00023-01 06C Derailed Ingrid.wav.npy', '00024-06 06D German Mahadeva.wav.npy', '00024-11 06D German Mahadeva.wav.npy', '00024-03 06D German Mahadeva.wav.npy', '00024-07 06D German Mahadeva.wav.npy', '00024-02 06D German Mahadeva.wav.npy', '00024-05 06D German Mahadeva.wav.npy', '00024-10 06D German Mahadeva.wav.npy', '00024-12 06D German Mahadeva.wav.npy', '00024-09 06D German Mahadeva.wav.npy', '00024-08 06D German Mahadeva.wav.npy', '00024-04 06D German Mahadeva.wav.npy', '00025-10 07A WhoWatt 100.wav.npy', '00024-01 06D German Mahadeva.wav.npy', '00025-12 07A WhoWatt 100.wav.npy', '00025-04 07A WhoWatt 100.wav.npy', '00025-07 07A WhoWatt 100.wav.npy', '00025-02 07A WhoWatt 100.wav.npy', '00025-11 07A WhoWatt 100.wav.npy', '00025-08 07A WhoWatt 100.wav.npy', '00025-05 07A WhoWatt 100.wav.npy', '00025-03 07A WhoWatt 100.wav.npy', '00025-09 07A WhoWatt 100.wav.npy', '00025-06 07A WhoWatt 100.wav.npy', '00026-12 07B Line 6 Litigator.wav.npy', '00026-08 07B Line 6 Litigator.wav.npy', '00026-06 07B Line 6 Litigator.wav.npy', '00025-01 07A WhoWatt 100.wav.npy', '00026-02 07B Line 6 Litigator.wav.npy', '00026-04 07B Line 6 Litigator.wav.npy', '00026-10 07B Line 6 Litigator.wav.npy', '00026-05 07B Line 6 Litigator.wav.npy', '00026-09 07B Line 6 Litigator.wav.npy', '00026-11 07B Line 6 Litigator.wav.npy', '00026-03 07B Line 6 Litigator.wav.npy', '00026-07 07B Line 6 Litigator.wav.npy', '00027-03 07C Cartographer.wav.npy', '00027-11 07C Cartographer.wav.npy', '00027-09 07C Cartographer.wav.npy', '00027-06 07C Cartographer.wav.npy', '00027-07 07C Cartographer.wav.npy', '00027-10 07C Cartographer.wav.npy', '00027-08 07C Cartographer.wav.npy', '00026-01 07B Line 6 Litigator.wav.npy', '00027-04 07C Cartographer.wav.npy', '00027-05 07C Cartographer.wav.npy', '00027-12 07C Cartographer.wav.npy', '00027-01 07C Cartographer.wav.npy', '00027-02 07C Cartographer.wav.npy', '00028-04 07D ANGL Meteor.wav.npy', '00028-06 07D ANGL Meteor.wav.npy', '00028-08 07D ANGL Meteor.wav.npy', '00028-05 07D ANGL Meteor.wav.npy', '00028-02 07D ANGL Meteor.wav.npy', '00028-03 07D ANGL Meteor.wav.npy', '00028-12 07D ANGL Meteor.wav.npy', '00028-10 07D ANGL Meteor.wav.npy', '00028-11 07D ANGL Meteor.wav.npy', '00028-07 07D ANGL Meteor.wav.npy', '00028-09 07D ANGL Meteor.wav.npy', '00029-03 08A US Small Tweed.wav.npy', '00029-05 08A US Small Tweed.wav.npy', '00029-04 08A US Small Tweed.wav.npy', '00028-01 07D ANGL Meteor.wav.npy', '00029-10 08A US Small Tweed.wav.npy', '00029-08 08A US Small Tweed.wav.npy', '00029-02 08A US Small Tweed.wav.npy', '00029-06 08A US Small Tweed.wav.npy', '00029-09 08A US Small Tweed.wav.npy', '00029-12 08A US Small Tweed.wav.npy', '00029-01 08A US Small Tweed.wav.npy', '00029-07 08A US Small Tweed.wav.npy', '00029-11 08A US Small Tweed.wav.npy', '00030-06 08B Divided Duo.wav.npy', '00030-07 08B Divided Duo.wav.npy', '00030-03 08B Divided Duo.wav.npy', '00030-04 08B Divided Duo.wav.npy', '00030-09 08B Divided Duo.wav.npy', '00030-11 08B Divided Duo.wav.npy', '00030-02 08B Divided Duo.wav.npy', '00030-08 08B Divided Duo.wav.npy', '00030-05 08B Divided Duo.wav.npy', '00030-10 08B Divided Duo.wav.npy', '00030-01 08B Divided Duo.wav.npy', '00030-12 08B Divided Duo.wav.npy', '00031-04 08C Brit P75 Brt.wav.npy', '00031-12 08C Brit P75 Brt.wav.npy', '00031-08 08C Brit P75 Brt.wav.npy', '00031-03 08C Brit P75 Brt.wav.npy', '00031-09 08C Brit P75 Brt.wav.npy', '00031-07 08C Brit P75 Brt.wav.npy', '00031-10 08C Brit P75 Brt.wav.npy', '00031-05 08C Brit P75 Brt.wav.npy', '00031-11 08C Brit P75 Brt.wav.npy', '00031-02 08C Brit P75 Brt.wav.npy', '00031-06 08C Brit P75 Brt.wav.npy', '00032-05 08D Line 6 Badonk.wav.npy', '00032-07 08D Line 6 Badonk.wav.npy', '00032-10 08D Line 6 Badonk.wav.npy', '00032-06 08D Line 6 Badonk.wav.npy', '00032-11 08D Line 6 Badonk.wav.npy', '00032-03 08D Line 6 Badonk.wav.npy', '00032-08 08D Line 6 Badonk.wav.npy', '00032-09 08D Line 6 Badonk.wav.npy', '00031-01 08C Brit P75 Brt.wav.npy', '00032-02 08D Line 6 Badonk.wav.npy', '00032-12 08D Line 6 Badonk.wav.npy', '00032-04 08D Line 6 Badonk.wav.npy', '00033-04 09A DI.wav.npy', '00033-08 09A DI.wav.npy', '00033-05 09A DI.wav.npy', '00033-07 09A DI.wav.npy', '00032-01 08D Line 6 Badonk.wav.npy', '00033-02 09A DI.wav.npy', '00033-06 09A DI.wav.npy', '00033-10 09A DI.wav.npy', '00033-03 09A DI.wav.npy', '00033-11 09A DI.wav.npy', '00033-09 09A DI.wav.npy', '00033-12 09A DI.wav.npy', '00034-06 09B BAS_SVT-4 Pro.wav.npy', '00034-05 09B BAS_SVT-4 Pro.wav.npy', '00034-02 09B BAS_SVT-4 Pro.wav.npy', '00034-08 09B BAS_SVT-4 Pro.wav.npy', '00034-03 09B BAS_SVT-4 Pro.wav.npy', '00033-01 09A DI.wav.npy', '00034-09 09B BAS_SVT-4 Pro.wav.npy', '00034-04 09B BAS_SVT-4 Pro.wav.npy', '00034-11 09B BAS_SVT-4 Pro.wav.npy', '00034-12 09B BAS_SVT-4 Pro.wav.npy', '00034-07 09B BAS_SVT-4 Pro.wav.npy', '00034-10 09B BAS_SVT-4 Pro.wav.npy', '00034-01 09B BAS_SVT-4 Pro.wav.npy', '00035-06 09C BAS_Cali Bass.wav.npy', '00035-10 09C BAS_Cali Bass.wav.npy', '00035-11 09C BAS_Cali Bass.wav.npy', '00035-09 09C BAS_Cali Bass.wav.npy', '00035-04 09C BAS_Cali Bass.wav.npy', '00035-12 09C BAS_Cali Bass.wav.npy', '00035-07 09C BAS_Cali Bass.wav.npy', '00035-05 09C BAS_Cali Bass.wav.npy', '00035-08 09C BAS_Cali Bass.wav.npy', '00035-03 09C BAS_Cali Bass.wav.npy', '00035-01 09C BAS_Cali Bass.wav.npy', '00035-02 09C BAS_Cali Bass.wav.npy', '00036-06 09D BAS_Aqua 51.wav.npy', '00036-11 09D BAS_Aqua 51.wav.npy', '00036-04 09D BAS_Aqua 51.wav.npy', '00036-08 09D BAS_Aqua 51.wav.npy', '00036-09 09D BAS_Aqua 51.wav.npy', '00036-12 09D BAS_Aqua 51.wav.npy', '00036-10 09D BAS_Aqua 51.wav.npy', '00036-03 09D BAS_Aqua 51.wav.npy', '00036-05 09D BAS_Aqua 51.wav.npy', '00036-02 09D BAS_Aqua 51.wav.npy', '00036-07 09D BAS_Aqua 51.wav.npy', '00037-05 10A BAS_Cougar 800.wav.npy', '00037-08 10A BAS_Cougar 800.wav.npy', '00037-11 10A BAS_Cougar 800.wav.npy', '00037-06 10A BAS_Cougar 800.wav.npy', '00036-01 09D BAS_Aqua 51.wav.npy', '00037-03 10A BAS_Cougar 800.wav.npy', '00037-10 10A BAS_Cougar 800.wav.npy', '00037-02 10A BAS_Cougar 800.wav.npy', '00037-12 10A BAS_Cougar 800.wav.npy', '00037-09 10A BAS_Cougar 800.wav.npy', '00037-07 10A BAS_Cougar 800.wav.npy', '00037-04 10A BAS_Cougar 800.wav.npy', '00038-11 10B BAS_SVT Nrm.wav.npy', '00038-05 10B BAS_SVT Nrm.wav.npy', '00038-10 10B BAS_SVT Nrm.wav.npy', '00038-04 10B BAS_SVT Nrm.wav.npy', '00038-08 10B BAS_SVT Nrm.wav.npy', '00038-12 10B BAS_SVT Nrm.wav.npy', '00038-03 10B BAS_SVT Nrm.wav.npy', '00038-02 10B BAS_SVT Nrm.wav.npy', '00037-01 10A BAS_Cougar 800.wav.npy', '00038-07 10B BAS_SVT Nrm.wav.npy', '00038-09 10B BAS_SVT Nrm.wav.npy', '00038-06 10B BAS_SVT Nrm.wav.npy', '00039-04 10C BAS_Cali 400 Ch1.wav.npy', '00039-09 10C BAS_Cali 400 Ch1.wav.npy', '00039-05 10C BAS_Cali 400 Ch1.wav.npy', '00039-12 10C BAS_Cali 400 Ch1.wav.npy', '00039-07 10C BAS_Cali 400 Ch1.wav.npy', '00038-01 10B BAS_SVT Nrm.wav.npy', '00039-10 10C BAS_Cali 400 Ch1.wav.npy', '00039-02 10C BAS_Cali 400 Ch1.wav.npy', '00039-08 10C BAS_Cali 400 Ch1.wav.npy', '00039-06 10C BAS_Cali 400 Ch1.wav.npy', '00039-03 10C BAS_Cali 400 Ch1.wav.npy', '00039-11 10C BAS_Cali 400 Ch1.wav.npy', '00040-06 10D BAS_Del Sol 300.wav.npy', '00040-05 10D BAS_Del Sol 300.wav.npy', '00040-04 10D BAS_Del Sol 300.wav.npy', '00040-02 10D BAS_Del Sol 300.wav.npy', '00039-01 10C BAS_Cali 400 Ch1.wav.npy', '00040-03 10D BAS_Del Sol 300.wav.npy', '00040-10 10D BAS_Del Sol 300.wav.npy', '00040-08 10D BAS_Del Sol 300.wav.npy', '00040-11 10D BAS_Del Sol 300.wav.npy', '00040-12 10D BAS_Del Sol 300.wav.npy', '00040-09 10D BAS_Del Sol 300.wav.npy', '00040-01 10D BAS_Del Sol 300.wav.npy', '00040-07 10D BAS_Del Sol 300.wav.npy', '00041-10 11A BAS_Woody Blue.wav.npy', '00041-09 11A BAS_Woody Blue.wav.npy', '00041-12 11A BAS_Woody Blue.wav.npy', '00041-05 11A BAS_Woody Blue.wav.npy', '00041-06 11A BAS_Woody Blue.wav.npy', '00041-11 11A BAS_Woody Blue.wav.npy', '00041-03 11A BAS_Woody Blue.wav.npy', '00041-02 11A BAS_Woody Blue.wav.npy', '00041-04 11A BAS_Woody Blue.wav.npy', '00041-08 11A BAS_Woody Blue.wav.npy', '00041-07 11A BAS_Woody Blue.wav.npy', '00042-08 11B Trademark.wav.npy', '00042-05 11B Trademark.wav.npy', '00041-01 11A BAS_Woody Blue.wav.npy', '00042-07 11B Trademark.wav.npy', '00042-10 11B Trademark.wav.npy', '00042-11 11B Trademark.wav.npy', '00042-09 11B Trademark.wav.npy', '00042-12 11B Trademark.wav.npy', '00042-03 11B Trademark.wav.npy', '00042-02 11B Trademark.wav.npy', '00042-01 11B Trademark.wav.npy', '00042-06 11B Trademark.wav.npy', '00042-04 11B Trademark.wav.npy', '00043-12 11C AUS Flood.wav.npy', '00043-04 11C AUS Flood.wav.npy', '00043-09 11C AUS Flood.wav.npy', '00043-05 11C AUS Flood.wav.npy', '00043-06 11C AUS Flood.wav.npy', '00043-08 11C AUS Flood.wav.npy', '00043-11 11C AUS Flood.wav.npy', '00043-10 11C AUS Flood.wav.npy', '00043-03 11C AUS Flood.wav.npy', '00043-07 11C AUS Flood.wav.npy', '00043-02 11C AUS Flood.wav.npy', \"00044-09 11D Justice Fo Y'all.wav.npy\", \"00044-10 11D Justice Fo Y'all.wav.npy\", '00043-01 11C AUS Flood.wav.npy', \"00044-11 11D Justice Fo Y'all.wav.npy\", \"00044-05 11D Justice Fo Y'all.wav.npy\", \"00044-03 11D Justice Fo Y'all.wav.npy\", \"00044-12 11D Justice Fo Y'all.wav.npy\", \"00044-06 11D Justice Fo Y'all.wav.npy\", \"00044-04 11D Justice Fo Y'all.wav.npy\", \"00044-07 11D Justice Fo Y'all.wav.npy\", \"00044-08 11D Justice Fo Y'all.wav.npy\", \"00044-02 11D Justice Fo Y'all.wav.npy\", '00045-08 12A Lonely Hearts.wav.npy', \"00044-01 11D Justice Fo Y'all.wav.npy\", '00045-10 12A Lonely Hearts.wav.npy', '00045-04 12A Lonely Hearts.wav.npy', '00045-03 12A Lonely Hearts.wav.npy', '00045-12 12A Lonely Hearts.wav.npy', '00045-11 12A Lonely Hearts.wav.npy', '00045-05 12A Lonely Hearts.wav.npy', '00045-09 12A Lonely Hearts.wav.npy', '00045-06 12A Lonely Hearts.wav.npy', '00045-02 12A Lonely Hearts.wav.npy', '00045-07 12A Lonely Hearts.wav.npy', '00046-10 12B Pull Me Under.wav.npy', '00046-11 12B Pull Me Under.wav.npy', '00046-07 12B Pull Me Under.wav.npy', '00046-12 12B Pull Me Under.wav.npy', '00045-01 12A Lonely Hearts.wav.npy', '00046-05 12B Pull Me Under.wav.npy', '00046-03 12B Pull Me Under.wav.npy', '00046-09 12B Pull Me Under.wav.npy', '00046-04 12B Pull Me Under.wav.npy', '00046-02 12B Pull Me Under.wav.npy', '00046-08 12B Pull Me Under.wav.npy', '00046-06 12B Pull Me Under.wav.npy', '00047-08 12C Stone Cold Loco.wav.npy', '00047-10 12C Stone Cold Loco.wav.npy', '00047-09 12C Stone Cold Loco.wav.npy', '00046-01 12B Pull Me Under.wav.npy', '00047-04 12C Stone Cold Loco.wav.npy', '00047-03 12C Stone Cold Loco.wav.npy', '00047-06 12C Stone Cold Loco.wav.npy', '00047-07 12C Stone Cold Loco.wav.npy', '00047-12 12C Stone Cold Loco.wav.npy', '00047-11 12C Stone Cold Loco.wav.npy', '00047-05 12C Stone Cold Loco.wav.npy', '00047-02 12C Stone Cold Loco.wav.npy', '00048-12 12D Plush Garden.wav.npy', '00048-05 12D Plush Garden.wav.npy', '00048-10 12D Plush Garden.wav.npy', '00048-08 12D Plush Garden.wav.npy', '00048-07 12D Plush Garden.wav.npy', '00047-01 12C Stone Cold Loco.wav.npy', '00048-11 12D Plush Garden.wav.npy', '00048-09 12D Plush Garden.wav.npy', '00048-06 12D Plush Garden.wav.npy', '00048-02 12D Plush Garden.wav.npy', '00048-03 12D Plush Garden.wav.npy', '00048-04 12D Plush Garden.wav.npy', '00049-02 13A Cowboys from DFW.wav.npy', '00049-04 13A Cowboys from DFW.wav.npy', '00049-09 13A Cowboys from DFW.wav.npy', '00049-11 13A Cowboys from DFW.wav.npy', '00049-03 13A Cowboys from DFW.wav.npy', '00048-01 12D Plush Garden.wav.npy', '00049-12 13A Cowboys from DFW.wav.npy', '00049-08 13A Cowboys from DFW.wav.npy', '00049-10 13A Cowboys from DFW.wav.npy', '00049-06 13A Cowboys from DFW.wav.npy', '00049-05 13A Cowboys from DFW.wav.npy', '00049-07 13A Cowboys from DFW.wav.npy', '00050-06 13B G.O.A.T Rodeo.wav.npy', '00050-03 13B G.O.A.T Rodeo.wav.npy', '00050-12 13B G.O.A.T Rodeo.wav.npy', '00050-10 13B G.O.A.T Rodeo.wav.npy', '00050-11 13B G.O.A.T Rodeo.wav.npy', '00050-04 13B G.O.A.T Rodeo.wav.npy', '00050-05 13B G.O.A.T Rodeo.wav.npy', '00049-01 13A Cowboys from DFW.wav.npy', '00050-02 13B G.O.A.T Rodeo.wav.npy', '00050-07 13B G.O.A.T Rodeo.wav.npy', '00050-09 13B G.O.A.T Rodeo.wav.npy', '00050-08 13B G.O.A.T Rodeo.wav.npy', '00051-03 13C BIG DUBB.wav.npy', '00050-01 13B G.O.A.T Rodeo.wav.npy', '00051-05 13C BIG DUBB.wav.npy', '00051-04 13C BIG DUBB.wav.npy', '00051-02 13C BIG DUBB.wav.npy', '00051-09 13C BIG DUBB.wav.npy', '00051-11 13C BIG DUBB.wav.npy', '00051-10 13C BIG DUBB.wav.npy', '00051-12 13C BIG DUBB.wav.npy', '00051-01 13C BIG DUBB.wav.npy', '00051-07 13C BIG DUBB.wav.npy', '00051-06 13C BIG DUBB.wav.npy', '00051-08 13C BIG DUBB.wav.npy', '00052-02 13D BIG VENUE DRIVE.wav.npy', '00052-10 13D BIG VENUE DRIVE.wav.npy', '00052-04 13D BIG VENUE DRIVE.wav.npy', '00052-09 13D BIG VENUE DRIVE.wav.npy', '00052-11 13D BIG VENUE DRIVE.wav.npy', '00052-12 13D BIG VENUE DRIVE.wav.npy', '00052-08 13D BIG VENUE DRIVE.wav.npy', '00052-07 13D BIG VENUE DRIVE.wav.npy', '00052-06 13D BIG VENUE DRIVE.wav.npy', '00052-05 13D BIG VENUE DRIVE.wav.npy', '00052-03 13D BIG VENUE DRIVE.wav.npy', '00053-09 14A BUBBLE NEST.wav.npy', '00053-02 14A BUBBLE NEST.wav.npy', '00052-01 13D BIG VENUE DRIVE.wav.npy', '00053-07 14A BUBBLE NEST.wav.npy', '00053-03 14A BUBBLE NEST.wav.npy', '00053-12 14A BUBBLE NEST.wav.npy', '00053-06 14A BUBBLE NEST.wav.npy', '00053-08 14A BUBBLE NEST.wav.npy', '00053-05 14A BUBBLE NEST.wav.npy', '00053-01 14A BUBBLE NEST.wav.npy', '00053-04 14A BUBBLE NEST.wav.npy', '00053-11 14A BUBBLE NEST.wav.npy', '00053-10 14A BUBBLE NEST.wav.npy', '00054-10 14B DUSTED.wav.npy', '00054-09 14B DUSTED.wav.npy', '00054-06 14B DUSTED.wav.npy', '00054-02 14B DUSTED.wav.npy', '00054-04 14B DUSTED.wav.npy', '00054-11 14B DUSTED.wav.npy', '00054-12 14B DUSTED.wav.npy', '00054-07 14B DUSTED.wav.npy', '00054-08 14B DUSTED.wav.npy', '00054-05 14B DUSTED.wav.npy', '00054-01 14B DUSTED.wav.npy', '00054-03 14B DUSTED.wav.npy', '00055-10 14C SUNRISE DRIVE.wav.npy', '00055-05 14C SUNRISE DRIVE.wav.npy', '00055-11 14C SUNRISE DRIVE.wav.npy', '00055-08 14C SUNRISE DRIVE.wav.npy', '00055-03 14C SUNRISE DRIVE.wav.npy', '00055-09 14C SUNRISE DRIVE.wav.npy', '00055-07 14C SUNRISE DRIVE.wav.npy', '00055-04 14C SUNRISE DRIVE.wav.npy', '00055-02 14C SUNRISE DRIVE.wav.npy', '00055-12 14C SUNRISE DRIVE.wav.npy', '00055-06 14C SUNRISE DRIVE.wav.npy', '00056-03 14D GLISTEN.wav.npy', '00056-09 14D GLISTEN.wav.npy', '00056-07 14D GLISTEN.wav.npy', '00055-01 14C SUNRISE DRIVE.wav.npy', '00056-05 14D GLISTEN.wav.npy', '00056-11 14D GLISTEN.wav.npy', '00056-02 14D GLISTEN.wav.npy', '00056-12 14D GLISTEN.wav.npy', '00056-04 14D GLISTEN.wav.npy', '00056-06 14D GLISTEN.wav.npy', '00056-08 14D GLISTEN.wav.npy', '00056-10 14D GLISTEN.wav.npy', '00057-07 15A WATERS IN HELL.wav.npy', '00057-03 15A WATERS IN HELL.wav.npy', '00056-01 14D GLISTEN.wav.npy', '00057-12 15A WATERS IN HELL.wav.npy', '00057-04 15A WATERS IN HELL.wav.npy', '00057-06 15A WATERS IN HELL.wav.npy', '00057-02 15A WATERS IN HELL.wav.npy', '00057-08 15A WATERS IN HELL.wav.npy', '00057-10 15A WATERS IN HELL.wav.npy', '00057-11 15A WATERS IN HELL.wav.npy', '00057-09 15A WATERS IN HELL.wav.npy', '00057-05 15A WATERS IN HELL.wav.npy', '00058-05 15B FAUX 7 STG CHUG.wav.npy', '00057-01 15A WATERS IN HELL.wav.npy', '00058-12 15B FAUX 7 STG CHUG.wav.npy', '00058-03 15B FAUX 7 STG CHUG.wav.npy', '00058-02 15B FAUX 7 STG CHUG.wav.npy', '00058-08 15B FAUX 7 STG CHUG.wav.npy', '00058-09 15B FAUX 7 STG CHUG.wav.npy', '00058-11 15B FAUX 7 STG CHUG.wav.npy', '00058-07 15B FAUX 7 STG CHUG.wav.npy', '00058-06 15B FAUX 7 STG CHUG.wav.npy', '00058-10 15B FAUX 7 STG CHUG.wav.npy', '00058-04 15B FAUX 7 STG CHUG.wav.npy', '00059-04 15C RICHEESE.wav.npy', '00058-01 15B FAUX 7 STG CHUG.wav.npy', '00059-10 15C RICHEESE.wav.npy', '00059-08 15C RICHEESE.wav.npy', '00059-05 15C RICHEESE.wav.npy', '00059-07 15C RICHEESE.wav.npy', '00059-09 15C RICHEESE.wav.npy', '00059-06 15C RICHEESE.wav.npy', '00059-12 15C RICHEESE.wav.npy', '00059-02 15C RICHEESE.wav.npy', '00059-03 15C RICHEESE.wav.npy', '00059-11 15C RICHEESE.wav.npy', '00060-06 15D RC REINCARNATION.wav.npy', '00060-02 15D RC REINCARNATION.wav.npy', '00060-08 15D RC REINCARNATION.wav.npy', '00060-04 15D RC REINCARNATION.wav.npy', '00060-07 15D RC REINCARNATION.wav.npy', '00060-03 15D RC REINCARNATION.wav.npy', '00060-05 15D RC REINCARNATION.wav.npy', '00059-01 15C RICHEESE.wav.npy', '00060-10 15D RC REINCARNATION.wav.npy', '00060-11 15D RC REINCARNATION.wav.npy', '00060-12 15D RC REINCARNATION.wav.npy', '00060-01 15D RC REINCARNATION.wav.npy', '00060-09 15D RC REINCARNATION.wav.npy', '00061-10 16A RIFFS AND BEARDS.wav.npy', '00061-02 16A RIFFS AND BEARDS.wav.npy', '00061-04 16A RIFFS AND BEARDS.wav.npy', '00061-03 16A RIFFS AND BEARDS.wav.npy', '00061-07 16A RIFFS AND BEARDS.wav.npy', '00061-05 16A RIFFS AND BEARDS.wav.npy', '00061-08 16A RIFFS AND BEARDS.wav.npy', '00061-12 16A RIFFS AND BEARDS.wav.npy', '00061-11 16A RIFFS AND BEARDS.wav.npy', '00061-01 16A RIFFS AND BEARDS.wav.npy', '00061-09 16A RIFFS AND BEARDS.wav.npy', '00061-06 16A RIFFS AND BEARDS.wav.npy', '00062-07 16B FELIX MARK IV.wav.npy', '00062-05 16B FELIX MARK IV.wav.npy', '00062-02 16B FELIX MARK IV.wav.npy', '00062-12 16B FELIX MARK IV.wav.npy', '00062-09 16B FELIX MARK IV.wav.npy', '00062-08 16B FELIX MARK IV.wav.npy', '00062-11 16B FELIX MARK IV.wav.npy', '00062-10 16B FELIX MARK IV.wav.npy', '00062-04 16B FELIX MARK IV.wav.npy', '00062-03 16B FELIX MARK IV.wav.npy', '00062-06 16B FELIX MARK IV.wav.npy', '00063-03 16C FELIX JAZZ 120.wav.npy', '00063-08 16C FELIX JAZZ 120.wav.npy', '00063-05 16C FELIX JAZZ 120.wav.npy', '00063-10 16C FELIX JAZZ 120.wav.npy', '00062-01 16B FELIX MARK IV.wav.npy', '00063-06 16C FELIX JAZZ 120.wav.npy', '00063-09 16C FELIX JAZZ 120.wav.npy', '00063-07 16C FELIX JAZZ 120.wav.npy', '00063-11 16C FELIX JAZZ 120.wav.npy', '00063-12 16C FELIX JAZZ 120.wav.npy', '00063-02 16C FELIX JAZZ 120.wav.npy', '00063-04 16C FELIX JAZZ 120.wav.npy', '00064-05 16D FELIX DELUXE MOD.wav.npy', '00064-11 16D FELIX DELUXE MOD.wav.npy', '00064-09 16D FELIX DELUXE MOD.wav.npy', '00063-01 16C FELIX JAZZ 120.wav.npy', '00064-07 16D FELIX DELUXE MOD.wav.npy', '00064-03 16D FELIX DELUXE MOD.wav.npy', '00064-08 16D FELIX DELUXE MOD.wav.npy', '00064-06 16D FELIX DELUXE MOD.wav.npy', '00064-02 16D FELIX DELUXE MOD.wav.npy', '00064-12 16D FELIX DELUXE MOD.wav.npy', '00064-04 16D FELIX DELUXE MOD.wav.npy', '00064-01 16D FELIX DELUXE MOD.wav.npy', '00064-10 16D FELIX DELUXE MOD.wav.npy', '00065-05 17A FELIX ENGL.wav.npy', '00065-12 17A FELIX ENGL.wav.npy', '00065-02 17A FELIX ENGL.wav.npy', '00065-06 17A FELIX ENGL.wav.npy', '00065-07 17A FELIX ENGL.wav.npy', '00065-11 17A FELIX ENGL.wav.npy', '00065-08 17A FELIX ENGL.wav.npy', '00065-04 17A FELIX ENGL.wav.npy', '00065-03 17A FELIX ENGL.wav.npy', '00065-10 17A FELIX ENGL.wav.npy', '00065-09 17A FELIX ENGL.wav.npy', '00066-03 17B SPOTLIGHTS.wav.npy', '00066-04 17B SPOTLIGHTS.wav.npy', '00065-01 17A FELIX ENGL.wav.npy', '00066-08 17B SPOTLIGHTS.wav.npy', '00066-12 17B SPOTLIGHTS.wav.npy', '00066-02 17B SPOTLIGHTS.wav.npy', '00066-11 17B SPOTLIGHTS.wav.npy', '00066-06 17B SPOTLIGHTS.wav.npy', '00066-05 17B SPOTLIGHTS.wav.npy', '00066-10 17B SPOTLIGHTS.wav.npy', '00066-09 17B SPOTLIGHTS.wav.npy', '00066-07 17B SPOTLIGHTS.wav.npy', '00067-09 17C BUMBLE ACOUSTIC.wav.npy', '00067-10 17C BUMBLE ACOUSTIC.wav.npy', '00066-01 17B SPOTLIGHTS.wav.npy', '00067-07 17C BUMBLE ACOUSTIC.wav.npy', '00067-03 17C BUMBLE ACOUSTIC.wav.npy', '00067-06 17C BUMBLE ACOUSTIC.wav.npy', '00067-12 17C BUMBLE ACOUSTIC.wav.npy', '00067-02 17C BUMBLE ACOUSTIC.wav.npy', '00067-04 17C BUMBLE ACOUSTIC.wav.npy', '00067-05 17C BUMBLE ACOUSTIC.wav.npy', '00067-08 17C BUMBLE ACOUSTIC.wav.npy', '00067-11 17C BUMBLE ACOUSTIC.wav.npy', '00068-07 17D BMBLFOOT PRINCE.wav.npy', '00068-05 17D BMBLFOOT PRINCE.wav.npy', '00068-04 17D BMBLFOOT PRINCE.wav.npy', '00068-10 17D BMBLFOOT PRINCE.wav.npy', '00068-03 17D BMBLFOOT PRINCE.wav.npy', '00067-01 17C BUMBLE ACOUSTIC.wav.npy', '00068-02 17D BMBLFOOT PRINCE.wav.npy', '00068-11 17D BMBLFOOT PRINCE.wav.npy', '00068-12 17D BMBLFOOT PRINCE.wav.npy', '00068-06 17D BMBLFOOT PRINCE.wav.npy', '00068-09 17D BMBLFOOT PRINCE.wav.npy', '00068-08 17D BMBLFOOT PRINCE.wav.npy', '00069-10 18A SHEEHAN PEARCE.wav.npy', '00069-07 18A SHEEHAN PEARCE.wav.npy', '00069-08 18A SHEEHAN PEARCE.wav.npy', '00069-09 18A SHEEHAN PEARCE.wav.npy', '00069-12 18A SHEEHAN PEARCE.wav.npy', '00069-02 18A SHEEHAN PEARCE.wav.npy', '00069-03 18A SHEEHAN PEARCE.wav.npy', '00069-11 18A SHEEHAN PEARCE.wav.npy', '00068-01 17D BMBLFOOT PRINCE.wav.npy', '00069-04 18A SHEEHAN PEARCE.wav.npy', '00069-05 18A SHEEHAN PEARCE.wav.npy', '00069-06 18A SHEEHAN PEARCE.wav.npy', '00070-11 18B SHEEHAN SVT4PRO.wav.npy', '00070-06 18B SHEEHAN SVT4PRO.wav.npy', '00070-05 18B SHEEHAN SVT4PRO.wav.npy', '00070-04 18B SHEEHAN SVT4PRO.wav.npy', '00070-12 18B SHEEHAN SVT4PRO.wav.npy', '00070-03 18B SHEEHAN SVT4PRO.wav.npy', '00069-01 18A SHEEHAN PEARCE.wav.npy', '00070-09 18B SHEEHAN SVT4PRO.wav.npy', '00070-10 18B SHEEHAN SVT4PRO.wav.npy', '00070-08 18B SHEEHAN SVT4PRO.wav.npy', '00070-07 18B SHEEHAN SVT4PRO.wav.npy', '00070-02 18B SHEEHAN SVT4PRO.wav.npy', '00071-06 18C THE BLUE AGAVE.wav.npy', '00070-01 18B SHEEHAN SVT4PRO.wav.npy', '00071-11 18C THE BLUE AGAVE.wav.npy', '00071-09 18C THE BLUE AGAVE.wav.npy', '00071-10 18C THE BLUE AGAVE.wav.npy', '00071-04 18C THE BLUE AGAVE.wav.npy', '00071-12 18C THE BLUE AGAVE.wav.npy', '00071-03 18C THE BLUE AGAVE.wav.npy', '00071-08 18C THE BLUE AGAVE.wav.npy', '00071-07 18C THE BLUE AGAVE.wav.npy', '00071-05 18C THE BLUE AGAVE.wav.npy', '00071-02 18C THE BLUE AGAVE.wav.npy', '00072-02 18D BULB RHYTHM.wav.npy', '00071-01 18C THE BLUE AGAVE.wav.npy', '00072-11 18D BULB RHYTHM.wav.npy', '00072-07 18D BULB RHYTHM.wav.npy', '00072-03 18D BULB RHYTHM.wav.npy', '00072-05 18D BULB RHYTHM.wav.npy', '00072-09 18D BULB RHYTHM.wav.npy', '00072-12 18D BULB RHYTHM.wav.npy', '00072-06 18D BULB RHYTHM.wav.npy', '00072-10 18D BULB RHYTHM.wav.npy', '00072-08 18D BULB RHYTHM.wav.npy', '00072-04 18D BULB RHYTHM.wav.npy', '00073-11 19A BULB LEAD.wav.npy', '00073-03 19A BULB LEAD.wav.npy', '00073-09 19A BULB LEAD.wav.npy', '00073-02 19A BULB LEAD.wav.npy', '00073-10 19A BULB LEAD.wav.npy', '00073-04 19A BULB LEAD.wav.npy', '00073-05 19A BULB LEAD.wav.npy', '00072-01 18D BULB RHYTHM.wav.npy', '00073-06 19A BULB LEAD.wav.npy', '00073-08 19A BULB LEAD.wav.npy', '00073-12 19A BULB LEAD.wav.npy', '00073-07 19A BULB LEAD.wav.npy', '00073-01 19A BULB LEAD.wav.npy', '00074-08 19B BULB CLEAN.wav.npy', '00074-02 19B BULB CLEAN.wav.npy', '00074-04 19B BULB CLEAN.wav.npy', '00074-05 19B BULB CLEAN.wav.npy', '00074-07 19B BULB CLEAN.wav.npy', '00074-12 19B BULB CLEAN.wav.npy', '00074-03 19B BULB CLEAN.wav.npy', '00074-10 19B BULB CLEAN.wav.npy', '00074-06 19B BULB CLEAN.wav.npy', '00074-09 19B BULB CLEAN.wav.npy', '00074-11 19B BULB CLEAN.wav.npy', '00075-06 19C BULB AMBIENT.wav.npy', '00075-07 19C BULB AMBIENT.wav.npy', '00075-09 19C BULB AMBIENT.wav.npy', '00075-11 19C BULB AMBIENT.wav.npy', '00075-03 19C BULB AMBIENT.wav.npy', '00075-04 19C BULB AMBIENT.wav.npy', '00075-10 19C BULB AMBIENT.wav.npy', '00074-01 19B BULB CLEAN.wav.npy', '00075-02 19C BULB AMBIENT.wav.npy', '00075-12 19C BULB AMBIENT.wav.npy', '00075-08 19C BULB AMBIENT.wav.npy', '00075-05 19C BULB AMBIENT.wav.npy', '00076-11 19D EMPTY GARBAGE.wav.npy', '00076-02 19D EMPTY GARBAGE.wav.npy', '00076-03 19D EMPTY GARBAGE.wav.npy', '00076-05 19D EMPTY GARBAGE.wav.npy', '00076-04 19D EMPTY GARBAGE.wav.npy', '00076-07 19D EMPTY GARBAGE.wav.npy', '00076-09 19D EMPTY GARBAGE.wav.npy', '00075-01 19C BULB AMBIENT.wav.npy', '00076-10 19D EMPTY GARBAGE.wav.npy', '00076-12 19D EMPTY GARBAGE.wav.npy', '00076-06 19D EMPTY GARBAGE.wav.npy', '00076-08 19D EMPTY GARBAGE.wav.npy', '00077-12 20A ONLY GARBAGE.wav.npy', '00077-10 20A ONLY GARBAGE.wav.npy', '00077-09 20A ONLY GARBAGE.wav.npy', '00077-07 20A ONLY GARBAGE.wav.npy', '00077-03 20A ONLY GARBAGE.wav.npy', '00077-04 20A ONLY GARBAGE.wav.npy', '00076-01 19D EMPTY GARBAGE.wav.npy', '00077-08 20A ONLY GARBAGE.wav.npy', '00077-02 20A ONLY GARBAGE.wav.npy', '00077-05 20A ONLY GARBAGE.wav.npy', '00077-11 20A ONLY GARBAGE.wav.npy', '00077-06 20A ONLY GARBAGE.wav.npy', '00078-12 20B GARBAGE BASS.wav.npy', '00077-01 20A ONLY GARBAGE.wav.npy', '00078-06 20B GARBAGE BASS.wav.npy', '00078-03 20B GARBAGE BASS.wav.npy', '00078-07 20B GARBAGE BASS.wav.npy', '00078-08 20B GARBAGE BASS.wav.npy', '00078-11 20B GARBAGE BASS.wav.npy', '00078-10 20B GARBAGE BASS.wav.npy', '00078-02 20B GARBAGE BASS.wav.npy', '00078-04 20B GARBAGE BASS.wav.npy', '00078-05 20B GARBAGE BASS.wav.npy', '00078-09 20B GARBAGE BASS.wav.npy', '00079-09 20C BILLY KASTODON.wav.npy', '00079-07 20C BILLY KASTODON.wav.npy', '00078-01 20B GARBAGE BASS.wav.npy', '00079-05 20C BILLY KASTODON.wav.npy', '00079-06 20C BILLY KASTODON.wav.npy', '00079-04 20C BILLY KASTODON.wav.npy', '00079-02 20C BILLY KASTODON.wav.npy', '00079-11 20C BILLY KASTODON.wav.npy', '00079-03 20C BILLY KASTODON.wav.npy', '00079-12 20C BILLY KASTODON.wav.npy', '00079-08 20C BILLY KASTODON.wav.npy', '00079-10 20C BILLY KASTODON.wav.npy', '00080-10 20D THIS IS THE END.wav.npy', '00080-08 20D THIS IS THE END.wav.npy', '00080-11 20D THIS IS THE END.wav.npy', '00080-07 20D THIS IS THE END.wav.npy', '00080-06 20D THIS IS THE END.wav.npy', '00079-01 20C BILLY KASTODON.wav.npy', '00080-04 20D THIS IS THE END.wav.npy', '00080-03 20D THIS IS THE END.wav.npy', '00080-09 20D THIS IS THE END.wav.npy', '00080-12 20D THIS IS THE END.wav.npy', '00080-05 20D THIS IS THE END.wav.npy', '00080-02 20D THIS IS THE END.wav.npy', '00080-01 20D THIS IS THE END.wav.npy']))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ]
}